{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T12:51:15.850237Z",
     "start_time": "2020-05-16T12:51:15.836293Z"
    }
   },
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "\n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T12:51:41.160781Z",
     "start_time": "2020-05-16T12:51:40.473669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n"
     ]
    }
   ],
   "source": [
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T12:59:19.502839Z",
     "start_time": "2020-05-16T12:59:19.494464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T12:58:08.910329Z",
     "start_time": "2020-05-16T12:58:08.313969Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T12:59:40.456776Z",
     "start_time": "2020-05-16T12:59:40.340499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([layers.Dense(256, activation='relu'),\n",
    "                     layers.Dense(128, activation='relu'),\n",
    "                     layers.Dense(64, activation='relu'),\n",
    "                     layers.Dense(32, activation='relu'),\n",
    "                     layers.Dense(10)])\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T13:04:33.956315Z",
     "start_time": "2020-05-16T13:04:33.936933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=0.01)\n",
    "\n",
    "acc_meter = metrics.Accuracy()\n",
    "loss_meter = metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T13:06:46.356170Z",
     "start_time": "2020-05-16T13:04:37.536933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 2.3430045\n",
      "78 Evaluate Acc: 0.2143 0.2143\n",
      "100 loss: 0.5216492\n",
      "200 loss: 0.2301424\n",
      "300 loss: 0.20898262\n",
      "400 loss: 0.199205\n",
      "500 loss: 0.16166781\n",
      "78 Evaluate Acc: 0.9582 0.9582\n",
      "600 loss: 0.14944176\n",
      "700 loss: 0.13741818\n",
      "800 loss: 0.13429566\n",
      "900 loss: 0.124954216\n",
      "1000 loss: 0.11625112\n",
      "78 Evaluate Acc: 0.9675 0.9675\n",
      "1100 loss: 0.10145916\n",
      "1200 loss: 0.10475279\n",
      "1300 loss: 0.106985204\n",
      "1400 loss: 0.10870165\n",
      "1500 loss: 0.08039901\n",
      "78 Evaluate Acc: 0.9702 0.9702\n",
      "1600 loss: 0.1086403\n",
      "1700 loss: 0.089237764\n",
      "1800 loss: 0.10264205\n",
      "1900 loss: 0.093836695\n",
      "2000 loss: 0.069580704\n",
      "78 Evaluate Acc: 0.9703 0.9703\n",
      "2100 loss: 0.08971125\n",
      "2200 loss: 0.08915021\n",
      "2300 loss: 0.079365686\n",
      "2400 loss: 0.0751986\n",
      "2500 loss: 0.074397795\n",
      "78 Evaluate Acc: 0.9611 0.9611\n",
      "2600 loss: 0.09853884\n",
      "2700 loss: 0.08801999\n",
      "2800 loss: 0.10047382\n",
      "2900 loss: 0.080029964\n",
      "3000 loss: 0.07832683\n",
      "78 Evaluate Acc: 0.9693 0.9693\n",
      "3100 loss: 0.07068557\n",
      "3200 loss: 0.08225421\n",
      "3300 loss: 0.074772075\n",
      "3400 loss: 0.063054346\n",
      "3500 loss: 0.070554934\n",
      "78 Evaluate Acc: 0.9739 0.9739\n",
      "3600 loss: 0.070293464\n",
      "3700 loss: 0.07386956\n",
      "3800 loss: 0.06434065\n",
      "3900 loss: 0.057645105\n",
      "4000 loss: 0.063810445\n",
      "78 Evaluate Acc: 0.9719 0.9719\n",
      "4100 loss: 0.0703415\n",
      "4200 loss: 0.070934184\n",
      "4300 loss: 0.054448098\n",
      "4400 loss: 0.04887894\n",
      "4500 loss: 0.06202144\n",
      "78 Evaluate Acc: 0.9676 0.9676\n",
      "4600 loss: 0.07229813\n"
     ]
    }
   ],
   "source": [
    "for step, (x,y) in enumerate(db):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        out = network(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10) \n",
    "        # [b]\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "\n",
    "        loss_meter.update_state(loss)\n",
    "\n",
    " \n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "\n",
    "    if step % 100 == 0:\n",
    "\n",
    "        print(step, 'loss:', loss_meter.result().numpy()) \n",
    "        loss_meter.reset_states()\n",
    "\n",
    "\n",
    "    # evaluate\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "        acc_meter.reset_states()\n",
    "\n",
    "        for step, (x, y) in enumerate(ds_val): \n",
    "            # [b, 28, 28] => [b, 784]\n",
    "            x = tf.reshape(x, (-1, 28*28))\n",
    "            # [b, 784] => [b, 10]\n",
    "            out = network(x) \n",
    "\n",
    "\n",
    "            # [b, 10] => [b] \n",
    "            pred = tf.argmax(out, axis=1) \n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            # bool type \n",
    "            correct = tf.equal(pred, y)\n",
    "            # bool tensor => int tensor => numpy\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += x.shape[0]\n",
    "\n",
    "            acc_meter.update_state(y, pred)\n",
    "\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct/total, acc_meter.result().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
