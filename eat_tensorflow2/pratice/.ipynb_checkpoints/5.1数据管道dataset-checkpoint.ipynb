{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:38:23.687553Z",
     "start_time": "2020-05-12T09:38:23.680820Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from sklearn import datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy array 构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:43:49.297521Z",
     "start_time": "2020-05-12T09:43:49.284892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:44:16.728424Z",
     "start_time": "2020-05-12T09:44:16.721233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:46:45.685048Z",
     "start_time": "2020-05-12T09:46:45.660104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor([4.9 3.  1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor([5.  3.6 1.4 0.2], shape=(4,), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "## numpy to tensorflow \n",
    "ds1 = tf.data.Dataset.from_tensor_slices((iris[\"data\"],iris[\"target\"]))\n",
    "for features,label in ds1.take(5):\n",
    "    print(features,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas dataframe 构建数据管道 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:50:25.401255Z",
     "start_time": "2020-05-12T09:50:25.392018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:50:26.295906Z",
     "start_time": "2020-05-12T09:50:26.286914Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris.feature_names \n",
    "dfiris = pd.DataFrame(iris[\"data\"],columns = iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:50:49.294439Z",
     "start_time": "2020-05-12T09:50:49.276338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfiris.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:52:58.527923Z",
     "start_time": "2020-05-12T09:52:58.519675Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfiris.to_dict(\"list\").keys()   ## to_dict, value to list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:53:21.530108Z",
     "start_time": "2020-05-12T09:53:21.521489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T09:59:34.264288Z",
     "start_time": "2020-05-12T09:59:34.244331Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sepal length (cm)': <tf.Tensor: id=872, shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: id=873, shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: id=870, shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: id=871, shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n",
      "{'sepal length (cm)': <tf.Tensor: id=877, shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: id=878, shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: id=875, shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: id=876, shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n",
      "{'sepal length (cm)': <tf.Tensor: id=882, shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: id=883, shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: id=880, shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: id=881, shape=(), dtype=float32, numpy=0.2>} tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ds2 = tf.data.Dataset.from_tensor_slices((dfiris.to_dict(\"list\"),iris[\"target\"]))\n",
    "for features,label in ds2.take(3):\n",
    "    print(features,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从csv文件构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:30:25.441985Z",
     "start_time": "2020-05-12T12:30:25.296540Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('sex', <tf.Tensor: id=8728, shape=(3,), dtype=string, numpy=array([b'male', b'male', b'female'], dtype=object)>), ('age', <tf.Tensor: id=8720, shape=(3,), dtype=float32, numpy=array([28.  ,  0.92, 36.  ], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: id=8726, shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('parch', <tf.Tensor: id=8727, shape=(3,), dtype=int32, numpy=array([0, 2, 0], dtype=int32)>), ('fare', <tf.Tensor: id=8725, shape=(3,), dtype=float32, numpy=array([  7.7958, 151.55  ,  13.    ], dtype=float32)>), ('class', <tf.Tensor: id=8722, shape=(3,), dtype=string, numpy=array([b'Third', b'First', b'Second'], dtype=object)>), ('deck', <tf.Tensor: id=8723, shape=(3,), dtype=string, numpy=array([b'unknown', b'C', b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: id=8724, shape=(3,), dtype=string, numpy=array([b'Southampton', b'Southampton', b'Southampton'], dtype=object)>), ('alone', <tf.Tensor: id=8721, shape=(3,), dtype=string, numpy=array([b'y', b'n', b'y'], dtype=object)>)]) tf.Tensor([0 1 1], shape=(3,), dtype=int32)\n",
      "OrderedDict([('sex', <tf.Tensor: id=8738, shape=(3,), dtype=string, numpy=array([b'male', b'male', b'male'], dtype=object)>), ('age', <tf.Tensor: id=8730, shape=(3,), dtype=float32, numpy=array([28., 64., 32.], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: id=8736, shape=(3,), dtype=int32, numpy=array([0, 1, 0], dtype=int32)>), ('parch', <tf.Tensor: id=8737, shape=(3,), dtype=int32, numpy=array([0, 4, 0], dtype=int32)>), ('fare', <tf.Tensor: id=8735, shape=(3,), dtype=float32, numpy=array([  8.4583, 263.    ,   8.3625], dtype=float32)>), ('class', <tf.Tensor: id=8732, shape=(3,), dtype=string, numpy=array([b'Third', b'First', b'Third'], dtype=object)>), ('deck', <tf.Tensor: id=8733, shape=(3,), dtype=string, numpy=array([b'unknown', b'C', b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: id=8734, shape=(3,), dtype=string, numpy=array([b'Queenstown', b'Southampton', b'Southampton'], dtype=object)>), ('alone', <tf.Tensor: id=8731, shape=(3,), dtype=string, numpy=array([b'y', b'n', b'y'], dtype=object)>)]) tf.Tensor([0 0 0], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ds4 = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = [\"/Users/jun_yu/Documents/yujun_repository/Wide & Deep/wide-and-deep-titan_0512/train.csv\",\n",
    "                    \"/Users/jun_yu/Documents/yujun_repository/Wide & Deep/wide-and-deep-titan_0512/eval.csv\"],\n",
    "    batch_size=3, \n",
    "    label_name=\"survived\",\n",
    "    na_value=\"\",\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True)\n",
    "\n",
    "for data,label in ds4.take(2):\n",
    "    print(data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从文本文件构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T10:58:51.826872Z",
     "start_time": "2020-05-12T10:58:51.797148Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'0,male,22.0,1,0,7.25,Third,unknown,Southampton,n', shape=(), dtype=string)\n",
      "tf.Tensor(b'1,female,38.0,1,0,71.2833,First,C,Cherbourg,n', shape=(), dtype=string)\n",
      "tf.Tensor(b'1,female,26.0,0,0,7.925,Third,unknown,Southampton,y', shape=(), dtype=string)\n",
      "tf.Tensor(b'1,female,35.0,1,0,53.1,First,C,Southampton,n', shape=(), dtype=string)\n",
      "tf.Tensor(b'0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ds5 = tf.data.TextLineDataset(\n",
    "    filenames = [\"/Users/jun_yu/Documents/yujun_repository/Wide & Deep/wide-and-deep-titan_0512/train.csv\",\n",
    "                 \"/Users/jun_yu/Documents/yujun_repository/Wide & Deep/wide-and-deep-titan_0512/eval.csv\"],\n",
    "    ).skip(1)  #略去第一行header\n",
    "\n",
    "for line in ds5.take(5):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从文件路径构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:00:41.923609Z",
     "start_time": "2020-05-12T11:00:41.918643Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ds6 = tf.data.Dataset.list_files(\"./data/cifar2/train/*/*.jpg\")\n",
    "# for file in ds6.take(5):\n",
    "#     print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset包含了非常丰富的数据转换功能。\n",
    "\n",
    "* map: 将转换函数映射到数据集每一个元素。\n",
    "\n",
    "* flat_map: 将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。\n",
    "\n",
    "* interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。\n",
    "\n",
    "* filter: 过滤掉某些元素。\n",
    "\n",
    "* zip: 将两个长度相同的Dataset横向铰合。\n",
    "\n",
    "* concatenate: 将两个Dataset纵向连接。\n",
    "\n",
    "* reduce: 执行归并操作。\n",
    "\n",
    "* batch : 构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。\n",
    "\n",
    "* padded_batch: 构建批次，类似batch, 但可以填充到相同的形状。\n",
    "\n",
    "* window :构建滑动窗口，返回Dataset of Dataset.\n",
    "\n",
    "* shuffle: 数据顺序洗牌。\n",
    "\n",
    "* repeat: 重复数据若干次，不带参数时，重复无数次。\n",
    "\n",
    "* shard: 采样，从某个位置开始隔固定距离采样一个元素。\n",
    "\n",
    "* take: 采样，从开始位置取前几个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:15:32.077400Z",
     "start_time": "2020-05-12T12:15:31.883808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'hello', b'world']\n",
      "[b'hello', b'China']\n",
      "[b'hello', b'Beijing']\n",
      "hello world\n",
      "hello China\n",
      "hello Beijing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hello world', 'hello China', 'hello Beijing']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map:将转换函数映射到数据集每一个元素\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n",
    "ds_map = ds.map(lambda x:tf.strings.split(x,\" \"))\n",
    "for x in ds_map:\n",
    "    print(list(x.numpy()))\n",
    "\n",
    "tmp = []\n",
    "for x in ds:\n",
    "    tmp.append(x.numpy().decode('utf-8'))\n",
    "    print(x.numpy().decode('utf-8'))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:17:18.554721Z",
     "start_time": "2020-05-12T12:17:18.439542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n",
      "hello\n",
      "China\n",
      "hello\n",
      "Beijing\n"
     ]
    }
   ],
   "source": [
    "#flat_map:将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n",
    "ds_flatmap = ds.flat_map(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\n",
    "for x in ds_flatmap:\n",
    "    print(x.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:18:39.567959Z",
     "start_time": "2020-05-12T12:18:39.459425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "world\n",
      "China\n",
      "Beijing\n"
     ]
    }
   ],
   "source": [
    "# interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n",
    "ds_interleave = ds.interleave(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\n",
    "for x in ds_interleave:\n",
    "    print(x.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:19:40.606838Z",
     "start_time": "2020-05-12T12:19:40.487276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello China\n",
      "hello Beijing\n"
     ]
    }
   ],
   "source": [
    "#filter:过滤掉某些元素。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n",
    "#找出含有字母a或B的元素\n",
    "ds_filter = ds.filter(lambda x: tf.strings.regex_full_match(x, \".*[a|B].*\"))\n",
    "for x in ds_filter:\n",
    "    print(x.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:20:26.337402Z",
     "start_time": "2020-05-12T12:20:26.306591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 6\n",
      "1 4 7\n",
      "2 5 8\n"
     ]
    }
   ],
   "source": [
    "#zip:将两个长度相同的Dataset横向铰合。\n",
    "\n",
    "ds1 = tf.data.Dataset.range(0,3)\n",
    "ds2 = tf.data.Dataset.range(3,6)\n",
    "ds3 = tf.data.Dataset.range(6,9)\n",
    "ds_zip = tf.data.Dataset.zip((ds1,ds2,ds3))\n",
    "for x,y,z in ds_zip:\n",
    "    print(x.numpy(),y.numpy(),z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:21:10.163219Z",
     "start_time": "2020-05-12T12:21:10.146531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#condatenate:将两个Dataset纵向连接。\n",
    "\n",
    "ds1 = tf.data.Dataset.range(0,3)\n",
    "ds2 = tf.data.Dataset.range(3,6)\n",
    "ds_concat = tf.data.Dataset.concatenate(ds1,ds2)\n",
    "for x in ds_concat:\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:25:03.229740Z",
     "start_time": "2020-05-12T12:25:03.202420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8395, shape=(), dtype=float32, numpy=15.0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce:执行归并操作。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([1,2,3,4,5.0])\n",
    "result = ds.reduce(0.0, lambda x,y: tf.add(x,y))    ### 0.0 表示初始值 \n",
    "print(result.numpy())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:53:00.960328Z",
     "start_time": "2020-05-12T11:53:00.944945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "[10 11 12 13 14]\n",
      "[15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "#batch:构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。 \n",
    "\n",
    "ds = tf.data.Dataset.range(20)\n",
    "ds_batch = ds.batch(5)\n",
    "for x in ds_batch:\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:58:57.687888Z",
     "start_time": "2020-05-12T11:58:57.629060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 0 0]\n",
      " [3 4 5 0]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[6 7 0 0]\n",
      " [8 0 0 0]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#padded_batch:构建批次，类似batch, 但可以填充到相同的形状。\n",
    "elements = [[1, 2],[3, 4, 5],[6, 7],[8]]\n",
    "ds = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32) \n",
    "\n",
    "ds_padded_batch = ds.padded_batch(2,padded_shapes = [4,])\n",
    "for x in ds_padded_batch:\n",
    "#     print(x.numpy())\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T12:04:35.840726Z",
     "start_time": "2020-05-12T12:04:35.808497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "(3,)\n",
      "[3 4 5]\n",
      "(3,)\n",
      "[6 7 8]\n",
      "(3,)\n",
      "[ 9 10 11]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "#window:构建滑动窗口，返回Dataset of Dataset.\n",
    "\n",
    "ds = tf.data.Dataset.range(12)\n",
    "#window返回的是Dataset of Dataset,可以用flat_map压平\n",
    "ds_window = ds.window(3, shift=3).flat_map(lambda x: x.batch(3,drop_remainder=True)) \n",
    "for x in ds_window:\n",
    "    print(x.numpy())\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:48:05.309839Z",
     "start_time": "2020-05-12T11:48:05.292353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#shuffle:数据顺序洗牌。\n",
    "ds = tf.data.Dataset.range(7)\n",
    "ds_shuffle = ds.shuffle(buffer_size = 3)\n",
    "for x in ds_shuffle:\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:48:08.699797Z",
     "start_time": "2020-05-12T11:48:08.682914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#repeat:重复数据若干次，不带参数时，重复无数次。\n",
    "ds = tf.data.Dataset.range(3)\n",
    "ds_repeat = ds.repeat(2)\n",
    "for x in ds_repeat:\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:48:12.621702Z",
     "start_time": "2020-05-12T11:48:12.606757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "7\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#shard:采样，从某个位置开始隔固定距离采样一个元素。\n",
    "ds = tf.data.Dataset.range(12)\n",
    "ds_shard = ds.shard(3,index = 1)\n",
    "for x in ds_shard:\n",
    "    print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:49:57.613095Z",
     "start_time": "2020-05-12T11:49:57.606866Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take:采样，从开始位置取前几个元素。\n",
    "ds = tf.data.Dataset.range(12)\n",
    "ds_take = ds.take(3)\n",
    "# list(ds_take.())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是一些构建高效数据管道的建议。\n",
    "\n",
    "* 1，使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。\n",
    "\n",
    "* 2，使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。\n",
    "\n",
    "* 3，使用 map 时设置num_parallel_calls 让数据转换过程多进程执行。\n",
    "\n",
    "* 4，使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。\n",
    "\n",
    "* 5，使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 cache 方法让数据在第一个epoch后缓存到内存中，仅限于数据集不大情形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:16:11.161422Z",
     "start_time": "2020-05-12T11:16:11.097798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 模拟数据准备\n",
    "def generator():\n",
    "    for i in range(5):\n",
    "        #假设每次准备数据需要2s\n",
    "        time.sleep(2) \n",
    "        yield i \n",
    "ds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:17:34.280775Z",
     "start_time": "2020-05-12T11:17:04.098423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "epoch = 0  ended\n",
      "epoch = 1  ended\n",
      "epoch = 2  ended\n",
      "end training...\n"
     ]
    }
   ],
   "source": [
    "# 模拟参数迭代\n",
    "def train_step():\n",
    "    #假设每一步训练需要0s\n",
    "    pass\n",
    "\n",
    "# 训练过程预计耗时 (5*2+5*0)*3 = 30s\n",
    "tf.print(tf.constant(\"start training...\"))\n",
    "for epoch in tf.range(3):\n",
    "    for x in ds:\n",
    "        train_step()  \n",
    "    tf.print(\"epoch =\",epoch,\" ended\")\n",
    "\n",
    "tf.print(tf.constant(\"end training...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:39:10.829818Z",
     "start_time": "2020-05-12T11:39:10.783385Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    ts = tf.timestamp()\n",
    "    today_ts = ts%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "    \n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "    \n",
    "    timestring = tf.strings.join([timeformat(hour),\n",
    "                                  timeformat(minite), \n",
    "                                  timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8,end = \"\")\n",
    "    tf.print(timestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:39:12.046554Z",
     "start_time": "2020-05-12T11:39:11.511386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================19:39:12\n"
     ]
    }
   ],
   "source": [
    "printbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 interleave 方法可以让数据读取过程多进程执行,并将不同来源数据夹在一起。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:23:14.360884Z",
     "start_time": "2020-05-12T11:23:14.356411Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path =\"/Volumes/TOSHIBA/rank_model/no_interest_feature/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:31:41.235767Z",
     "start_time": "2020-05-12T11:31:41.092929Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_files = tf.data.Dataset.list_files(file_path)\n",
    "ds = ds_files.interleave(lambda x:tf.data.TextLineDataset(x).skip(1))\n",
    "\n",
    "tp = list()\n",
    "for line in ds.take(3):\n",
    "    x = list(line.numpy())\n",
    "    tp.append(x)\n",
    "#     print(tf.print(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 map转换时，先batch, 然后采用向量化的转换方法对每个batch进行转换。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先map后batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:12:57.257443Z",
     "start_time": "2020-05-12T11:12:57.241996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.range(100000)\n",
    "ds_map_batch = ds.map(lambda x:x**2).batch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:12:58.435454Z",
     "start_time": "2020-05-12T11:12:58.391389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 ... 289 324 361]\n",
      "None\n",
      "[400 441 484 ... 1369 1444 1521]\n",
      "None\n",
      "[1600 1681 1764 ... 3249 3364 3481]\n",
      "None\n",
      "[3600 3721 3844 ... 5929 6084 6241]\n",
      "None\n",
      "[6400 6561 6724 ... 9409 9604 9801]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in ds_map_batch.take(5):\n",
    "    print(tf.print(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 先batch后map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:04:43.879280Z",
     "start_time": "2020-05-12T11:04:43.799336Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.range(100000)\n",
    "ds_batch_map = ds.batch(20).map(lambda x:x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:10:40.501566Z",
     "start_time": "2020-05-12T11:10:40.468665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 ... 289 324 361]\n",
      "None\n",
      "[400 441 484 ... 1369 1444 1521]\n",
      "None\n",
      "[1600 1681 1764 ... 3249 3364 3481]\n",
      "None\n",
      "[3600 3721 3844 ... 5929 6084 6241]\n",
      "None\n",
      "[6400 6561 6724 ... 9409 9604 9801]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in ds_batch_map.take(5):\n",
    "    print(tf.print(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T11:09:22.554002Z",
     "start_time": "2020-05-12T11:09:22.541117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end vector transformation...\n"
     ]
    }
   ],
   "source": [
    "tf.print(tf.constant(\"end vector transformation...\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load data using tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:54:27.183646Z",
     "start_time": "2020-05-13T10:54:27.178841Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:54:28.240400Z",
     "start_time": "2020-05-13T10:54:28.234083Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_file = tf.keras.utils.get_file('heart.csv', 'https://storage.googleapis.com/applied-dl/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:54:29.280258Z",
     "start_time": "2020-05-13T10:54:29.272278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jun_yu/.keras/datasets/heart.csv'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:54:30.172945Z",
     "start_time": "2020-05-13T10:54:30.149095Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:54:31.013534Z",
     "start_time": "2020-05-13T10:54:31.006998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:54:49.246098Z",
     "start_time": "2020-05-13T10:54:49.222466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:55:07.997414Z",
     "start_time": "2020-05-13T10:55:07.986769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    220\n",
       "1     83\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:55:20.935100Z",
     "start_time": "2020-05-13T10:55:20.924532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal         object\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:55:57.929934Z",
     "start_time": "2020-05-13T10:55:57.920504Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['thal'] = pd.Categorical(df['thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:56:24.261816Z",
     "start_time": "2020-05-13T10:56:24.248132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        168\n",
       "reversible    115\n",
       "fixed          18\n",
       "2               1\n",
       "1               1\n",
       "Name: thal, dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:57:13.942015Z",
     "start_time": "2020-05-13T10:57:13.930941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    168\n",
       "4    115\n",
       "2     18\n",
       "1      1\n",
       "0      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.thal.cat.codes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:58:24.209180Z",
     "start_time": "2020-05-13T10:58:24.201146Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['thal'] = pd.Categorical(df['thal'])\n",
    "df['thal'] = df.thal.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:58:25.101490Z",
     "start_time": "2020-05-13T10:58:25.075869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     2       0  \n",
       "1   3     3       1  \n",
       "2   2     4       0  \n",
       "3   0     3       0  \n",
       "4   0     3       0  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:58:47.951294Z",
     "start_time": "2020-05-13T10:58:47.941665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    168\n",
       "4    115\n",
       "2     18\n",
       "1      1\n",
       "0      1\n",
       "Name: thal, dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['thal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:59:33.595654Z",
     "start_time": "2020-05-13T10:59:33.590198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = df.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T10:59:55.431646Z",
     "start_time": "2020-05-13T10:59:55.424115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63.,  1.,  1., ...,  3.,  0.,  2.],\n",
       "       [67.,  1.,  4., ...,  2.,  3.,  3.],\n",
       "       [67.,  1.,  4., ...,  2.,  2.,  4.],\n",
       "       ...,\n",
       "       [65.,  1.,  4., ...,  2.,  1.,  4.],\n",
       "       [48.,  1.,  4., ...,  1.,  2.,  4.],\n",
       "       [63.,  0.,  4., ...,  2.,  3.,  4.]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:00:15.216706Z",
     "start_time": "2020-05-13T11:00:15.207912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:01:37.313777Z",
     "start_time": "2020-05-13T11:01:37.305521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:30:06.632356Z",
     "start_time": "2020-05-13T09:30:06.486365Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:05:34.471654Z",
     "start_time": "2020-05-13T11:05:34.456886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [ 63.    1.    1.  145.  233.    1.    2.  150.    0.    2.3   3.    0.\n",
      "   2. ], Target: 0\n",
      "Features: [ 67.    1.    4.  160.  286.    0.    2.  108.    1.    1.5   2.    3.\n",
      "   3. ], Target: 1\n",
      "Features: [ 67.    1.    4.  120.  229.    0.    2.  129.    1.    2.6   2.    2.\n",
      "   4. ], Target: 0\n",
      "Features: [ 37.    1.    3.  130.  250.    0.    0.  187.    0.    3.5   3.    0.\n",
      "   3. ], Target: 0\n",
      "Features: [ 41.    0.    2.  130.  204.    0.    2.  172.    0.    1.4   1.    0.\n",
      "   3. ], Target: 0\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in dataset.take(5):\n",
    "    print('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T11:08:46.871316Z",
     "start_time": "2020-05-13T11:08:46.860541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=25380, shape=(303,), dtype=int32, numpy=\n",
       "array([2, 3, 4, 3, 3, 3, 3, 3, 4, 4, 2, 3, 2, 4, 4, 3, 4, 3, 3, 3, 3, 3,\n",
       "       3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 3, 4, 2, 4, 3, 4, 3, 4, 4,\n",
       "       2, 3, 3, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 4,\n",
       "       4, 2, 3, 3, 4, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 4, 4,\n",
       "       3, 3, 4, 3, 4, 4, 3, 4, 3, 3, 3, 4, 3, 4, 4, 3, 3, 4, 4, 4, 4, 4,\n",
       "       3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 2, 4, 4, 2, 3, 3, 4, 4, 3, 4,\n",
       "       3, 3, 4, 2, 4, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
       "       4, 3, 3, 3, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 2,\n",
       "       4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 2, 2, 4, 3, 4, 2, 4, 3,\n",
       "       3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 2, 2, 4, 3, 4, 3, 2, 4, 3, 3, 2,\n",
       "       4, 4, 4, 4, 3, 0, 3, 3, 3, 3, 1, 4, 3, 3, 3, 4, 3, 4, 3, 3, 3, 4,\n",
       "       3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 3,\n",
       "       3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 3, 2, 4, 4, 4, 4], dtype=int32)>"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(df['thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:31:35.527417Z",
     "start_time": "2020-05-13T09:31:35.494614Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(df)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:33:23.476615Z",
     "start_time": "2020-05-13T09:33:23.435630Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:34:55.748618Z",
     "start_time": "2020-05-13T09:34:39.577674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0513 17:34:40.191283 140737132438464 base_layer.py:1814] Layer sequential is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "303/303 [==============================] - 6s 20ms/step - loss: 0.7392 - accuracy: 0.7426\n",
      "Epoch 2/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.6225 - accuracy: 0.7327\n",
      "Epoch 3/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.7228\n",
      "Epoch 4/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.5833 - accuracy: 0.7162\n",
      "Epoch 5/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.5605 - accuracy: 0.7393\n",
      "Epoch 6/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7360\n",
      "Epoch 7/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7459\n",
      "Epoch 8/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7228\n",
      "Epoch 9/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.5105 - accuracy: 0.7228\n",
      "Epoch 10/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7327\n",
      "Epoch 11/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7624\n",
      "Epoch 12/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.7426\n",
      "Epoch 13/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.7690\n",
      "Epoch 14/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.7591\n",
      "Epoch 15/15\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.7459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a36a7d048>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:36:52.988976Z",
     "start_time": "2020-05-13T09:36:52.776123Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = {key: tf.keras.layers.Input(shape=(), name=key) for key in df.keys()}\n",
    "\n",
    "x = tf.stack(list(inputs.values()), axis=-1)\n",
    "\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model_func = tf.keras.Model(inputs=inputs, \n",
    "                            outputs=output)\n",
    "\n",
    "model_func.compile(optimizer='adam',\n",
    "                   loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:37:33.153692Z",
     "start_time": "2020-05-13T09:37:33.090723Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_slices = tf.data.Dataset.from_tensor_slices((df.to_dict('list'), target.values)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:45:11.054186Z",
     "start_time": "2020-05-13T09:45:11.032386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "dict_values([<tf.Tensor: id=25332, shape=(16,), dtype=int32, numpy=\n",
      "array([63, 67, 67, 37, 41, 56, 62, 57, 63, 53, 57, 56, 56, 44, 52, 57],\n",
      "      dtype=int32)>, <tf.Tensor: id=25340, shape=(16,), dtype=int32, numpy=array([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1], dtype=int32)>, <tf.Tensor: id=25335, shape=(16,), dtype=int32, numpy=array([1, 4, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3, 2, 3, 3], dtype=int32)>, <tf.Tensor: id=25344, shape=(16,), dtype=int32, numpy=\n",
      "array([145, 160, 120, 130, 130, 120, 140, 120, 130, 140, 140, 140, 130,\n",
      "       120, 172, 150], dtype=int32)>, <tf.Tensor: id=25334, shape=(16,), dtype=int32, numpy=\n",
      "array([233, 286, 229, 250, 204, 236, 268, 354, 254, 203, 192, 294, 256,\n",
      "       263, 199, 168], dtype=int32)>, <tf.Tensor: id=25337, shape=(16,), dtype=int32, numpy=array([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int32)>, <tf.Tensor: id=25339, shape=(16,), dtype=int32, numpy=array([2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0], dtype=int32)>, <tf.Tensor: id=25343, shape=(16,), dtype=int32, numpy=\n",
      "array([150, 108, 129, 187, 172, 178, 160, 163, 147, 155, 148, 153, 142,\n",
      "       173, 162, 174], dtype=int32)>, <tf.Tensor: id=25336, shape=(16,), dtype=int32, numpy=array([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0], dtype=int32)>, <tf.Tensor: id=25338, shape=(16,), dtype=float32, numpy=\n",
      "array([2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 1.4, 3.1, 0.4, 1.3, 0.6,\n",
      "       0. , 0.5, 1.6], dtype=float32)>, <tf.Tensor: id=25341, shape=(16,), dtype=int32, numpy=array([3, 2, 2, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2, 1, 1, 1], dtype=int32)>, <tf.Tensor: id=25333, shape=(16,), dtype=int32, numpy=array([0, 3, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int32)>, <tf.Tensor: id=25342, shape=(16,), dtype=int32, numpy=array([2, 3, 4, 3, 3, 3, 3, 3, 4, 4, 2, 3, 2, 4, 4, 3], dtype=int32)>])\n"
     ]
    }
   ],
   "source": [
    "for dict_slice in dict_slices.take(1):\n",
    "    print(type(dict_slice))\n",
    "    print(dict_slice[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T09:40:00.567998Z",
     "start_time": "2020-05-13T09:39:58.159423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "19/19 [==============================] - 1s 51ms/step - loss: 3.4952 - accuracy: 0.7426\n",
      "Epoch 2/15\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.9554 - accuracy: 0.7228\n",
      "Epoch 3/15\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.5521 - accuracy: 0.7459\n",
      "Epoch 4/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.3603 - accuracy: 0.7327\n",
      "Epoch 5/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.1574 - accuracy: 0.7393\n",
      "Epoch 6/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.0183 - accuracy: 0.7327\n",
      "Epoch 7/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9161 - accuracy: 0.7195\n",
      "Epoch 8/15\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.8166 - accuracy: 0.7228\n",
      "Epoch 9/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7166 - accuracy: 0.7162\n",
      "Epoch 10/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6302 - accuracy: 0.7162\n",
      "Epoch 11/15\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.5449 - accuracy: 0.7162\n",
      "Epoch 12/15\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.4698 - accuracy: 0.7228\n",
      "Epoch 13/15\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.4062 - accuracy: 0.7327\n",
      "Epoch 14/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3505 - accuracy: 0.7426\n",
      "Epoch 15/15\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3026 - accuracy: 0.7492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a36a874a8>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_func.fit(dict_slices, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
