{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## feature_column  特征列 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* numeric_column 数值列，最常用。\n",
    "\n",
    "\n",
    "* bucketized_column 分桶列，由数值列生成，可以由一个数值列出多个特征，one-hot编码。\n",
    "\n",
    "\n",
    "* categorical_column_with_identity 分类标识列，one-hot编码，相当于分桶列每个桶为1个整数的情况。\n",
    "\n",
    "\n",
    "* categorical_column_with_vocabulary_list 分类词汇列，one-hot编码，由list指定词典。\n",
    "\n",
    "\n",
    "* categorical_column_with_vocabulary_file 分类词汇列，由文件file指定词典。\n",
    "\n",
    "\n",
    "* categorical_column_with_hash_bucket 哈希列，整数或词典较大时采用。\n",
    "\n",
    "\n",
    "* indicator_column 指标列，由Categorical Column生成，one-hot编码\n",
    "\n",
    "\n",
    "* embedding_column 嵌入列，由Categorical Column生成，嵌入矢量分布参数需要学习。嵌入矢量维数建议取类别数量的 4 次方根。\n",
    "\n",
    "\n",
    "* crossed_column 交叉列，可以由除categorical_column_with_hash_bucket的任意分类列构成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:18:40.293883Z",
     "start_time": "2020-05-13T16:18:40.201664Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers,models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:18:44.927475Z",
     "start_time": "2020-05-13T16:18:44.890173Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#打印日志\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(info+'...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:18:47.477673Z",
     "start_time": "2020-05-13T16:18:47.454624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2020-05-14 00:18:47\n",
      "step1: prepare dataset......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printlog(\"step1: prepare dataset...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:19:07.952212Z",
     "start_time": "2020-05-13T16:19:07.583022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2020-05-14 00:19:07\n",
      "step1: prepare dataset......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printlog(\"step1: prepare dataset...\")\n",
    "\n",
    "dftrain_raw = pd.read_csv(\"/Users/jun_yu/Documents/yujun_repository/tensorflow_2.0_study/eat_tensorflow2/data/titanic/train.csv\")\n",
    "dftest_raw = pd.read_csv(\"/Users/jun_yu/Documents/yujun_repository/tensorflow_2.0_study/eat_tensorflow2/data/titanic/test.csv\")\n",
    "\n",
    "dfraw = pd.concat([dftrain_raw,dftest_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:19:11.655302Z",
     "start_time": "2020-05-13T16:19:11.608986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 12), (179, 12))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain_raw.shape, dftest_raw.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:19:21.283997Z",
     "start_time": "2020-05-13T16:19:21.269377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfraw.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:19:29.384307Z",
     "start_time": "2020-05-13T16:19:29.299289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfraw['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:22:12.820909Z",
     "start_time": "2020-05-13T16:22:12.686056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dfdata(dfraw):\n",
    "    dfdata = dfraw.copy()\n",
    "    dfdata.columns = [x.lower() for x in dfdata.columns]\n",
    "    dfdata = dfdata.rename(columns={'survived':'label'})\n",
    "    \n",
    "    dfdata = dfdata.drop(['passengerid','name'],axis = 1)\n",
    "    for col,dtype in dict(dfdata.dtypes).items():\n",
    "        # 判断是否包含缺失值\n",
    "        if dfdata[col].hasnans:\n",
    "            # 添加标识是否缺失列\n",
    "            dfdata[col + '_nan'] = pd.isna(dfdata[col]).astype('int32')   ## 添加每列是否 缺失标记 \n",
    "            # 填充, 缺失值填充, 字符串按''填充, 非字符串按均值填充  \n",
    "            if dtype not in [np.object,np.str,np.unicode]:                ## 每列做缺失填充  \n",
    "                dfdata[col].fillna(dfdata[col].mean(),inplace = True)\n",
    "            else:\n",
    "                dfdata[col].fillna('',inplace = True)\n",
    "    return(dfdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T07:08:23.759978Z",
     "start_time": "2020-05-13T07:08:23.745412Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label float64\n",
      "pclass int64\n",
      "sex object\n",
      "age float64\n",
      "sibsp int64\n",
      "parch int64\n",
      "ticket object\n",
      "fare float64\n",
      "cabin object\n",
      "embarked object\n",
      "label_nan int32\n",
      "age_nan int32\n",
      "fare_nan int32\n",
      "cabin_nan int32\n",
      "embarked_nan int32\n"
     ]
    }
   ],
   "source": [
    "# for col,dtype in dict(dfdata.dtypes).items():\n",
    "#     print(col,dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:22:18.314919Z",
     "start_time": "2020-05-13T16:22:18.119672Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfdata = prepare_dfdata(dfraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:22:45.328634Z",
     "start_time": "2020-05-13T16:22:45.312456Z"
    }
   },
   "outputs": [],
   "source": [
    "dftrain = dfdata.iloc[0:len(dftrain_raw),:]\n",
    "dftest = dfdata.iloc[len(dftrain_raw):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:22:48.484375Z",
     "start_time": "2020-05-13T16:22:48.477166Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 13), (179, 13))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape, dftest.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:23:25.288930Z",
     "start_time": "2020-05-13T16:23:25.250395Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>age_nan</th>\n",
       "      <th>cabin_nan</th>\n",
       "      <th>embarked_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315096</td>\n",
       "      <td>8.6625</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>347088</td>\n",
       "      <td>27.9000</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2666</td>\n",
       "      <td>19.2583</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pclass     sex        age  sibsp  parch    ticket      fare  \\\n",
       "0      0       3  female  29.699118      8      2  CA. 2343   69.5500   \n",
       "1      0       3  female  20.000000      0      0    315096    8.6625   \n",
       "2      0       3  female   9.000000      3      2    347088   27.9000   \n",
       "3      1       1  female  18.000000      1      0  PC 17757  227.5250   \n",
       "4      1       3  female   0.750000      2      1      2666   19.2583   \n",
       "\n",
       "     cabin embarked  age_nan  cabin_nan  embarked_nan  \n",
       "0                 S        1          1             0  \n",
       "1                 S        0          1             0  \n",
       "2                 S        0          1             0  \n",
       "3  C62 C64        C        0          0             0  \n",
       "4                 C        0          1             0  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:28:59.153991Z",
     "start_time": "2020-05-13T16:28:59.122698Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 从 dataframe 导入数据 \n",
    "def df_to_dataset(df, shuffle=True, batch_size=32):\n",
    "    dfdata = df.copy()\n",
    "    if 'label' not in dfdata.columns:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dfdata.to_dict(orient = 'list'))\n",
    "    else: \n",
    "        labels = dfdata.pop('label')\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dfdata.to_dict(orient = 'list'), labels))  \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dfdata))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:29:00.723929Z",
     "start_time": "2020-05-13T16:29:00.342019Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_train = df_to_dataset(dftrain)\n",
    "ds_test = df_to_dataset(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:31:00.330212Z",
     "start_time": "2020-05-13T16:31:00.305826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2020-05-14 00:31:00\n",
      "step2: make feature columns......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printlog(\"step2: make feature columns...\")\n",
    "\n",
    "feature_columns = [] \n",
    "\n",
    "# 数值列\n",
    "for col in ['age','fare','parch','sibsp'] + [c for c in dfdata.columns if c.endswith('_nan')]:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:31:03.227270Z",
     "start_time": "2020-05-13T16:31:03.216214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='sibsp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='age_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='cabin_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='embarked_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:32:23.699790Z",
     "start_time": "2020-05-13T16:32:23.686989Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分桶列\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "age_buckets = tf.feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "\n",
    "feature_columns.append(age_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:32:50.713302Z",
     "start_time": "2020-05-13T16:32:50.702173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='sibsp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='age_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='cabin_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='embarked_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65))]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:32:55.715502Z",
     "start_time": "2020-05-13T16:32:55.680399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 类别列\n",
    "# 注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！！\n",
    "sex = tf.feature_column.indicator_column(\n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      key='sex',vocabulary_list=[\"male\", \"female\"]))\n",
    "feature_columns.append(sex)\n",
    "\n",
    "pclass = tf.feature_column.indicator_column(    ## 竟然是类别的, 但是数值是 int的  \n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      key='pclass',vocabulary_list=[1,2,3]))\n",
    "feature_columns.append(pclass)\n",
    "\n",
    "ticket = tf.feature_column.indicator_column(     ## 类别无法枚举完时, 采用hash_bucket\n",
    "     tf.feature_column.categorical_column_with_hash_bucket('ticket',3))\n",
    "feature_columns.append(ticket)\n",
    "\n",
    "embarked = tf.feature_column.indicator_column(\n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      key='embarked',vocabulary_list=['S','C','B']))\n",
    "feature_columns.append(embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:33:04.288415Z",
     "start_time": "2020-05-13T16:33:04.281289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='sibsp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='age_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='cabin_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='embarked_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='pclass', vocabulary_list=(1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=HashedCategoricalColumn(key='ticket', hash_bucket_size=3, dtype=tf.string)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embarked', vocabulary_list=('S', 'C', 'B'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:33:09.746860Z",
     "start_time": "2020-05-13T16:33:09.725384Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 嵌入列   \n",
    "cabin = tf.feature_column.embedding_column(   ## embedding 列, 拼合维度为2 \n",
    "    tf.feature_column.categorical_column_with_hash_bucket('cabin',32),2)\n",
    "feature_columns.append(cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:33:12.735923Z",
     "start_time": "2020-05-13T16:33:12.725387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='sibsp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='age_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='cabin_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='embarked_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='pclass', vocabulary_list=(1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=HashedCategoricalColumn(key='ticket', hash_bucket_size=3, dtype=tf.string)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embarked', vocabulary_list=('S', 'C', 'B'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='cabin', hash_bucket_size=32, dtype=tf.string), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x18388d3080>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:33:21.833934Z",
     "start_time": "2020-05-13T16:33:21.823381Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 交叉列\n",
    "pclass_cate = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "          key='pclass',vocabulary_list=[1,2,3])\n",
    "\n",
    "crossed_feature = tf.feature_column.indicator_column(   ## age分桶列 交叉pclass类别列\n",
    "    tf.feature_column.crossed_column([age_buckets, pclass_cate],hash_bucket_size=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:33:31.928112Z",
     "start_time": "2020-05-13T16:33:31.924233Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns.append(crossed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:33:36.227229Z",
     "start_time": "2020-05-13T16:33:36.217829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='sibsp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='age_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='cabin_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='embarked_nan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='pclass', vocabulary_list=(1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=HashedCategoricalColumn(key='ticket', hash_bucket_size=3, dtype=tf.string)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embarked', vocabulary_list=('S', 'C', 'B'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='cabin', hash_bucket_size=32, dtype=tf.string), dimension=2, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x18388d3080>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " IndicatorColumn(categorical_column=CrossedColumn(keys=(BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), VocabularyListCategoricalColumn(key='pclass', vocabulary_list=(1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)), hash_bucket_size=15, hash_key=None))]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:34:01.379763Z",
     "start_time": "2020-05-13T16:34:01.153840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2020-05-14 00:34:01\n",
      "step3: define model......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printlog(\"step3: define model...\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "  layers.DenseFeatures(feature_columns), #将特征列放入到tf.keras.layers.DenseFeatures中!!!\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:37:20.741719Z",
     "start_time": "2020-05-13T16:34:45.521842Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2020-05-14 00:34:45\n",
      "step4: train model......\n",
      "\n",
      "Epoch 1/1000\n",
      "23/23 [==============================] - 6s 248ms/step - loss: 1.6740 - accuracy: 0.5154 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6978 - accuracy: 0.6882 - val_loss: 0.6613 - val_accuracy: 0.6592\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5962 - accuracy: 0.7008 - val_loss: 0.6075 - val_accuracy: 0.6704\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5917 - accuracy: 0.7079 - val_loss: 0.5901 - val_accuracy: 0.6760\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5911 - accuracy: 0.7177 - val_loss: 0.5553 - val_accuracy: 0.7095\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5613 - accuracy: 0.7303 - val_loss: 0.5300 - val_accuracy: 0.7207\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5450 - accuracy: 0.7331 - val_loss: 0.5236 - val_accuracy: 0.7430\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5164 - accuracy: 0.7472 - val_loss: 0.5294 - val_accuracy: 0.7542\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.5287 - accuracy: 0.7486 - val_loss: 0.5335 - val_accuracy: 0.7318\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5227 - accuracy: 0.7612 - val_loss: 0.5230 - val_accuracy: 0.7318\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.7907 - val_loss: 0.4660 - val_accuracy: 0.7933\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.7879 - val_loss: 0.4713 - val_accuracy: 0.7933\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7725 - val_loss: 0.4863 - val_accuracy: 0.7877\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.8034 - val_loss: 0.5186 - val_accuracy: 0.7598\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.8076 - val_loss: 0.4443 - val_accuracy: 0.7821\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.8048 - val_loss: 0.4494 - val_accuracy: 0.7989\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.8062 - val_loss: 0.4470 - val_accuracy: 0.7989\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.8216 - val_loss: 0.4387 - val_accuracy: 0.7989\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.8006 - val_loss: 0.4619 - val_accuracy: 0.7765\n",
      "Epoch 20/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.8090 - val_loss: 0.4367 - val_accuracy: 0.8101\n",
      "Epoch 21/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8174 - val_loss: 0.4500 - val_accuracy: 0.7821\n",
      "Epoch 22/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.8104 - val_loss: 0.4296 - val_accuracy: 0.8101\n",
      "Epoch 23/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.8202 - val_loss: 0.4332 - val_accuracy: 0.7654\n",
      "Epoch 24/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.8132 - val_loss: 0.4513 - val_accuracy: 0.8045\n",
      "Epoch 25/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.8104 - val_loss: 0.4452 - val_accuracy: 0.8101\n",
      "Epoch 26/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8118 - val_loss: 0.4481 - val_accuracy: 0.7933\n",
      "Epoch 27/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8272 - val_loss: 0.4420 - val_accuracy: 0.7821\n",
      "Epoch 28/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4026 - accuracy: 0.8216 - val_loss: 0.4249 - val_accuracy: 0.7989\n",
      "Epoch 29/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3917 - accuracy: 0.8287 - val_loss: 0.4593 - val_accuracy: 0.7989\n",
      "Epoch 30/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8287 - val_loss: 0.4380 - val_accuracy: 0.8045\n",
      "Epoch 31/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8329 - val_loss: 0.4345 - val_accuracy: 0.8045\n",
      "Epoch 32/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8244 - val_loss: 0.4508 - val_accuracy: 0.7933\n",
      "Epoch 33/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8230 - val_loss: 0.4595 - val_accuracy: 0.7821\n",
      "Epoch 34/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8287 - val_loss: 0.4892 - val_accuracy: 0.7821\n",
      "Epoch 35/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8244 - val_loss: 0.4785 - val_accuracy: 0.7709\n",
      "Epoch 36/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8301 - val_loss: 0.4314 - val_accuracy: 0.7989\n",
      "Epoch 37/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8287 - val_loss: 0.4460 - val_accuracy: 0.8045\n",
      "Epoch 38/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8287 - val_loss: 0.4335 - val_accuracy: 0.8045\n",
      "Epoch 39/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.8329 - val_loss: 0.4398 - val_accuracy: 0.8045\n",
      "Epoch 40/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.8287 - val_loss: 0.4566 - val_accuracy: 0.8045\n",
      "Epoch 41/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8357 - val_loss: 0.4444 - val_accuracy: 0.7877\n",
      "Epoch 42/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8329 - val_loss: 0.4512 - val_accuracy: 0.7989\n",
      "Epoch 43/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8202 - val_loss: 0.4407 - val_accuracy: 0.7877\n",
      "Epoch 44/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8399 - val_loss: 0.4513 - val_accuracy: 0.7933\n",
      "Epoch 45/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8385 - val_loss: 0.4412 - val_accuracy: 0.8045\n",
      "Epoch 46/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8287 - val_loss: 0.5483 - val_accuracy: 0.7933\n",
      "Epoch 47/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8371 - val_loss: 0.4507 - val_accuracy: 0.8045\n",
      "Epoch 48/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8371 - val_loss: 0.4599 - val_accuracy: 0.7877\n",
      "Epoch 49/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.8216 - val_loss: 0.4492 - val_accuracy: 0.7989\n",
      "Epoch 50/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8427 - val_loss: 0.4738 - val_accuracy: 0.7877\n",
      "Epoch 51/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8216 - val_loss: 0.4422 - val_accuracy: 0.8045\n",
      "Epoch 52/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8343 - val_loss: 0.4586 - val_accuracy: 0.8212\n",
      "Epoch 53/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3620 - accuracy: 0.8399 - val_loss: 0.4486 - val_accuracy: 0.8045\n",
      "Epoch 54/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3580 - accuracy: 0.8427 - val_loss: 0.4644 - val_accuracy: 0.7989\n",
      "Epoch 55/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.8455 - val_loss: 0.4679 - val_accuracy: 0.7877\n",
      "Epoch 56/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3607 - accuracy: 0.8413 - val_loss: 0.4764 - val_accuracy: 0.7933\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3658 - accuracy: 0.8427 - val_loss: 0.4597 - val_accuracy: 0.8045\n",
      "Epoch 58/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3584 - accuracy: 0.8469 - val_loss: 0.4492 - val_accuracy: 0.7989\n",
      "Epoch 59/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3434 - accuracy: 0.8581 - val_loss: 0.4521 - val_accuracy: 0.7989\n",
      "Epoch 60/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3415 - accuracy: 0.8539 - val_loss: 0.4449 - val_accuracy: 0.7933\n",
      "Epoch 61/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3438 - accuracy: 0.8511 - val_loss: 0.4453 - val_accuracy: 0.7989\n",
      "Epoch 62/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.8581 - val_loss: 0.4385 - val_accuracy: 0.7989\n",
      "Epoch 63/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3426 - accuracy: 0.8483 - val_loss: 0.4534 - val_accuracy: 0.8045\n",
      "Epoch 64/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3440 - accuracy: 0.8567 - val_loss: 0.4542 - val_accuracy: 0.7989\n",
      "Epoch 65/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3498 - accuracy: 0.8483 - val_loss: 0.4648 - val_accuracy: 0.7877\n",
      "Epoch 66/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.8596 - val_loss: 0.4620 - val_accuracy: 0.7877\n",
      "Epoch 67/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3459 - accuracy: 0.8511 - val_loss: 0.4848 - val_accuracy: 0.7877\n",
      "Epoch 68/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3394 - accuracy: 0.8525 - val_loss: 0.4993 - val_accuracy: 0.7989\n",
      "Epoch 69/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.8596 - val_loss: 0.4819 - val_accuracy: 0.7933\n",
      "Epoch 70/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3311 - accuracy: 0.8624 - val_loss: 0.4657 - val_accuracy: 0.8045\n",
      "Epoch 71/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3222 - accuracy: 0.8652 - val_loss: 0.4782 - val_accuracy: 0.7877\n",
      "Epoch 72/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8427 - val_loss: 0.4853 - val_accuracy: 0.8045\n",
      "Epoch 73/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3315 - accuracy: 0.8610 - val_loss: 0.4680 - val_accuracy: 0.7933\n",
      "Epoch 74/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3383 - accuracy: 0.8553 - val_loss: 0.4974 - val_accuracy: 0.8045\n",
      "Epoch 75/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8666 - val_loss: 0.4724 - val_accuracy: 0.8045\n",
      "Epoch 76/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8652 - val_loss: 0.4699 - val_accuracy: 0.8045\n",
      "Epoch 77/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3204 - accuracy: 0.8624 - val_loss: 0.4713 - val_accuracy: 0.8101\n",
      "Epoch 78/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3269 - accuracy: 0.8638 - val_loss: 0.4718 - val_accuracy: 0.7989\n",
      "Epoch 79/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3141 - accuracy: 0.8666 - val_loss: 0.4898 - val_accuracy: 0.8045\n",
      "Epoch 80/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3221 - accuracy: 0.8638 - val_loss: 0.4970 - val_accuracy: 0.7989\n",
      "Epoch 81/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3162 - accuracy: 0.8694 - val_loss: 0.5085 - val_accuracy: 0.7989\n",
      "Epoch 82/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3294 - accuracy: 0.8581 - val_loss: 0.5419 - val_accuracy: 0.7933\n",
      "Epoch 83/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3292 - accuracy: 0.8596 - val_loss: 0.4796 - val_accuracy: 0.7877\n",
      "Epoch 84/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3382 - accuracy: 0.8624 - val_loss: 0.5310 - val_accuracy: 0.7877\n",
      "Epoch 85/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.8287 - val_loss: 0.5114 - val_accuracy: 0.8101\n",
      "Epoch 86/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3574 - accuracy: 0.8624 - val_loss: 0.4582 - val_accuracy: 0.7989\n",
      "Epoch 87/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3674 - accuracy: 0.8441 - val_loss: 0.4775 - val_accuracy: 0.7989\n",
      "Epoch 88/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3125 - accuracy: 0.8666 - val_loss: 0.4889 - val_accuracy: 0.7989\n",
      "Epoch 89/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3325 - accuracy: 0.8652 - val_loss: 0.4948 - val_accuracy: 0.8045\n",
      "Epoch 90/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3371 - accuracy: 0.8624 - val_loss: 0.5155 - val_accuracy: 0.7877\n",
      "Epoch 91/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.8694 - val_loss: 0.5165 - val_accuracy: 0.7933\n",
      "Epoch 92/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3032 - accuracy: 0.8666 - val_loss: 0.5196 - val_accuracy: 0.7821\n",
      "Epoch 93/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3040 - accuracy: 0.8596 - val_loss: 0.5354 - val_accuracy: 0.7933\n",
      "Epoch 94/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3179 - accuracy: 0.8680 - val_loss: 0.5125 - val_accuracy: 0.7877\n",
      "Epoch 95/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3150 - accuracy: 0.8666 - val_loss: 0.5599 - val_accuracy: 0.7989\n",
      "Epoch 96/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3057 - accuracy: 0.8652 - val_loss: 0.5066 - val_accuracy: 0.7877\n",
      "Epoch 97/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2956 - accuracy: 0.8680 - val_loss: 0.5424 - val_accuracy: 0.7877\n",
      "Epoch 98/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2912 - accuracy: 0.8834 - val_loss: 0.5307 - val_accuracy: 0.7989\n",
      "Epoch 99/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2967 - accuracy: 0.8722 - val_loss: 0.5738 - val_accuracy: 0.7821\n",
      "Epoch 100/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3052 - accuracy: 0.8764 - val_loss: 0.5159 - val_accuracy: 0.7933\n",
      "Epoch 101/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2923 - accuracy: 0.8708 - val_loss: 0.5235 - val_accuracy: 0.8101\n",
      "Epoch 102/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2945 - accuracy: 0.8750 - val_loss: 0.5228 - val_accuracy: 0.7933\n",
      "Epoch 103/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2876 - accuracy: 0.8764 - val_loss: 0.5297 - val_accuracy: 0.7821\n",
      "Epoch 104/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2770 - accuracy: 0.8722 - val_loss: 0.5460 - val_accuracy: 0.7877\n",
      "Epoch 105/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2953 - accuracy: 0.8708 - val_loss: 0.5564 - val_accuracy: 0.7933\n",
      "Epoch 106/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2884 - accuracy: 0.8764 - val_loss: 0.6176 - val_accuracy: 0.7933\n",
      "Epoch 107/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2933 - accuracy: 0.8750 - val_loss: 0.5331 - val_accuracy: 0.7821\n",
      "Epoch 108/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2848 - accuracy: 0.8806 - val_loss: 0.5882 - val_accuracy: 0.7877\n",
      "Epoch 109/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3113 - accuracy: 0.8708 - val_loss: 0.5555 - val_accuracy: 0.7821\n",
      "Epoch 110/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8610 - val_loss: 0.5779 - val_accuracy: 0.7821\n",
      "Epoch 111/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2916 - accuracy: 0.8708 - val_loss: 0.5964 - val_accuracy: 0.7989\n",
      "Epoch 112/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2802 - accuracy: 0.8750 - val_loss: 0.6209 - val_accuracy: 0.7821\n",
      "Epoch 113/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2735 - accuracy: 0.8680 - val_loss: 0.6177 - val_accuracy: 0.7821\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2781 - accuracy: 0.8750 - val_loss: 0.5914 - val_accuracy: 0.7877\n",
      "Epoch 115/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2832 - accuracy: 0.8778 - val_loss: 0.6054 - val_accuracy: 0.7765\n",
      "Epoch 116/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2836 - accuracy: 0.8722 - val_loss: 0.6138 - val_accuracy: 0.7933\n",
      "Epoch 117/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2813 - accuracy: 0.8736 - val_loss: 0.6214 - val_accuracy: 0.7933\n",
      "Epoch 118/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2689 - accuracy: 0.8806 - val_loss: 0.6078 - val_accuracy: 0.7989\n",
      "Epoch 119/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2754 - accuracy: 0.8764 - val_loss: 0.6014 - val_accuracy: 0.7877\n",
      "Epoch 120/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2671 - accuracy: 0.8919 - val_loss: 0.5747 - val_accuracy: 0.7933\n",
      "Epoch 121/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2698 - accuracy: 0.8806 - val_loss: 0.5661 - val_accuracy: 0.7933\n",
      "Epoch 122/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2712 - accuracy: 0.8848 - val_loss: 0.6217 - val_accuracy: 0.7821\n",
      "Epoch 123/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2629 - accuracy: 0.8961 - val_loss: 0.6123 - val_accuracy: 0.7877\n",
      "Epoch 124/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2639 - accuracy: 0.8834 - val_loss: 0.6611 - val_accuracy: 0.7877\n",
      "Epoch 125/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2723 - accuracy: 0.8820 - val_loss: 0.6280 - val_accuracy: 0.7933\n",
      "Epoch 126/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2647 - accuracy: 0.8834 - val_loss: 0.6133 - val_accuracy: 0.7765\n",
      "Epoch 127/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.5966 - accuracy: 0.8202 - val_loss: 0.6770 - val_accuracy: 0.8045\n",
      "Epoch 128/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3077 - accuracy: 0.8820 - val_loss: 0.5639 - val_accuracy: 0.7765\n",
      "Epoch 129/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2751 - accuracy: 0.8890 - val_loss: 0.5770 - val_accuracy: 0.7877\n",
      "Epoch 130/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2636 - accuracy: 0.8778 - val_loss: 0.6182 - val_accuracy: 0.7877\n",
      "Epoch 131/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2594 - accuracy: 0.8904 - val_loss: 0.6775 - val_accuracy: 0.7821\n",
      "Epoch 132/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2614 - accuracy: 0.8904 - val_loss: 0.6378 - val_accuracy: 0.7765\n",
      "Epoch 133/1000\n",
      "23/23 [==============================] - 1s 30ms/step - loss: 0.2646 - accuracy: 0.8904 - val_loss: 0.6100 - val_accuracy: 0.7877\n",
      "Epoch 134/1000\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.2665 - accuracy: 0.8806 - val_loss: 0.5949 - val_accuracy: 0.7877\n",
      "Epoch 135/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2500 - accuracy: 0.8919 - val_loss: 0.6361 - val_accuracy: 0.7877\n",
      "Epoch 136/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2581 - accuracy: 0.8933 - val_loss: 0.6192 - val_accuracy: 0.7989\n",
      "Epoch 137/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2504 - accuracy: 0.8904 - val_loss: 0.6691 - val_accuracy: 0.7821\n",
      "Epoch 138/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2581 - accuracy: 0.8989 - val_loss: 0.6244 - val_accuracy: 0.7933\n",
      "Epoch 139/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2534 - accuracy: 0.8890 - val_loss: 0.6483 - val_accuracy: 0.7933\n",
      "Epoch 140/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2781 - accuracy: 0.8792 - val_loss: 0.7135 - val_accuracy: 0.7877\n",
      "Epoch 141/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2646 - accuracy: 0.8778 - val_loss: 0.6756 - val_accuracy: 0.7765\n",
      "Epoch 142/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2437 - accuracy: 0.8961 - val_loss: 0.6508 - val_accuracy: 0.7877\n",
      "Epoch 143/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2486 - accuracy: 0.8933 - val_loss: 0.6688 - val_accuracy: 0.7821\n",
      "Epoch 144/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2521 - accuracy: 0.8933 - val_loss: 0.6661 - val_accuracy: 0.7877\n",
      "Epoch 145/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2605 - accuracy: 0.8919 - val_loss: 0.6817 - val_accuracy: 0.7821\n",
      "Epoch 146/1000\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.2483 - accuracy: 0.8989 - val_loss: 0.6932 - val_accuracy: 0.7989\n",
      "Epoch 147/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2474 - accuracy: 0.8904 - val_loss: 0.6925 - val_accuracy: 0.7877\n",
      "Epoch 148/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2435 - accuracy: 0.8947 - val_loss: 0.7052 - val_accuracy: 0.7765\n",
      "Epoch 149/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2468 - accuracy: 0.8947 - val_loss: 0.7218 - val_accuracy: 0.7877\n",
      "Epoch 150/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2357 - accuracy: 0.9087 - val_loss: 0.6782 - val_accuracy: 0.7933\n",
      "Epoch 151/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2414 - accuracy: 0.9087 - val_loss: 0.6629 - val_accuracy: 0.7877\n",
      "Epoch 152/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2463 - accuracy: 0.8975 - val_loss: 0.6786 - val_accuracy: 0.7933\n",
      "Epoch 153/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2344 - accuracy: 0.8961 - val_loss: 0.7179 - val_accuracy: 0.7877\n",
      "Epoch 154/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2540 - accuracy: 0.8890 - val_loss: 0.7176 - val_accuracy: 0.7877\n",
      "Epoch 155/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2486 - accuracy: 0.8961 - val_loss: 0.6941 - val_accuracy: 0.7821\n",
      "Epoch 156/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2434 - accuracy: 0.9017 - val_loss: 0.7162 - val_accuracy: 0.7765\n",
      "Epoch 157/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2385 - accuracy: 0.9073 - val_loss: 0.6813 - val_accuracy: 0.7933\n",
      "Epoch 158/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2349 - accuracy: 0.9031 - val_loss: 0.7144 - val_accuracy: 0.7989\n",
      "Epoch 159/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2330 - accuracy: 0.9017 - val_loss: 0.7155 - val_accuracy: 0.7933\n",
      "Epoch 160/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2369 - accuracy: 0.9031 - val_loss: 0.7153 - val_accuracy: 0.7933\n",
      "Epoch 161/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2370 - accuracy: 0.8933 - val_loss: 0.7569 - val_accuracy: 0.7821\n",
      "Epoch 162/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2453 - accuracy: 0.8947 - val_loss: 0.7168 - val_accuracy: 0.7877\n",
      "Epoch 163/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3001 - accuracy: 0.8806 - val_loss: 0.7176 - val_accuracy: 0.7989\n",
      "Epoch 164/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2416 - accuracy: 0.9073 - val_loss: 0.7045 - val_accuracy: 0.7821\n",
      "Epoch 165/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2314 - accuracy: 0.9059 - val_loss: 0.7598 - val_accuracy: 0.7821\n",
      "Epoch 166/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2306 - accuracy: 0.9087 - val_loss: 0.7390 - val_accuracy: 0.7821\n",
      "Epoch 167/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2318 - accuracy: 0.9003 - val_loss: 0.8055 - val_accuracy: 0.7821\n",
      "Epoch 168/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2345 - accuracy: 0.8961 - val_loss: 0.7203 - val_accuracy: 0.7821\n",
      "Epoch 169/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2258 - accuracy: 0.9087 - val_loss: 0.7131 - val_accuracy: 0.7933\n",
      "Epoch 170/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2279 - accuracy: 0.9073 - val_loss: 0.7619 - val_accuracy: 0.7933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2417 - accuracy: 0.8919 - val_loss: 0.7809 - val_accuracy: 0.7821\n",
      "Epoch 172/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2309 - accuracy: 0.9087 - val_loss: 0.7572 - val_accuracy: 0.7933\n",
      "Epoch 173/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2415 - accuracy: 0.9059 - val_loss: 0.7790 - val_accuracy: 0.7709\n",
      "Epoch 174/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.8834 - val_loss: 0.7833 - val_accuracy: 0.7933\n",
      "Epoch 175/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2308 - accuracy: 0.9101 - val_loss: 0.7757 - val_accuracy: 0.7877\n",
      "Epoch 176/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.9003 - val_loss: 0.7789 - val_accuracy: 0.7877\n",
      "Epoch 177/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2231 - accuracy: 0.9073 - val_loss: 0.7864 - val_accuracy: 0.7933\n",
      "Epoch 178/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2275 - accuracy: 0.9101 - val_loss: 0.7885 - val_accuracy: 0.7877\n",
      "Epoch 179/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2291 - accuracy: 0.9101 - val_loss: 0.7648 - val_accuracy: 0.7765\n",
      "Epoch 180/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9031 - val_loss: 0.8121 - val_accuracy: 0.7821\n",
      "Epoch 181/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2196 - accuracy: 0.9073 - val_loss: 0.8276 - val_accuracy: 0.7877\n",
      "Epoch 182/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2394 - accuracy: 0.8919 - val_loss: 0.7818 - val_accuracy: 0.7989\n",
      "Epoch 183/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2734 - accuracy: 0.8834 - val_loss: 0.7808 - val_accuracy: 0.7989\n",
      "Epoch 184/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.8624 - val_loss: 0.9361 - val_accuracy: 0.7765\n",
      "Epoch 185/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2845 - accuracy: 0.8722 - val_loss: 0.7387 - val_accuracy: 0.7877\n",
      "Epoch 186/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2435 - accuracy: 0.8975 - val_loss: 0.7703 - val_accuracy: 0.7821\n",
      "Epoch 187/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2255 - accuracy: 0.9087 - val_loss: 0.7894 - val_accuracy: 0.7933\n",
      "Epoch 188/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2203 - accuracy: 0.9185 - val_loss: 0.7453 - val_accuracy: 0.7877\n",
      "Epoch 189/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2119 - accuracy: 0.9129 - val_loss: 0.8093 - val_accuracy: 0.7933\n",
      "Epoch 190/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2199 - accuracy: 0.9115 - val_loss: 0.8249 - val_accuracy: 0.7821\n",
      "Epoch 191/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2151 - accuracy: 0.9157 - val_loss: 0.7941 - val_accuracy: 0.8045\n",
      "Epoch 192/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2121 - accuracy: 0.9143 - val_loss: 0.8718 - val_accuracy: 0.7821\n",
      "Epoch 193/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2196 - accuracy: 0.9157 - val_loss: 0.8239 - val_accuracy: 0.7765\n",
      "Epoch 194/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2089 - accuracy: 0.9157 - val_loss: 0.8160 - val_accuracy: 0.8045\n",
      "Epoch 195/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2110 - accuracy: 0.9199 - val_loss: 0.8381 - val_accuracy: 0.7933\n",
      "Epoch 196/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2079 - accuracy: 0.9157 - val_loss: 0.7882 - val_accuracy: 0.7989\n",
      "Epoch 197/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2052 - accuracy: 0.9171 - val_loss: 0.8332 - val_accuracy: 0.7933\n",
      "Epoch 198/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2100 - accuracy: 0.9199 - val_loss: 0.8469 - val_accuracy: 0.7933\n",
      "Epoch 199/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2088 - accuracy: 0.9129 - val_loss: 0.8243 - val_accuracy: 0.7933\n",
      "Epoch 200/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2139 - accuracy: 0.9171 - val_loss: 0.8202 - val_accuracy: 0.7877\n",
      "Epoch 201/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2164 - accuracy: 0.9228 - val_loss: 0.8300 - val_accuracy: 0.7821\n",
      "Epoch 202/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2133 - accuracy: 0.9115 - val_loss: 0.7981 - val_accuracy: 0.7877\n",
      "Epoch 203/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2034 - accuracy: 0.9228 - val_loss: 0.8228 - val_accuracy: 0.7877\n",
      "Epoch 204/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2025 - accuracy: 0.9242 - val_loss: 0.8827 - val_accuracy: 0.7989\n",
      "Epoch 205/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2053 - accuracy: 0.9171 - val_loss: 0.8103 - val_accuracy: 0.7933\n",
      "Epoch 206/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2069 - accuracy: 0.9143 - val_loss: 0.8343 - val_accuracy: 0.7821\n",
      "Epoch 207/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2018 - accuracy: 0.9298 - val_loss: 0.8730 - val_accuracy: 0.7933\n",
      "Epoch 208/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2104 - accuracy: 0.9129 - val_loss: 0.8056 - val_accuracy: 0.7877\n",
      "Epoch 209/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2025 - accuracy: 0.9256 - val_loss: 0.8400 - val_accuracy: 0.7877\n",
      "Epoch 210/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1998 - accuracy: 0.9284 - val_loss: 0.9536 - val_accuracy: 0.7821\n",
      "Epoch 211/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2006 - accuracy: 0.9228 - val_loss: 0.9121 - val_accuracy: 0.7877\n",
      "Epoch 212/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2023 - accuracy: 0.9256 - val_loss: 0.8980 - val_accuracy: 0.7821\n",
      "Epoch 213/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2067 - accuracy: 0.9228 - val_loss: 0.8807 - val_accuracy: 0.7989\n",
      "Epoch 214/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2008 - accuracy: 0.9242 - val_loss: 0.9159 - val_accuracy: 0.7933\n",
      "Epoch 215/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1955 - accuracy: 0.9340 - val_loss: 0.8435 - val_accuracy: 0.7654\n",
      "Epoch 216/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2030 - accuracy: 0.9228 - val_loss: 0.9036 - val_accuracy: 0.7821\n",
      "Epoch 217/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1944 - accuracy: 0.9270 - val_loss: 0.9044 - val_accuracy: 0.7877\n",
      "Epoch 218/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1964 - accuracy: 0.9284 - val_loss: 0.8948 - val_accuracy: 0.7877\n",
      "Epoch 219/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2079 - accuracy: 0.9213 - val_loss: 0.9314 - val_accuracy: 0.7542\n",
      "Epoch 220/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1989 - accuracy: 0.9270 - val_loss: 0.9002 - val_accuracy: 0.7821\n",
      "Epoch 221/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9171 - val_loss: 0.9333 - val_accuracy: 0.7821\n",
      "Epoch 222/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1912 - accuracy: 0.9326 - val_loss: 0.8799 - val_accuracy: 0.7877\n",
      "Epoch 223/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1986 - accuracy: 0.9284 - val_loss: 0.9598 - val_accuracy: 0.7877\n",
      "Epoch 224/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2042 - accuracy: 0.9185 - val_loss: 0.9292 - val_accuracy: 0.7877\n",
      "Epoch 225/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2015 - accuracy: 0.9242 - val_loss: 0.9184 - val_accuracy: 0.7821\n",
      "Epoch 226/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2912 - accuracy: 0.9031 - val_loss: 0.9357 - val_accuracy: 0.7877\n",
      "Epoch 227/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2051 - accuracy: 0.9213 - val_loss: 0.9885 - val_accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1946 - accuracy: 0.9157 - val_loss: 0.9160 - val_accuracy: 0.7989\n",
      "Epoch 229/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.9228 - val_loss: 0.9218 - val_accuracy: 0.7542\n",
      "Epoch 230/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1941 - accuracy: 0.9354 - val_loss: 0.9123 - val_accuracy: 0.7933\n",
      "Epoch 231/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1921 - accuracy: 0.9242 - val_loss: 0.8907 - val_accuracy: 0.7765\n",
      "Epoch 232/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1927 - accuracy: 0.9256 - val_loss: 0.9428 - val_accuracy: 0.7821\n",
      "Epoch 233/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2006 - accuracy: 0.9143 - val_loss: 0.8831 - val_accuracy: 0.7654\n",
      "Epoch 234/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1953 - accuracy: 0.9242 - val_loss: 0.9669 - val_accuracy: 0.7765\n",
      "Epoch 235/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2158 - accuracy: 0.9185 - val_loss: 1.0461 - val_accuracy: 0.7877\n",
      "Epoch 236/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1931 - accuracy: 0.9298 - val_loss: 0.9334 - val_accuracy: 0.7933\n",
      "Epoch 237/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1893 - accuracy: 0.9256 - val_loss: 0.9882 - val_accuracy: 0.7877\n",
      "Epoch 238/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9270 - val_loss: 0.9682 - val_accuracy: 0.7765\n",
      "Epoch 239/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.9340 - val_loss: 0.9221 - val_accuracy: 0.7877\n",
      "Epoch 240/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1784 - accuracy: 0.9326 - val_loss: 0.9621 - val_accuracy: 0.7877\n",
      "Epoch 241/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1799 - accuracy: 0.9326 - val_loss: 0.9937 - val_accuracy: 0.7821\n",
      "Epoch 242/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.9270 - val_loss: 1.0080 - val_accuracy: 0.7821\n",
      "Epoch 243/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1780 - accuracy: 0.9284 - val_loss: 0.9882 - val_accuracy: 0.7877\n",
      "Epoch 244/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1863 - accuracy: 0.9256 - val_loss: 0.9654 - val_accuracy: 0.7821\n",
      "Epoch 245/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1904 - accuracy: 0.9312 - val_loss: 0.9934 - val_accuracy: 0.7765\n",
      "Epoch 246/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2146 - accuracy: 0.9242 - val_loss: 0.9877 - val_accuracy: 0.7654\n",
      "Epoch 247/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1923 - accuracy: 0.9256 - val_loss: 0.9932 - val_accuracy: 0.7821\n",
      "Epoch 248/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1857 - accuracy: 0.9312 - val_loss: 0.9423 - val_accuracy: 0.7821\n",
      "Epoch 249/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1796 - accuracy: 0.9354 - val_loss: 0.9569 - val_accuracy: 0.7877\n",
      "Epoch 250/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1841 - accuracy: 0.9284 - val_loss: 1.0053 - val_accuracy: 0.7709\n",
      "Epoch 251/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9368 - val_loss: 1.0025 - val_accuracy: 0.7877\n",
      "Epoch 252/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1719 - accuracy: 0.9368 - val_loss: 0.9850 - val_accuracy: 0.7933\n",
      "Epoch 253/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1782 - accuracy: 0.9354 - val_loss: 1.0505 - val_accuracy: 0.7654\n",
      "Epoch 254/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1787 - accuracy: 0.9326 - val_loss: 0.9950 - val_accuracy: 0.7765\n",
      "Epoch 255/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1831 - accuracy: 0.9326 - val_loss: 1.0357 - val_accuracy: 0.7542\n",
      "Epoch 256/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1793 - accuracy: 0.9270 - val_loss: 0.9899 - val_accuracy: 0.7598\n",
      "Epoch 257/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1897 - accuracy: 0.9284 - val_loss: 1.0067 - val_accuracy: 0.7709\n",
      "Epoch 258/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1816 - accuracy: 0.9312 - val_loss: 1.1043 - val_accuracy: 0.7430\n",
      "Epoch 259/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9284 - val_loss: 1.1264 - val_accuracy: 0.7709\n",
      "Epoch 260/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1887 - accuracy: 0.9242 - val_loss: 1.2428 - val_accuracy: 0.7765\n",
      "Epoch 261/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1807 - accuracy: 0.9312 - val_loss: 1.0651 - val_accuracy: 0.7765\n",
      "Epoch 262/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1769 - accuracy: 0.9340 - val_loss: 1.1444 - val_accuracy: 0.7877\n",
      "Epoch 263/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1676 - accuracy: 0.9410 - val_loss: 1.3700 - val_accuracy: 0.7821\n",
      "Epoch 264/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1681 - accuracy: 0.9410 - val_loss: 1.1637 - val_accuracy: 0.7821\n",
      "Epoch 265/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9340 - val_loss: 1.0960 - val_accuracy: 0.7709\n",
      "Epoch 266/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9382 - val_loss: 1.0961 - val_accuracy: 0.7709\n",
      "Epoch 267/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1732 - accuracy: 0.9340 - val_loss: 1.1820 - val_accuracy: 0.7821\n",
      "Epoch 268/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1787 - accuracy: 0.9340 - val_loss: 1.2441 - val_accuracy: 0.7933\n",
      "Epoch 269/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1762 - accuracy: 0.9382 - val_loss: 1.1012 - val_accuracy: 0.7654\n",
      "Epoch 270/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1719 - accuracy: 0.9410 - val_loss: 1.1287 - val_accuracy: 0.7821\n",
      "Epoch 271/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1725 - accuracy: 0.9354 - val_loss: 1.1035 - val_accuracy: 0.7709\n",
      "Epoch 272/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1614 - accuracy: 0.9410 - val_loss: 1.1121 - val_accuracy: 0.7821\n",
      "Epoch 273/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1628 - accuracy: 0.9382 - val_loss: 1.1701 - val_accuracy: 0.7542\n",
      "Epoch 274/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1683 - accuracy: 0.9396 - val_loss: 1.1008 - val_accuracy: 0.7654\n",
      "Epoch 275/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.9396 - val_loss: 1.0824 - val_accuracy: 0.7877\n",
      "Epoch 276/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.9368 - val_loss: 1.1626 - val_accuracy: 0.7877\n",
      "Epoch 277/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1654 - accuracy: 0.9396 - val_loss: 1.1839 - val_accuracy: 0.7877\n",
      "Epoch 278/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1631 - accuracy: 0.9410 - val_loss: 1.1576 - val_accuracy: 0.7821\n",
      "Epoch 279/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1673 - accuracy: 0.9410 - val_loss: 1.1624 - val_accuracy: 0.7765\n",
      "Epoch 280/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1623 - accuracy: 0.9396 - val_loss: 1.1826 - val_accuracy: 0.7877\n",
      "Epoch 281/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.9438 - val_loss: 1.1612 - val_accuracy: 0.7765\n",
      "Epoch 282/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.9354 - val_loss: 1.2817 - val_accuracy: 0.7486\n",
      "Epoch 283/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9326 - val_loss: 1.3113 - val_accuracy: 0.7821\n",
      "Epoch 284/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.9396 - val_loss: 1.1389 - val_accuracy: 0.7877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1672 - accuracy: 0.9438 - val_loss: 1.1370 - val_accuracy: 0.7765\n",
      "Epoch 286/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1552 - accuracy: 0.9438 - val_loss: 1.2789 - val_accuracy: 0.7877\n",
      "Epoch 287/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1593 - accuracy: 0.9396 - val_loss: 1.1703 - val_accuracy: 0.7765\n",
      "Epoch 288/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1594 - accuracy: 0.9466 - val_loss: 1.3116 - val_accuracy: 0.7765\n",
      "Epoch 289/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1620 - accuracy: 0.9438 - val_loss: 1.1816 - val_accuracy: 0.7486\n",
      "Epoch 290/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1731 - accuracy: 0.9340 - val_loss: 1.2721 - val_accuracy: 0.7765\n",
      "Epoch 291/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9466 - val_loss: 1.1936 - val_accuracy: 0.7877\n",
      "Epoch 292/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1647 - accuracy: 0.9452 - val_loss: 1.1967 - val_accuracy: 0.7765\n",
      "Epoch 293/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.9466 - val_loss: 1.2121 - val_accuracy: 0.7765\n",
      "Epoch 294/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1565 - accuracy: 0.9396 - val_loss: 1.2047 - val_accuracy: 0.7821\n",
      "Epoch 295/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9452 - val_loss: 1.2341 - val_accuracy: 0.7765\n",
      "Epoch 296/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.9452 - val_loss: 1.2318 - val_accuracy: 0.7709\n",
      "Epoch 297/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1539 - accuracy: 0.9424 - val_loss: 1.1946 - val_accuracy: 0.7709\n",
      "Epoch 298/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.9438 - val_loss: 1.2081 - val_accuracy: 0.7486\n",
      "Epoch 299/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1634 - accuracy: 0.9368 - val_loss: 1.3581 - val_accuracy: 0.7542\n",
      "Epoch 300/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1688 - accuracy: 0.9368 - val_loss: 1.2517 - val_accuracy: 0.7821\n",
      "Epoch 301/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.9354 - val_loss: 1.2912 - val_accuracy: 0.7542\n",
      "Epoch 302/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1600 - accuracy: 0.9382 - val_loss: 1.1744 - val_accuracy: 0.7654\n",
      "Epoch 303/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1512 - accuracy: 0.9466 - val_loss: 1.2163 - val_accuracy: 0.7654\n",
      "Epoch 304/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9480 - val_loss: 1.2937 - val_accuracy: 0.7542\n",
      "Epoch 305/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.9480 - val_loss: 1.2529 - val_accuracy: 0.7654\n",
      "Epoch 306/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2047 - accuracy: 0.9326 - val_loss: 1.2274 - val_accuracy: 0.7598\n",
      "Epoch 307/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1826 - accuracy: 0.9228 - val_loss: 1.2812 - val_accuracy: 0.7654\n",
      "Epoch 308/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1829 - accuracy: 0.9382 - val_loss: 1.2378 - val_accuracy: 0.7542\n",
      "Epoch 309/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1656 - accuracy: 0.9340 - val_loss: 1.2306 - val_accuracy: 0.7598\n",
      "Epoch 310/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1556 - accuracy: 0.9410 - val_loss: 1.2736 - val_accuracy: 0.7598\n",
      "Epoch 311/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1411 - accuracy: 0.9424 - val_loss: 1.2289 - val_accuracy: 0.7542\n",
      "Epoch 312/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1522 - accuracy: 0.9382 - val_loss: 1.2301 - val_accuracy: 0.7709\n",
      "Epoch 313/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1474 - accuracy: 0.9522 - val_loss: 1.3881 - val_accuracy: 0.7709\n",
      "Epoch 314/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1425 - accuracy: 0.9480 - val_loss: 1.2706 - val_accuracy: 0.7654\n",
      "Epoch 315/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1571 - accuracy: 0.9410 - val_loss: 1.3570 - val_accuracy: 0.7765\n",
      "Epoch 316/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1524 - accuracy: 0.9438 - val_loss: 1.2411 - val_accuracy: 0.7709\n",
      "Epoch 317/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1581 - accuracy: 0.9382 - val_loss: 1.3626 - val_accuracy: 0.7821\n",
      "Epoch 318/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1535 - accuracy: 0.9494 - val_loss: 1.3128 - val_accuracy: 0.7821\n",
      "Epoch 319/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1536 - accuracy: 0.9438 - val_loss: 1.3727 - val_accuracy: 0.7709\n",
      "Epoch 320/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1421 - accuracy: 0.9494 - val_loss: 1.3284 - val_accuracy: 0.7709\n",
      "Epoch 321/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1475 - accuracy: 0.9438 - val_loss: 1.3099 - val_accuracy: 0.7821\n",
      "Epoch 322/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1496 - accuracy: 0.9480 - val_loss: 1.3230 - val_accuracy: 0.7765\n",
      "Epoch 323/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9452 - val_loss: 1.3000 - val_accuracy: 0.7654\n",
      "Epoch 324/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1505 - accuracy: 0.9452 - val_loss: 1.2455 - val_accuracy: 0.7765\n",
      "Epoch 325/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.9452 - val_loss: 1.2708 - val_accuracy: 0.7654\n",
      "Epoch 326/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.9452 - val_loss: 1.3282 - val_accuracy: 0.7765\n",
      "Epoch 327/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1461 - accuracy: 0.9508 - val_loss: 1.3098 - val_accuracy: 0.7598\n",
      "Epoch 328/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1396 - accuracy: 0.9480 - val_loss: 1.2473 - val_accuracy: 0.7709\n",
      "Epoch 329/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1341 - accuracy: 0.9522 - val_loss: 1.3074 - val_accuracy: 0.7598\n",
      "Epoch 330/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1418 - accuracy: 0.9508 - val_loss: 1.3983 - val_accuracy: 0.7598\n",
      "Epoch 331/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1409 - accuracy: 0.9508 - val_loss: 1.3289 - val_accuracy: 0.7654\n",
      "Epoch 332/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1451 - accuracy: 0.9382 - val_loss: 1.3140 - val_accuracy: 0.7821\n",
      "Epoch 333/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1367 - accuracy: 0.9410 - val_loss: 1.4129 - val_accuracy: 0.7765\n",
      "Epoch 334/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9494 - val_loss: 1.4068 - val_accuracy: 0.7542\n",
      "Epoch 335/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1296 - accuracy: 0.9480 - val_loss: 1.3364 - val_accuracy: 0.7598\n",
      "Epoch 336/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1474 - accuracy: 0.9438 - val_loss: 1.4344 - val_accuracy: 0.7654\n",
      "Epoch 337/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9480 - val_loss: 1.4185 - val_accuracy: 0.7709\n",
      "Epoch 338/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9508 - val_loss: 1.4599 - val_accuracy: 0.7542\n",
      "Epoch 339/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.9466 - val_loss: 1.3858 - val_accuracy: 0.7486\n",
      "Epoch 340/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9466 - val_loss: 1.5194 - val_accuracy: 0.7765\n",
      "Epoch 341/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1333 - accuracy: 0.9508 - val_loss: 1.4219 - val_accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1408 - accuracy: 0.9466 - val_loss: 1.3767 - val_accuracy: 0.7654\n",
      "Epoch 343/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9494 - val_loss: 1.4353 - val_accuracy: 0.7709\n",
      "Epoch 344/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.9494 - val_loss: 1.3763 - val_accuracy: 0.7765\n",
      "Epoch 345/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9508 - val_loss: 1.3740 - val_accuracy: 0.7598\n",
      "Epoch 346/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1310 - accuracy: 0.9551 - val_loss: 1.4244 - val_accuracy: 0.7765\n",
      "Epoch 347/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9508 - val_loss: 1.4543 - val_accuracy: 0.7709\n",
      "Epoch 348/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1327 - accuracy: 0.9522 - val_loss: 1.3920 - val_accuracy: 0.7598\n",
      "Epoch 349/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1335 - accuracy: 0.9522 - val_loss: 1.4059 - val_accuracy: 0.7765\n",
      "Epoch 350/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9494 - val_loss: 1.4539 - val_accuracy: 0.7654\n",
      "Epoch 351/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1351 - accuracy: 0.9480 - val_loss: 1.4440 - val_accuracy: 0.7821\n",
      "Epoch 352/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.9565 - val_loss: 1.4532 - val_accuracy: 0.7654\n",
      "Epoch 353/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1386 - accuracy: 0.9466 - val_loss: 1.4149 - val_accuracy: 0.7821\n",
      "Epoch 354/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1377 - accuracy: 0.9452 - val_loss: 1.4236 - val_accuracy: 0.7709\n",
      "Epoch 355/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9522 - val_loss: 1.4893 - val_accuracy: 0.7430\n",
      "Epoch 356/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1318 - accuracy: 0.9522 - val_loss: 1.5563 - val_accuracy: 0.7765\n",
      "Epoch 357/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1330 - accuracy: 0.9452 - val_loss: 1.4718 - val_accuracy: 0.7709\n",
      "Epoch 358/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1324 - accuracy: 0.9466 - val_loss: 1.4702 - val_accuracy: 0.7765\n",
      "Epoch 359/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.9522 - val_loss: 1.5872 - val_accuracy: 0.7654\n",
      "Epoch 360/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.95 - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9522 - val_loss: 1.5758 - val_accuracy: 0.7709\n",
      "Epoch 361/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9537 - val_loss: 1.6257 - val_accuracy: 0.7654\n",
      "Epoch 362/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9508 - val_loss: 1.6290 - val_accuracy: 0.7765\n",
      "Epoch 363/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9508 - val_loss: 1.4931 - val_accuracy: 0.7765\n",
      "Epoch 364/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1298 - accuracy: 0.9480 - val_loss: 1.5289 - val_accuracy: 0.7654\n",
      "Epoch 365/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9537 - val_loss: 1.5602 - val_accuracy: 0.7765\n",
      "Epoch 366/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9424 - val_loss: 1.4837 - val_accuracy: 0.7263\n",
      "Epoch 367/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1232 - accuracy: 0.9579 - val_loss: 1.6320 - val_accuracy: 0.7821\n",
      "Epoch 368/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1268 - accuracy: 0.9508 - val_loss: 1.5862 - val_accuracy: 0.7709\n",
      "Epoch 369/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1337 - accuracy: 0.9396 - val_loss: 1.6040 - val_accuracy: 0.7709\n",
      "Epoch 370/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9508 - val_loss: 1.6975 - val_accuracy: 0.7765\n",
      "Epoch 371/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9466 - val_loss: 1.6762 - val_accuracy: 0.7821\n",
      "Epoch 372/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1324 - accuracy: 0.9508 - val_loss: 1.4941 - val_accuracy: 0.7709\n",
      "Epoch 373/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1283 - accuracy: 0.9480 - val_loss: 1.5108 - val_accuracy: 0.7598\n",
      "Epoch 374/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1533 - accuracy: 0.9368 - val_loss: 1.5284 - val_accuracy: 0.7709\n",
      "Epoch 375/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2644 - accuracy: 0.9115 - val_loss: 1.9453 - val_accuracy: 0.7709\n",
      "Epoch 376/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.9031 - val_loss: 1.7133 - val_accuracy: 0.7430\n",
      "Epoch 377/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3071 - accuracy: 0.9228 - val_loss: 1.6754 - val_accuracy: 0.7318\n",
      "Epoch 378/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1717 - accuracy: 0.9396 - val_loss: 1.4328 - val_accuracy: 0.7765\n",
      "Epoch 379/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9480 - val_loss: 1.4711 - val_accuracy: 0.7709\n",
      "Epoch 380/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1253 - accuracy: 0.9522 - val_loss: 1.4462 - val_accuracy: 0.7821\n",
      "Epoch 381/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1301 - accuracy: 0.9508 - val_loss: 1.4870 - val_accuracy: 0.7821\n",
      "Epoch 382/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.9537 - val_loss: 1.5017 - val_accuracy: 0.7821\n",
      "Epoch 383/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9565 - val_loss: 1.5513 - val_accuracy: 0.7709\n",
      "Epoch 384/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1258 - accuracy: 0.9508 - val_loss: 1.5159 - val_accuracy: 0.7709\n",
      "Epoch 385/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1333 - accuracy: 0.9522 - val_loss: 1.4621 - val_accuracy: 0.7765\n",
      "Epoch 386/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1337 - accuracy: 0.9466 - val_loss: 1.5606 - val_accuracy: 0.7709\n",
      "Epoch 387/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.9508 - val_loss: 1.4773 - val_accuracy: 0.7654\n",
      "Epoch 388/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9480 - val_loss: 1.5075 - val_accuracy: 0.7709\n",
      "Epoch 389/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1310 - accuracy: 0.9466 - val_loss: 1.5075 - val_accuracy: 0.7709\n",
      "Epoch 390/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9579 - val_loss: 1.4816 - val_accuracy: 0.7765\n",
      "Epoch 391/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1331 - accuracy: 0.9466 - val_loss: 1.4991 - val_accuracy: 0.7654\n",
      "Epoch 392/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.9537 - val_loss: 1.4992 - val_accuracy: 0.7709\n",
      "Epoch 393/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9466 - val_loss: 1.5852 - val_accuracy: 0.7709\n",
      "Epoch 394/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.9508 - val_loss: 1.5208 - val_accuracy: 0.7765\n",
      "Epoch 395/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1207 - accuracy: 0.9537 - val_loss: 1.5248 - val_accuracy: 0.7709\n",
      "Epoch 396/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.9522 - val_loss: 1.5846 - val_accuracy: 0.7654\n",
      "Epoch 397/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1154 - accuracy: 0.9579 - val_loss: 1.5668 - val_accuracy: 0.7765\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1220 - accuracy: 0.9537 - val_loss: 1.6524 - val_accuracy: 0.7709\n",
      "Epoch 399/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.9522 - val_loss: 1.4965 - val_accuracy: 0.7765\n",
      "Epoch 400/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1210 - accuracy: 0.9551 - val_loss: 1.6716 - val_accuracy: 0.7821\n",
      "Epoch 401/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1186 - accuracy: 0.9522 - val_loss: 1.6305 - val_accuracy: 0.7654\n",
      "Epoch 402/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9466 - val_loss: 1.5921 - val_accuracy: 0.7709\n",
      "Epoch 403/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.9522 - val_loss: 1.5541 - val_accuracy: 0.7709\n",
      "Epoch 404/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1230 - accuracy: 0.9508 - val_loss: 1.5590 - val_accuracy: 0.7598\n",
      "Epoch 405/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.9537 - val_loss: 1.5468 - val_accuracy: 0.7765\n",
      "Epoch 406/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1269 - accuracy: 0.9522 - val_loss: 1.6553 - val_accuracy: 0.7821\n",
      "Epoch 407/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9480 - val_loss: 1.5897 - val_accuracy: 0.7598\n",
      "Epoch 408/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.9508 - val_loss: 1.5415 - val_accuracy: 0.7821\n",
      "Epoch 409/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.9508 - val_loss: 1.6776 - val_accuracy: 0.7654\n",
      "Epoch 410/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.9579 - val_loss: 1.6304 - val_accuracy: 0.7765\n",
      "Epoch 411/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9508 - val_loss: 1.7346 - val_accuracy: 0.7709\n",
      "Epoch 412/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9565 - val_loss: 1.5683 - val_accuracy: 0.7709\n",
      "Epoch 413/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.9565 - val_loss: 1.6871 - val_accuracy: 0.7709\n",
      "Epoch 414/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9522 - val_loss: 1.6457 - val_accuracy: 0.7709\n",
      "Epoch 415/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1220 - accuracy: 0.9522 - val_loss: 1.6346 - val_accuracy: 0.7430\n",
      "Epoch 416/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1303 - accuracy: 0.9466 - val_loss: 1.7101 - val_accuracy: 0.7765\n",
      "Epoch 417/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.9537 - val_loss: 1.5919 - val_accuracy: 0.7709\n",
      "Epoch 418/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9551 - val_loss: 1.6905 - val_accuracy: 0.7709\n",
      "Epoch 419/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1310 - accuracy: 0.9494 - val_loss: 1.6266 - val_accuracy: 0.7654\n",
      "Epoch 420/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1469 - accuracy: 0.9522 - val_loss: 1.7859 - val_accuracy: 0.7709\n",
      "Epoch 421/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.9537 - val_loss: 1.6787 - val_accuracy: 0.7542\n",
      "Epoch 422/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.9565 - val_loss: 1.7057 - val_accuracy: 0.7709\n",
      "Epoch 423/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9565 - val_loss: 1.8194 - val_accuracy: 0.7598\n",
      "Epoch 424/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9537 - val_loss: 1.8075 - val_accuracy: 0.7709\n",
      "Epoch 425/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.9579 - val_loss: 1.7032 - val_accuracy: 0.7709\n",
      "Epoch 426/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.9551 - val_loss: 1.6797 - val_accuracy: 0.7765\n",
      "Epoch 427/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9593 - val_loss: 1.7006 - val_accuracy: 0.7654\n",
      "Epoch 428/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9508 - val_loss: 1.6221 - val_accuracy: 0.7654\n",
      "Epoch 429/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9551 - val_loss: 1.7465 - val_accuracy: 0.7709\n",
      "Epoch 430/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9579 - val_loss: 1.7183 - val_accuracy: 0.7654\n",
      "Epoch 431/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.9522 - val_loss: 1.7336 - val_accuracy: 0.7765\n",
      "Epoch 432/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.9565 - val_loss: 1.7775 - val_accuracy: 0.7598\n",
      "Epoch 433/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.9565 - val_loss: 1.7877 - val_accuracy: 0.7598\n",
      "Epoch 434/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.9522 - val_loss: 1.6446 - val_accuracy: 0.7709\n",
      "Epoch 435/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1188 - accuracy: 0.9565 - val_loss: 1.8392 - val_accuracy: 0.7598\n",
      "Epoch 436/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1145 - accuracy: 0.9508 - val_loss: 1.8165 - val_accuracy: 0.7654\n",
      "Epoch 437/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.9537 - val_loss: 1.7910 - val_accuracy: 0.7542\n",
      "Epoch 438/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9551 - val_loss: 1.7666 - val_accuracy: 0.7709\n",
      "Epoch 439/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9494 - val_loss: 1.8175 - val_accuracy: 0.7598\n",
      "Epoch 440/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.9565 - val_loss: 1.6613 - val_accuracy: 0.7765\n",
      "Epoch 441/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9607 - val_loss: 1.6924 - val_accuracy: 0.7709\n",
      "Epoch 442/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1127 - accuracy: 0.9480 - val_loss: 1.7675 - val_accuracy: 0.7598\n",
      "Epoch 443/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9621 - val_loss: 1.7624 - val_accuracy: 0.7709\n",
      "Epoch 444/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1108 - accuracy: 0.9579 - val_loss: 1.7595 - val_accuracy: 0.7709\n",
      "Epoch 445/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9635 - val_loss: 1.8141 - val_accuracy: 0.7765\n",
      "Epoch 446/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1191 - accuracy: 0.9551 - val_loss: 2.0218 - val_accuracy: 0.7654\n",
      "Epoch 447/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9551 - val_loss: 1.8335 - val_accuracy: 0.7654\n",
      "Epoch 448/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9508 - val_loss: 1.8127 - val_accuracy: 0.7709\n",
      "Epoch 449/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9537 - val_loss: 1.8224 - val_accuracy: 0.7542\n",
      "Epoch 450/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1107 - accuracy: 0.9537 - val_loss: 1.7336 - val_accuracy: 0.7654\n",
      "Epoch 451/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1084 - accuracy: 0.9607 - val_loss: 1.8202 - val_accuracy: 0.7709\n",
      "Epoch 452/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9522 - val_loss: 1.8589 - val_accuracy: 0.7598\n",
      "Epoch 453/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.9452 - val_loss: 1.8735 - val_accuracy: 0.7598\n",
      "Epoch 454/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.9551 - val_loss: 1.8873 - val_accuracy: 0.7486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.9551 - val_loss: 1.8216 - val_accuracy: 0.7654\n",
      "Epoch 456/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9551 - val_loss: 1.8107 - val_accuracy: 0.7709\n",
      "Epoch 457/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.9593 - val_loss: 1.9433 - val_accuracy: 0.7765\n",
      "Epoch 458/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.9522 - val_loss: 1.8777 - val_accuracy: 0.7709\n",
      "Epoch 459/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.9579 - val_loss: 1.7920 - val_accuracy: 0.7598\n",
      "Epoch 460/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9522 - val_loss: 1.9493 - val_accuracy: 0.7765\n",
      "Epoch 461/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9480 - val_loss: 1.7917 - val_accuracy: 0.7598\n",
      "Epoch 462/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9579 - val_loss: 1.7988 - val_accuracy: 0.7821\n",
      "Epoch 463/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1126 - accuracy: 0.9579 - val_loss: 2.0166 - val_accuracy: 0.7765\n",
      "Epoch 464/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9551 - val_loss: 1.8200 - val_accuracy: 0.7207\n",
      "Epoch 465/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1349 - accuracy: 0.9424 - val_loss: 1.8225 - val_accuracy: 0.7598\n",
      "Epoch 466/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9466 - val_loss: 1.8712 - val_accuracy: 0.7765\n",
      "Epoch 467/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9579 - val_loss: 1.8061 - val_accuracy: 0.7374\n",
      "Epoch 468/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.9551 - val_loss: 1.9621 - val_accuracy: 0.7598\n",
      "Epoch 469/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9565 - val_loss: 1.8701 - val_accuracy: 0.7654\n",
      "Epoch 470/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9537 - val_loss: 1.8473 - val_accuracy: 0.7654\n",
      "Epoch 471/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9593 - val_loss: 1.9537 - val_accuracy: 0.7877\n",
      "Epoch 472/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1211 - accuracy: 0.9508 - val_loss: 1.9522 - val_accuracy: 0.7598\n",
      "Epoch 473/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.9551 - val_loss: 1.8728 - val_accuracy: 0.7654\n",
      "Epoch 474/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 0.9565 - val_loss: 1.9347 - val_accuracy: 0.7430\n",
      "Epoch 475/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.9607 - val_loss: 1.8489 - val_accuracy: 0.7654\n",
      "Epoch 476/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.9565 - val_loss: 1.8711 - val_accuracy: 0.7598\n",
      "Epoch 477/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9565 - val_loss: 1.8887 - val_accuracy: 0.7654\n",
      "Epoch 478/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.9593 - val_loss: 2.0688 - val_accuracy: 0.7430\n",
      "Epoch 479/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9621 - val_loss: 1.8858 - val_accuracy: 0.7542\n",
      "Epoch 480/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9565 - val_loss: 1.8688 - val_accuracy: 0.7542\n",
      "Epoch 481/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9537 - val_loss: 2.0026 - val_accuracy: 0.7486\n",
      "Epoch 482/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9593 - val_loss: 1.8534 - val_accuracy: 0.7654\n",
      "Epoch 483/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9537 - val_loss: 1.8727 - val_accuracy: 0.7598\n",
      "Epoch 484/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.9508 - val_loss: 2.0576 - val_accuracy: 0.7542\n",
      "Epoch 485/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1358 - accuracy: 0.9579 - val_loss: 1.8049 - val_accuracy: 0.7598\n",
      "Epoch 486/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2521 - accuracy: 0.9298 - val_loss: 2.4420 - val_accuracy: 0.7598\n",
      "Epoch 487/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.8989 - val_loss: 2.0428 - val_accuracy: 0.6927\n",
      "Epoch 488/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1743 - accuracy: 0.9326 - val_loss: 1.7447 - val_accuracy: 0.7263\n",
      "Epoch 489/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1395 - accuracy: 0.9466 - val_loss: 2.0387 - val_accuracy: 0.7598\n",
      "Epoch 490/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.9565 - val_loss: 1.7172 - val_accuracy: 0.7486\n",
      "Epoch 491/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9579 - val_loss: 1.7914 - val_accuracy: 0.7654\n",
      "Epoch 492/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1008 - accuracy: 0.9607 - val_loss: 1.8155 - val_accuracy: 0.7542\n",
      "Epoch 493/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.9565 - val_loss: 1.8621 - val_accuracy: 0.7374\n",
      "Epoch 494/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9621 - val_loss: 1.8290 - val_accuracy: 0.7598\n",
      "Epoch 495/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9607 - val_loss: 1.8846 - val_accuracy: 0.7654\n",
      "Epoch 496/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9537 - val_loss: 1.9062 - val_accuracy: 0.7598\n",
      "Epoch 497/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.9480 - val_loss: 1.8573 - val_accuracy: 0.7654\n",
      "Epoch 498/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 0.9480 - val_loss: 1.8763 - val_accuracy: 0.7654\n",
      "Epoch 499/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.9551 - val_loss: 1.8661 - val_accuracy: 0.7486\n",
      "Epoch 500/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1033 - accuracy: 0.9579 - val_loss: 1.9714 - val_accuracy: 0.7598\n",
      "Epoch 501/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.9537 - val_loss: 1.8332 - val_accuracy: 0.7709\n",
      "Epoch 502/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9593 - val_loss: 2.0303 - val_accuracy: 0.7709\n",
      "Epoch 503/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1159 - accuracy: 0.9494 - val_loss: 1.9467 - val_accuracy: 0.7374\n",
      "Epoch 504/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9494 - val_loss: 1.8465 - val_accuracy: 0.7486\n",
      "Epoch 505/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.9508 - val_loss: 2.0115 - val_accuracy: 0.7598\n",
      "Epoch 506/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9565 - val_loss: 1.9835 - val_accuracy: 0.7765\n",
      "Epoch 507/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 0.9607 - val_loss: 2.0958 - val_accuracy: 0.7654\n",
      "Epoch 508/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9565 - val_loss: 1.8493 - val_accuracy: 0.7486\n",
      "Epoch 509/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9579 - val_loss: 1.9238 - val_accuracy: 0.7598\n",
      "Epoch 510/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9537 - val_loss: 2.0302 - val_accuracy: 0.7598\n",
      "Epoch 511/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0972 - accuracy: 0.9663 - val_loss: 2.0284 - val_accuracy: 0.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9649 - val_loss: 1.9647 - val_accuracy: 0.7598\n",
      "Epoch 513/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1003 - accuracy: 0.9579 - val_loss: 2.0240 - val_accuracy: 0.7430\n",
      "Epoch 514/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9649 - val_loss: 1.9414 - val_accuracy: 0.7598\n",
      "Epoch 515/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9621 - val_loss: 2.0583 - val_accuracy: 0.7598\n",
      "Epoch 516/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9621 - val_loss: 2.1511 - val_accuracy: 0.7821\n",
      "Epoch 517/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9537 - val_loss: 1.9893 - val_accuracy: 0.7598\n",
      "Epoch 518/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9565 - val_loss: 1.9212 - val_accuracy: 0.7542\n",
      "Epoch 519/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9593 - val_loss: 2.0752 - val_accuracy: 0.7709\n",
      "Epoch 520/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9621 - val_loss: 1.9704 - val_accuracy: 0.7542\n",
      "Epoch 521/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9593 - val_loss: 2.0672 - val_accuracy: 0.7654\n",
      "Epoch 522/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9621 - val_loss: 2.0554 - val_accuracy: 0.7598\n",
      "Epoch 523/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0952 - accuracy: 0.9593 - val_loss: 2.0397 - val_accuracy: 0.7542\n",
      "Epoch 524/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9607 - val_loss: 1.9936 - val_accuracy: 0.7486\n",
      "Epoch 525/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9565 - val_loss: 2.0724 - val_accuracy: 0.7430\n",
      "Epoch 526/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9537 - val_loss: 2.0353 - val_accuracy: 0.7486\n",
      "Epoch 527/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9551 - val_loss: 1.9874 - val_accuracy: 0.7542\n",
      "Epoch 528/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9635 - val_loss: 2.1293 - val_accuracy: 0.7542\n",
      "Epoch 529/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9607 - val_loss: 1.9763 - val_accuracy: 0.7486\n",
      "Epoch 530/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9579 - val_loss: 2.1922 - val_accuracy: 0.7430\n",
      "Epoch 531/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9635 - val_loss: 2.0749 - val_accuracy: 0.7598\n",
      "Epoch 532/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.9621 - val_loss: 2.0683 - val_accuracy: 0.7654\n",
      "Epoch 533/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9635 - val_loss: 2.1916 - val_accuracy: 0.7095\n",
      "Epoch 534/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9565 - val_loss: 2.2409 - val_accuracy: 0.7486\n",
      "Epoch 535/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9663 - val_loss: 1.9383 - val_accuracy: 0.7542\n",
      "Epoch 536/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9635 - val_loss: 2.0896 - val_accuracy: 0.7598\n",
      "Epoch 537/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9593 - val_loss: 2.1983 - val_accuracy: 0.7486\n",
      "Epoch 538/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9635 - val_loss: 2.0854 - val_accuracy: 0.7598\n",
      "Epoch 539/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9635 - val_loss: 2.1086 - val_accuracy: 0.7598\n",
      "Epoch 540/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9551 - val_loss: 2.0540 - val_accuracy: 0.7039\n",
      "Epoch 541/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9565 - val_loss: 2.1253 - val_accuracy: 0.7542\n",
      "Epoch 542/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.9649 - val_loss: 2.1509 - val_accuracy: 0.7709\n",
      "Epoch 543/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0947 - accuracy: 0.9607 - val_loss: 2.0215 - val_accuracy: 0.7374\n",
      "Epoch 544/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9565 - val_loss: 2.0898 - val_accuracy: 0.7486\n",
      "Epoch 545/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9621 - val_loss: 2.2554 - val_accuracy: 0.7318\n",
      "Epoch 546/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1238 - accuracy: 0.9522 - val_loss: 2.0155 - val_accuracy: 0.7654\n",
      "Epoch 547/1000\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0996 - accuracy: 0.9649 - val_loss: 2.0878 - val_accuracy: 0.7709\n",
      "Epoch 548/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0989 - accuracy: 0.9607 - val_loss: 2.0533 - val_accuracy: 0.7654\n",
      "Epoch 549/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.9593 - val_loss: 2.1035 - val_accuracy: 0.7486\n",
      "Epoch 550/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9551 - val_loss: 2.1810 - val_accuracy: 0.7598\n",
      "Epoch 551/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1116 - accuracy: 0.9494 - val_loss: 2.1199 - val_accuracy: 0.7263\n",
      "Epoch 552/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1005 - accuracy: 0.9579 - val_loss: 2.0997 - val_accuracy: 0.7207\n",
      "Epoch 553/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9579 - val_loss: 2.0321 - val_accuracy: 0.7654\n",
      "Epoch 554/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9579 - val_loss: 2.3217 - val_accuracy: 0.7374\n",
      "Epoch 555/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9607 - val_loss: 2.2221 - val_accuracy: 0.7374\n",
      "Epoch 556/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9537 - val_loss: 2.0990 - val_accuracy: 0.7542\n",
      "Epoch 557/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9635 - val_loss: 2.0782 - val_accuracy: 0.7765\n",
      "Epoch 558/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9663 - val_loss: 2.2017 - val_accuracy: 0.7263\n",
      "Epoch 559/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9565 - val_loss: 2.1017 - val_accuracy: 0.7598\n",
      "Epoch 560/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9551 - val_loss: 2.0940 - val_accuracy: 0.7430\n",
      "Epoch 561/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9649 - val_loss: 2.1696 - val_accuracy: 0.7542\n",
      "Epoch 562/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0952 - accuracy: 0.9635 - val_loss: 2.1082 - val_accuracy: 0.7598\n",
      "Epoch 563/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9621 - val_loss: 2.1752 - val_accuracy: 0.7542\n",
      "Epoch 564/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9649 - val_loss: 2.0880 - val_accuracy: 0.7709\n",
      "Epoch 565/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9537 - val_loss: 2.1789 - val_accuracy: 0.7598\n",
      "Epoch 566/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9537 - val_loss: 2.1669 - val_accuracy: 0.7542\n",
      "Epoch 567/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9579 - val_loss: 2.1457 - val_accuracy: 0.7765\n",
      "Epoch 568/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9579 - val_loss: 2.0211 - val_accuracy: 0.7542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.9593 - val_loss: 2.1676 - val_accuracy: 0.7654\n",
      "Epoch 570/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9565 - val_loss: 2.0410 - val_accuracy: 0.7542\n",
      "Epoch 571/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9565 - val_loss: 2.2872 - val_accuracy: 0.7765\n",
      "Epoch 572/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.9579 - val_loss: 2.1478 - val_accuracy: 0.7095\n",
      "Epoch 573/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9579 - val_loss: 2.1023 - val_accuracy: 0.7654\n",
      "Epoch 574/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 0.9621 - val_loss: 2.2731 - val_accuracy: 0.7709\n",
      "Epoch 575/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9621 - val_loss: 2.1784 - val_accuracy: 0.7430\n",
      "Epoch 576/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9593 - val_loss: 2.1668 - val_accuracy: 0.7765\n",
      "Epoch 577/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9537 - val_loss: 2.2039 - val_accuracy: 0.7542\n",
      "Epoch 578/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9621 - val_loss: 2.6078 - val_accuracy: 0.7654\n",
      "Epoch 579/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9607 - val_loss: 2.1732 - val_accuracy: 0.7207\n",
      "Epoch 580/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9621 - val_loss: 2.2131 - val_accuracy: 0.7765\n",
      "Epoch 581/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 0.9537 - val_loss: 2.3407 - val_accuracy: 0.7542\n",
      "Epoch 582/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9607 - val_loss: 2.1999 - val_accuracy: 0.7374\n",
      "Epoch 583/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9551 - val_loss: 2.2629 - val_accuracy: 0.7765\n",
      "Epoch 584/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9551 - val_loss: 2.1183 - val_accuracy: 0.7374\n",
      "Epoch 585/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9663 - val_loss: 2.1200 - val_accuracy: 0.7709\n",
      "Epoch 586/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.9621 - val_loss: 2.4777 - val_accuracy: 0.7598\n",
      "Epoch 587/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9649 - val_loss: 2.2997 - val_accuracy: 0.7654\n",
      "Epoch 588/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0932 - accuracy: 0.9691 - val_loss: 2.1703 - val_accuracy: 0.7654\n",
      "Epoch 589/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9607 - val_loss: 2.2118 - val_accuracy: 0.7709\n",
      "Epoch 590/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0986 - accuracy: 0.9522 - val_loss: 2.3284 - val_accuracy: 0.7709\n",
      "Epoch 591/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.9593 - val_loss: 2.1927 - val_accuracy: 0.7654\n",
      "Epoch 592/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9579 - val_loss: 2.2335 - val_accuracy: 0.7765\n",
      "Epoch 593/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9635 - val_loss: 2.4423 - val_accuracy: 0.7709\n",
      "Epoch 594/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9621 - val_loss: 2.1639 - val_accuracy: 0.7542\n",
      "Epoch 595/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9677 - val_loss: 2.1828 - val_accuracy: 0.7654\n",
      "Epoch 596/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9635 - val_loss: 2.2360 - val_accuracy: 0.7598\n",
      "Epoch 597/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9649 - val_loss: 2.2999 - val_accuracy: 0.7598\n",
      "Epoch 598/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9607 - val_loss: 2.2106 - val_accuracy: 0.7374\n",
      "Epoch 599/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9593 - val_loss: 2.3113 - val_accuracy: 0.7598\n",
      "Epoch 600/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9621 - val_loss: 2.2433 - val_accuracy: 0.7709\n",
      "Epoch 601/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1069 - accuracy: 0.9537 - val_loss: 2.2060 - val_accuracy: 0.7598\n",
      "Epoch 602/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0959 - accuracy: 0.9593 - val_loss: 2.3339 - val_accuracy: 0.7598\n",
      "Epoch 603/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9663 - val_loss: 2.3266 - val_accuracy: 0.7430\n",
      "Epoch 604/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9579 - val_loss: 2.2782 - val_accuracy: 0.7542\n",
      "Epoch 605/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9649 - val_loss: 2.1777 - val_accuracy: 0.7709\n",
      "Epoch 606/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9635 - val_loss: 2.2399 - val_accuracy: 0.7486\n",
      "Epoch 607/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.9635 - val_loss: 2.3306 - val_accuracy: 0.7598\n",
      "Epoch 608/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9593 - val_loss: 2.3054 - val_accuracy: 0.7709\n",
      "Epoch 609/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9579 - val_loss: 2.2882 - val_accuracy: 0.7765\n",
      "Epoch 610/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9593 - val_loss: 2.2061 - val_accuracy: 0.7542\n",
      "Epoch 611/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9649 - val_loss: 2.1612 - val_accuracy: 0.7430\n",
      "Epoch 612/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0904 - accuracy: 0.9635 - val_loss: 2.1923 - val_accuracy: 0.7374\n",
      "Epoch 613/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9635 - val_loss: 2.3689 - val_accuracy: 0.7430\n",
      "Epoch 614/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9593 - val_loss: 2.3371 - val_accuracy: 0.7654\n",
      "Epoch 615/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9607 - val_loss: 2.2768 - val_accuracy: 0.7654\n",
      "Epoch 616/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9635 - val_loss: 2.2864 - val_accuracy: 0.7542\n",
      "Epoch 617/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9635 - val_loss: 2.2406 - val_accuracy: 0.7374\n",
      "Epoch 618/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1095 - accuracy: 0.9593 - val_loss: 2.4147 - val_accuracy: 0.7095\n",
      "Epoch 619/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1040 - accuracy: 0.9593 - val_loss: 2.3874 - val_accuracy: 0.7039\n",
      "Epoch 620/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9677 - val_loss: 2.5638 - val_accuracy: 0.7486\n",
      "Epoch 621/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0976 - accuracy: 0.9649 - val_loss: 2.4563 - val_accuracy: 0.7207\n",
      "Epoch 622/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2051 - accuracy: 0.9480 - val_loss: 2.1680 - val_accuracy: 0.7654\n",
      "Epoch 623/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1535 - accuracy: 0.9396 - val_loss: 2.1843 - val_accuracy: 0.7486\n",
      "Epoch 624/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2381 - accuracy: 0.9396 - val_loss: 2.0606 - val_accuracy: 0.7821\n",
      "Epoch 625/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1591 - accuracy: 0.9522 - val_loss: 2.1282 - val_accuracy: 0.7598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0914 - accuracy: 0.9635 - val_loss: 1.9912 - val_accuracy: 0.7654\n",
      "Epoch 627/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1003 - accuracy: 0.9579 - val_loss: 2.1679 - val_accuracy: 0.7654\n",
      "Epoch 628/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9677 - val_loss: 2.1452 - val_accuracy: 0.7598\n",
      "Epoch 629/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9621 - val_loss: 2.1287 - val_accuracy: 0.7430\n",
      "Epoch 630/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0912 - accuracy: 0.9621 - val_loss: 2.1277 - val_accuracy: 0.7598\n",
      "Epoch 631/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9649 - val_loss: 2.1254 - val_accuracy: 0.7151\n",
      "Epoch 632/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9579 - val_loss: 2.4556 - val_accuracy: 0.7374\n",
      "Epoch 633/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9635 - val_loss: 2.2310 - val_accuracy: 0.7654\n",
      "Epoch 634/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0895 - accuracy: 0.9635 - val_loss: 2.2871 - val_accuracy: 0.7542\n",
      "Epoch 635/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9607 - val_loss: 2.3264 - val_accuracy: 0.7654\n",
      "Epoch 636/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0862 - accuracy: 0.9621 - val_loss: 2.1958 - val_accuracy: 0.7318\n",
      "Epoch 637/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9621 - val_loss: 2.1534 - val_accuracy: 0.7598\n",
      "Epoch 638/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9621 - val_loss: 2.2437 - val_accuracy: 0.7598\n",
      "Epoch 639/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9691 - val_loss: 2.2362 - val_accuracy: 0.7598\n",
      "Epoch 640/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9537 - val_loss: 2.1974 - val_accuracy: 0.7709\n",
      "Epoch 641/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9677 - val_loss: 2.4011 - val_accuracy: 0.7654\n",
      "Epoch 642/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0921 - accuracy: 0.9551 - val_loss: 2.2504 - val_accuracy: 0.7486\n",
      "Epoch 643/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9565 - val_loss: 2.2671 - val_accuracy: 0.7709\n",
      "Epoch 644/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9677 - val_loss: 2.3322 - val_accuracy: 0.7207\n",
      "Epoch 645/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9607 - val_loss: 2.2730 - val_accuracy: 0.7654\n",
      "Epoch 646/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9649 - val_loss: 2.3141 - val_accuracy: 0.7765\n",
      "Epoch 647/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1021 - accuracy: 0.9494 - val_loss: 2.1611 - val_accuracy: 0.7654\n",
      "Epoch 648/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9593 - val_loss: 2.2852 - val_accuracy: 0.7654\n",
      "Epoch 649/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9565 - val_loss: 2.2219 - val_accuracy: 0.7598\n",
      "Epoch 650/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.9635 - val_loss: 2.1121 - val_accuracy: 0.7318\n",
      "Epoch 651/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9621 - val_loss: 2.3217 - val_accuracy: 0.7654\n",
      "Epoch 652/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0930 - accuracy: 0.9607 - val_loss: 2.3090 - val_accuracy: 0.7654\n",
      "Epoch 653/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9705 - val_loss: 2.3945 - val_accuracy: 0.7709\n",
      "Epoch 654/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 0.9579 - val_loss: 2.4398 - val_accuracy: 0.7542\n",
      "Epoch 655/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0940 - accuracy: 0.9663 - val_loss: 2.1635 - val_accuracy: 0.7765\n",
      "Epoch 656/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9593 - val_loss: 2.4865 - val_accuracy: 0.7374\n",
      "Epoch 657/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9579 - val_loss: 2.4001 - val_accuracy: 0.7598\n",
      "Epoch 658/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9649 - val_loss: 2.2087 - val_accuracy: 0.7654\n",
      "Epoch 659/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0898 - accuracy: 0.9635 - val_loss: 2.2335 - val_accuracy: 0.7486\n",
      "Epoch 660/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9607 - val_loss: 2.1912 - val_accuracy: 0.7765\n",
      "Epoch 661/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9593 - val_loss: 2.3282 - val_accuracy: 0.7430\n",
      "Epoch 662/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9607 - val_loss: 2.1937 - val_accuracy: 0.7654\n",
      "Epoch 663/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.9635 - val_loss: 2.4098 - val_accuracy: 0.7430\n",
      "Epoch 664/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9579 - val_loss: 2.4367 - val_accuracy: 0.7598\n",
      "Epoch 665/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9663 - val_loss: 2.2808 - val_accuracy: 0.7654\n",
      "Epoch 666/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9593 - val_loss: 2.2785 - val_accuracy: 0.7598\n",
      "Epoch 667/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9621 - val_loss: 2.5932 - val_accuracy: 0.7542\n",
      "Epoch 668/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0930 - accuracy: 0.9635 - val_loss: 2.3388 - val_accuracy: 0.7151\n",
      "Epoch 669/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9565 - val_loss: 2.3885 - val_accuracy: 0.7263\n",
      "Epoch 670/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9649 - val_loss: 2.4427 - val_accuracy: 0.7598\n",
      "Epoch 671/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1030 - accuracy: 0.9551 - val_loss: 2.3235 - val_accuracy: 0.7542\n",
      "Epoch 672/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9635 - val_loss: 2.3782 - val_accuracy: 0.7709\n",
      "Epoch 673/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.9635 - val_loss: 2.2470 - val_accuracy: 0.7654\n",
      "Epoch 674/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9579 - val_loss: 2.2847 - val_accuracy: 0.7765\n",
      "Epoch 675/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9621 - val_loss: 2.2000 - val_accuracy: 0.7207\n",
      "Epoch 676/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9621 - val_loss: 2.3125 - val_accuracy: 0.7430\n",
      "Epoch 677/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 0.9649 - val_loss: 2.3864 - val_accuracy: 0.7374\n",
      "Epoch 678/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9691 - val_loss: 2.3776 - val_accuracy: 0.7765\n",
      "Epoch 679/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9649 - val_loss: 2.4366 - val_accuracy: 0.7654\n",
      "Epoch 680/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1013 - accuracy: 0.9607 - val_loss: 2.3178 - val_accuracy: 0.7765\n",
      "Epoch 681/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0992 - accuracy: 0.9579 - val_loss: 2.2703 - val_accuracy: 0.7821\n",
      "Epoch 682/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9607 - val_loss: 2.2914 - val_accuracy: 0.7263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9635 - val_loss: 2.3482 - val_accuracy: 0.7207\n",
      "Epoch 684/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9565 - val_loss: 2.2641 - val_accuracy: 0.7598\n",
      "Epoch 685/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9649 - val_loss: 2.2743 - val_accuracy: 0.7486\n",
      "Epoch 686/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9551 - val_loss: 2.4163 - val_accuracy: 0.7430\n",
      "Epoch 687/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9565 - val_loss: 2.4263 - val_accuracy: 0.7709\n",
      "Epoch 688/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9565 - val_loss: 2.4579 - val_accuracy: 0.7598\n",
      "Epoch 689/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9607 - val_loss: 2.1700 - val_accuracy: 0.7654\n",
      "Epoch 690/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 0.9579 - val_loss: 2.3906 - val_accuracy: 0.7654\n",
      "Epoch 691/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9537 - val_loss: 2.2624 - val_accuracy: 0.7654\n",
      "Epoch 692/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9593 - val_loss: 2.4519 - val_accuracy: 0.7709\n",
      "Epoch 693/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9565 - val_loss: 2.3111 - val_accuracy: 0.7654\n",
      "Epoch 694/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0880 - accuracy: 0.9607 - val_loss: 2.2883 - val_accuracy: 0.7542\n",
      "Epoch 695/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0946 - accuracy: 0.9607 - val_loss: 2.4288 - val_accuracy: 0.7598\n",
      "Epoch 696/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9677 - val_loss: 2.2919 - val_accuracy: 0.7598\n",
      "Epoch 697/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0902 - accuracy: 0.9635 - val_loss: 2.4800 - val_accuracy: 0.7765\n",
      "Epoch 698/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9635 - val_loss: 2.5095 - val_accuracy: 0.7542\n",
      "Epoch 699/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9494 - val_loss: 2.3957 - val_accuracy: 0.7598\n",
      "Epoch 700/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9649 - val_loss: 2.2649 - val_accuracy: 0.7430\n",
      "Epoch 701/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9649 - val_loss: 2.2080 - val_accuracy: 0.7542\n",
      "Epoch 702/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9663 - val_loss: 2.3705 - val_accuracy: 0.7709\n",
      "Epoch 703/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9635 - val_loss: 2.5700 - val_accuracy: 0.7654\n",
      "Epoch 704/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9593 - val_loss: 2.5366 - val_accuracy: 0.7430\n",
      "Epoch 705/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9635 - val_loss: 2.3905 - val_accuracy: 0.7598\n",
      "Epoch 706/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9677 - val_loss: 2.2756 - val_accuracy: 0.7709\n",
      "Epoch 707/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9649 - val_loss: 2.3889 - val_accuracy: 0.7207\n",
      "Epoch 708/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9691 - val_loss: 2.3806 - val_accuracy: 0.7542\n",
      "Epoch 709/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.9621 - val_loss: 2.4703 - val_accuracy: 0.7374\n",
      "Epoch 710/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1009 - accuracy: 0.9607 - val_loss: 2.3365 - val_accuracy: 0.7430\n",
      "Epoch 711/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9635 - val_loss: 2.3360 - val_accuracy: 0.7374\n",
      "Epoch 712/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0895 - accuracy: 0.9593 - val_loss: 2.3976 - val_accuracy: 0.7598\n",
      "Epoch 713/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9635 - val_loss: 2.3225 - val_accuracy: 0.7430\n",
      "Epoch 714/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9677 - val_loss: 2.4917 - val_accuracy: 0.7654\n",
      "Epoch 715/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9649 - val_loss: 2.4330 - val_accuracy: 0.7486\n",
      "Epoch 716/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9607 - val_loss: 2.3658 - val_accuracy: 0.7486\n",
      "Epoch 717/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9593 - val_loss: 2.4557 - val_accuracy: 0.7374\n",
      "Epoch 718/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9621 - val_loss: 2.6395 - val_accuracy: 0.7709\n",
      "Epoch 719/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9593 - val_loss: 2.3827 - val_accuracy: 0.7765\n",
      "Epoch 720/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 0.9635 - val_loss: 2.3400 - val_accuracy: 0.7654\n",
      "Epoch 721/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9677 - val_loss: 2.3579 - val_accuracy: 0.7654\n",
      "Epoch 722/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9691 - val_loss: 2.6274 - val_accuracy: 0.7430\n",
      "Epoch 723/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9663 - val_loss: 2.3163 - val_accuracy: 0.7709\n",
      "Epoch 724/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9691 - val_loss: 2.3747 - val_accuracy: 0.7318\n",
      "Epoch 725/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9649 - val_loss: 2.4409 - val_accuracy: 0.7486\n",
      "Epoch 726/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0909 - accuracy: 0.9677 - val_loss: 2.4324 - val_accuracy: 0.7542\n",
      "Epoch 727/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9565 - val_loss: 2.5020 - val_accuracy: 0.7654\n",
      "Epoch 728/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0962 - accuracy: 0.9607 - val_loss: 2.5497 - val_accuracy: 0.7709\n",
      "Epoch 729/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1007 - accuracy: 0.9621 - val_loss: 2.3472 - val_accuracy: 0.7318\n",
      "Epoch 730/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9537 - val_loss: 2.6843 - val_accuracy: 0.7598\n",
      "Epoch 731/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9522 - val_loss: 2.3914 - val_accuracy: 0.7542\n",
      "Epoch 732/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0951 - accuracy: 0.9635 - val_loss: 2.5346 - val_accuracy: 0.7598\n",
      "Epoch 733/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9635 - val_loss: 2.4884 - val_accuracy: 0.7654\n",
      "Epoch 734/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9621 - val_loss: 2.4122 - val_accuracy: 0.7709\n",
      "Epoch 735/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9635 - val_loss: 2.5156 - val_accuracy: 0.7709\n",
      "Epoch 736/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1097 - accuracy: 0.9494 - val_loss: 2.6462 - val_accuracy: 0.7765\n",
      "Epoch 737/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.9551 - val_loss: 2.4568 - val_accuracy: 0.7486\n",
      "Epoch 738/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9649 - val_loss: 2.4784 - val_accuracy: 0.7709\n",
      "Epoch 739/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9677 - val_loss: 2.5139 - val_accuracy: 0.7654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9649 - val_loss: 2.5523 - val_accuracy: 0.7654\n",
      "Epoch 741/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9663 - val_loss: 2.6447 - val_accuracy: 0.7598\n",
      "Epoch 742/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9551 - val_loss: 2.5600 - val_accuracy: 0.7430\n",
      "Epoch 743/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9537 - val_loss: 2.3202 - val_accuracy: 0.7542\n",
      "Epoch 744/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9705 - val_loss: 2.3755 - val_accuracy: 0.7430\n",
      "Epoch 745/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9607 - val_loss: 2.7875 - val_accuracy: 0.7598\n",
      "Epoch 746/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9607 - val_loss: 2.3485 - val_accuracy: 0.7542\n",
      "Epoch 747/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9663 - val_loss: 2.5172 - val_accuracy: 0.7542\n",
      "Epoch 748/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0907 - accuracy: 0.9621 - val_loss: 2.4396 - val_accuracy: 0.7709\n",
      "Epoch 749/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2423 - accuracy: 0.9368 - val_loss: 2.4017 - val_accuracy: 0.7207\n",
      "Epoch 750/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2354 - accuracy: 0.9256 - val_loss: 2.3763 - val_accuracy: 0.7598\n",
      "Epoch 751/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9382 - val_loss: 2.2592 - val_accuracy: 0.7542\n",
      "Epoch 752/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9649 - val_loss: 2.3982 - val_accuracy: 0.7654\n",
      "Epoch 753/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0969 - accuracy: 0.9607 - val_loss: 2.4649 - val_accuracy: 0.7598\n",
      "Epoch 754/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1061 - accuracy: 0.9579 - val_loss: 2.3770 - val_accuracy: 0.7654\n",
      "Epoch 755/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9635 - val_loss: 2.4665 - val_accuracy: 0.7598\n",
      "Epoch 756/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9663 - val_loss: 2.2997 - val_accuracy: 0.7821\n",
      "Epoch 757/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.9607 - val_loss: 2.3614 - val_accuracy: 0.7654\n",
      "Epoch 758/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9537 - val_loss: 2.3810 - val_accuracy: 0.7542\n",
      "Epoch 759/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9691 - val_loss: 2.3308 - val_accuracy: 0.7598\n",
      "Epoch 760/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0880 - accuracy: 0.9621 - val_loss: 2.3787 - val_accuracy: 0.7654\n",
      "Epoch 761/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1277 - accuracy: 0.9452 - val_loss: 2.5366 - val_accuracy: 0.7598\n",
      "Epoch 762/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9621 - val_loss: 2.4910 - val_accuracy: 0.7486\n",
      "Epoch 763/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9621 - val_loss: 2.3049 - val_accuracy: 0.7654\n",
      "Epoch 764/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9677 - val_loss: 2.3860 - val_accuracy: 0.7709\n",
      "Epoch 765/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0950 - accuracy: 0.9607 - val_loss: 2.4609 - val_accuracy: 0.7765\n",
      "Epoch 766/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9649 - val_loss: 2.3685 - val_accuracy: 0.7542\n",
      "Epoch 767/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9649 - val_loss: 2.3564 - val_accuracy: 0.7598\n",
      "Epoch 768/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0863 - accuracy: 0.9635 - val_loss: 2.5525 - val_accuracy: 0.7654\n",
      "Epoch 769/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9635 - val_loss: 2.4097 - val_accuracy: 0.7709\n",
      "Epoch 770/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9663 - val_loss: 2.4177 - val_accuracy: 0.7709\n",
      "Epoch 771/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9649 - val_loss: 2.5888 - val_accuracy: 0.7654\n",
      "Epoch 772/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9635 - val_loss: 2.3817 - val_accuracy: 0.7709\n",
      "Epoch 773/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9593 - val_loss: 2.4325 - val_accuracy: 0.7709\n",
      "Epoch 774/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9607 - val_loss: 2.5304 - val_accuracy: 0.7542\n",
      "Epoch 775/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9663 - val_loss: 2.5704 - val_accuracy: 0.7486\n",
      "Epoch 776/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9635 - val_loss: 2.4027 - val_accuracy: 0.7598\n",
      "Epoch 777/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9635 - val_loss: 2.5312 - val_accuracy: 0.7542\n",
      "Epoch 778/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0796 - accuracy: 0.9649 - val_loss: 2.4591 - val_accuracy: 0.7598\n",
      "Epoch 779/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9621 - val_loss: 2.6879 - val_accuracy: 0.7709\n",
      "Epoch 780/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9649 - val_loss: 2.5100 - val_accuracy: 0.7598\n",
      "Epoch 781/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9705 - val_loss: 2.5544 - val_accuracy: 0.7207\n",
      "Epoch 782/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9663 - val_loss: 2.4000 - val_accuracy: 0.7709\n",
      "Epoch 783/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9649 - val_loss: 2.6861 - val_accuracy: 0.7430\n",
      "Epoch 784/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9677 - val_loss: 2.5621 - val_accuracy: 0.7598\n",
      "Epoch 785/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.96 - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9593 - val_loss: 2.4630 - val_accuracy: 0.7374\n",
      "Epoch 786/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9579 - val_loss: 2.5403 - val_accuracy: 0.7430\n",
      "Epoch 787/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9677 - val_loss: 2.6293 - val_accuracy: 0.7430\n",
      "Epoch 788/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0835 - accuracy: 0.9635 - val_loss: 2.4973 - val_accuracy: 0.7207\n",
      "Epoch 789/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9565 - val_loss: 2.6380 - val_accuracy: 0.7430\n",
      "Epoch 790/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9593 - val_loss: 2.4117 - val_accuracy: 0.7430\n",
      "Epoch 791/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 0.9635 - val_loss: 2.4000 - val_accuracy: 0.7598\n",
      "Epoch 792/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 0.9649 - val_loss: 2.3922 - val_accuracy: 0.7542\n",
      "Epoch 793/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9621 - val_loss: 2.4575 - val_accuracy: 0.7486\n",
      "Epoch 794/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9649 - val_loss: 2.5330 - val_accuracy: 0.7598\n",
      "Epoch 795/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9635 - val_loss: 2.6478 - val_accuracy: 0.7709\n",
      "Epoch 796/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9621 - val_loss: 2.5813 - val_accuracy: 0.7654\n",
      "Epoch 797/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9663 - val_loss: 2.4438 - val_accuracy: 0.7430\n",
      "Epoch 798/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9635 - val_loss: 2.4752 - val_accuracy: 0.7151\n",
      "Epoch 799/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9635 - val_loss: 2.4272 - val_accuracy: 0.7430\n",
      "Epoch 800/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9663 - val_loss: 2.4921 - val_accuracy: 0.7654\n",
      "Epoch 801/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9677 - val_loss: 2.7528 - val_accuracy: 0.7542\n",
      "Epoch 802/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9635 - val_loss: 2.7233 - val_accuracy: 0.7598\n",
      "Epoch 803/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9565 - val_loss: 2.4602 - val_accuracy: 0.7709\n",
      "Epoch 804/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9691 - val_loss: 2.5877 - val_accuracy: 0.7709\n",
      "Epoch 805/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9607 - val_loss: 2.7129 - val_accuracy: 0.7542\n",
      "Epoch 806/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9691 - val_loss: 2.5877 - val_accuracy: 0.7765\n",
      "Epoch 807/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0863 - accuracy: 0.9607 - val_loss: 2.5956 - val_accuracy: 0.7765\n",
      "Epoch 808/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9663 - val_loss: 2.5621 - val_accuracy: 0.7486\n",
      "Epoch 809/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9635 - val_loss: 2.8063 - val_accuracy: 0.7765\n",
      "Epoch 810/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9649 - val_loss: 2.3721 - val_accuracy: 0.7486\n",
      "Epoch 811/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9635 - val_loss: 2.4282 - val_accuracy: 0.7486\n",
      "Epoch 812/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9649 - val_loss: 2.6730 - val_accuracy: 0.7486\n",
      "Epoch 813/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9691 - val_loss: 2.4793 - val_accuracy: 0.7542\n",
      "Epoch 814/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9635 - val_loss: 2.7886 - val_accuracy: 0.7598\n",
      "Epoch 815/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9621 - val_loss: 2.5749 - val_accuracy: 0.7654\n",
      "Epoch 816/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9579 - val_loss: 2.4961 - val_accuracy: 0.7542\n",
      "Epoch 817/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0817 - accuracy: 0.9635 - val_loss: 2.6108 - val_accuracy: 0.7542\n",
      "Epoch 818/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9607 - val_loss: 2.4871 - val_accuracy: 0.7318\n",
      "Epoch 819/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.9649 - val_loss: 2.5413 - val_accuracy: 0.7542\n",
      "Epoch 820/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9649 - val_loss: 2.6744 - val_accuracy: 0.7765\n",
      "Epoch 821/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0851 - accuracy: 0.9663 - val_loss: 2.6030 - val_accuracy: 0.7486\n",
      "Epoch 822/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0823 - accuracy: 0.9691 - val_loss: 2.4583 - val_accuracy: 0.7598\n",
      "Epoch 823/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9649 - val_loss: 2.6041 - val_accuracy: 0.7765\n",
      "Epoch 824/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9649 - val_loss: 2.5200 - val_accuracy: 0.7598\n",
      "Epoch 825/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.9607 - val_loss: 2.6519 - val_accuracy: 0.7654\n",
      "Epoch 826/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9607 - val_loss: 2.4181 - val_accuracy: 0.7654\n",
      "Epoch 827/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9649 - val_loss: 2.6137 - val_accuracy: 0.7709\n",
      "Epoch 828/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9635 - val_loss: 2.5778 - val_accuracy: 0.7709\n",
      "Epoch 829/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9621 - val_loss: 2.9102 - val_accuracy: 0.7654\n",
      "Epoch 830/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9621 - val_loss: 2.6878 - val_accuracy: 0.7318\n",
      "Epoch 831/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9565 - val_loss: 2.5725 - val_accuracy: 0.7709\n",
      "Epoch 832/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9579 - val_loss: 2.5274 - val_accuracy: 0.7765\n",
      "Epoch 833/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9649 - val_loss: 2.5958 - val_accuracy: 0.7486\n",
      "Epoch 834/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9719 - val_loss: 2.8259 - val_accuracy: 0.7709\n",
      "Epoch 835/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9677 - val_loss: 2.7814 - val_accuracy: 0.7598\n",
      "Epoch 836/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9635 - val_loss: 2.5602 - val_accuracy: 0.7709\n",
      "Epoch 837/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9635 - val_loss: 2.7563 - val_accuracy: 0.7598\n",
      "Epoch 838/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0816 - accuracy: 0.9607 - val_loss: 2.6675 - val_accuracy: 0.7486\n",
      "Epoch 839/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9635 - val_loss: 2.8628 - val_accuracy: 0.7207\n",
      "Epoch 840/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9649 - val_loss: 2.5136 - val_accuracy: 0.7598\n",
      "Epoch 841/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9649 - val_loss: 2.6035 - val_accuracy: 0.7765\n",
      "Epoch 842/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9649 - val_loss: 2.5396 - val_accuracy: 0.7654\n",
      "Epoch 843/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9649 - val_loss: 2.5331 - val_accuracy: 0.7542\n",
      "Epoch 844/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9691 - val_loss: 2.5978 - val_accuracy: 0.7598\n",
      "Epoch 845/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9691 - val_loss: 2.8814 - val_accuracy: 0.7709\n",
      "Epoch 846/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0789 - accuracy: 0.9607 - val_loss: 2.5310 - val_accuracy: 0.7486\n",
      "Epoch 847/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0897 - accuracy: 0.9649 - val_loss: 2.6211 - val_accuracy: 0.7263\n",
      "Epoch 848/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9579 - val_loss: 2.6914 - val_accuracy: 0.7542\n",
      "Epoch 849/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9663 - val_loss: 2.6840 - val_accuracy: 0.7263\n",
      "Epoch 850/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9649 - val_loss: 2.5824 - val_accuracy: 0.7542\n",
      "Epoch 851/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0835 - accuracy: 0.9635 - val_loss: 2.7923 - val_accuracy: 0.7654\n",
      "Epoch 852/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9537 - val_loss: 2.7214 - val_accuracy: 0.7654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9635 - val_loss: 2.5369 - val_accuracy: 0.7709\n",
      "Epoch 854/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9537 - val_loss: 2.7654 - val_accuracy: 0.7207\n",
      "Epoch 855/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0989 - accuracy: 0.9635 - val_loss: 2.5166 - val_accuracy: 0.7765\n",
      "Epoch 856/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.95 - 0s 6ms/step - loss: 0.0834 - accuracy: 0.9635 - val_loss: 2.7858 - val_accuracy: 0.7709\n",
      "Epoch 857/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9649 - val_loss: 2.8163 - val_accuracy: 0.7765\n",
      "Epoch 858/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9663 - val_loss: 2.8302 - val_accuracy: 0.7765\n",
      "Epoch 859/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9635 - val_loss: 2.9178 - val_accuracy: 0.7765\n",
      "Epoch 860/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9607 - val_loss: 2.6191 - val_accuracy: 0.7765\n",
      "Epoch 861/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0816 - accuracy: 0.9649 - val_loss: 2.7379 - val_accuracy: 0.7765\n",
      "Epoch 862/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9621 - val_loss: 2.5379 - val_accuracy: 0.7598\n",
      "Epoch 863/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9635 - val_loss: 2.7467 - val_accuracy: 0.7765\n",
      "Epoch 864/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9621 - val_loss: 2.7846 - val_accuracy: 0.7877\n",
      "Epoch 865/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9663 - val_loss: 2.6706 - val_accuracy: 0.7542\n",
      "Epoch 866/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0853 - accuracy: 0.9621 - val_loss: 2.9028 - val_accuracy: 0.7654\n",
      "Epoch 867/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.9494 - val_loss: 2.4974 - val_accuracy: 0.7654\n",
      "Epoch 868/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0883 - accuracy: 0.9649 - val_loss: 2.5195 - val_accuracy: 0.7709\n",
      "Epoch 869/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9649 - val_loss: 2.6423 - val_accuracy: 0.7654\n",
      "Epoch 870/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9635 - val_loss: 2.5614 - val_accuracy: 0.7654\n",
      "Epoch 871/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 0.9677 - val_loss: 2.6408 - val_accuracy: 0.7709\n",
      "Epoch 872/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9691 - val_loss: 2.6686 - val_accuracy: 0.7542\n",
      "Epoch 873/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9649 - val_loss: 2.5794 - val_accuracy: 0.7374\n",
      "Epoch 874/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9607 - val_loss: 2.6466 - val_accuracy: 0.7542\n",
      "Epoch 875/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9593 - val_loss: 2.6637 - val_accuracy: 0.7654\n",
      "Epoch 876/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1072 - accuracy: 0.9508 - val_loss: 2.5546 - val_accuracy: 0.7709\n",
      "Epoch 877/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9663 - val_loss: 2.6978 - val_accuracy: 0.7654\n",
      "Epoch 878/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9677 - val_loss: 2.6179 - val_accuracy: 0.7654\n",
      "Epoch 879/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9705 - val_loss: 2.6432 - val_accuracy: 0.7598\n",
      "Epoch 880/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9691 - val_loss: 2.6645 - val_accuracy: 0.7709\n",
      "Epoch 881/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9607 - val_loss: 2.5481 - val_accuracy: 0.7709\n",
      "Epoch 882/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0919 - accuracy: 0.9593 - val_loss: 2.6133 - val_accuracy: 0.7709\n",
      "Epoch 883/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.9579 - val_loss: 2.5766 - val_accuracy: 0.7709\n",
      "Epoch 884/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9663 - val_loss: 2.6766 - val_accuracy: 0.7654\n",
      "Epoch 885/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0803 - accuracy: 0.9621 - val_loss: 2.6846 - val_accuracy: 0.7542\n",
      "Epoch 886/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9649 - val_loss: 2.6023 - val_accuracy: 0.7654\n",
      "Epoch 887/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1022 - accuracy: 0.9621 - val_loss: 2.6028 - val_accuracy: 0.7765\n",
      "Epoch 888/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.9579 - val_loss: 2.6285 - val_accuracy: 0.7654\n",
      "Epoch 889/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9551 - val_loss: 2.4829 - val_accuracy: 0.7598\n",
      "Epoch 890/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0952 - accuracy: 0.9607 - val_loss: 2.4792 - val_accuracy: 0.7598\n",
      "Epoch 891/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.9621 - val_loss: 2.7093 - val_accuracy: 0.7598\n",
      "Epoch 892/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9621 - val_loss: 2.7559 - val_accuracy: 0.7821\n",
      "Epoch 893/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0886 - accuracy: 0.9593 - val_loss: 2.6233 - val_accuracy: 0.7765\n",
      "Epoch 894/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9607 - val_loss: 2.5577 - val_accuracy: 0.7654\n",
      "Epoch 895/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0813 - accuracy: 0.9635 - val_loss: 2.5588 - val_accuracy: 0.7542\n",
      "Epoch 896/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9705 - val_loss: 2.6322 - val_accuracy: 0.7598\n",
      "Epoch 897/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9677 - val_loss: 2.8273 - val_accuracy: 0.7709\n",
      "Epoch 898/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0772 - accuracy: 0.9663 - val_loss: 2.7215 - val_accuracy: 0.7765\n",
      "Epoch 899/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9635 - val_loss: 2.5295 - val_accuracy: 0.7598\n",
      "Epoch 900/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0768 - accuracy: 0.9635 - val_loss: 2.6539 - val_accuracy: 0.7654\n",
      "Epoch 901/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0842 - accuracy: 0.9663 - val_loss: 2.7732 - val_accuracy: 0.7486\n",
      "Epoch 902/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9649 - val_loss: 2.5411 - val_accuracy: 0.7430\n",
      "Epoch 903/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9649 - val_loss: 2.6628 - val_accuracy: 0.7598\n",
      "Epoch 904/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9663 - val_loss: 2.5808 - val_accuracy: 0.7654\n",
      "Epoch 905/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9579 - val_loss: 2.7516 - val_accuracy: 0.7765\n",
      "Epoch 906/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.9635 - val_loss: 2.7754 - val_accuracy: 0.7654\n",
      "Epoch 907/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9621 - val_loss: 2.6433 - val_accuracy: 0.7542\n",
      "Epoch 908/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1506 - accuracy: 0.9424 - val_loss: 2.8757 - val_accuracy: 0.7709\n",
      "Epoch 909/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.9494 - val_loss: 2.5742 - val_accuracy: 0.7654\n",
      "Epoch 910/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9607 - val_loss: 2.6926 - val_accuracy: 0.7765\n",
      "Epoch 911/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2104 - accuracy: 0.9396 - val_loss: 2.3737 - val_accuracy: 0.7765\n",
      "Epoch 912/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1224 - accuracy: 0.9551 - val_loss: 2.4827 - val_accuracy: 0.7542\n",
      "Epoch 913/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.0875 - accuracy: 0.9551 - val_loss: 2.5688 - val_accuracy: 0.7598\n",
      "Epoch 914/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9621 - val_loss: 2.4090 - val_accuracy: 0.7207\n",
      "Epoch 915/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9593 - val_loss: 2.5606 - val_accuracy: 0.7430\n",
      "Epoch 916/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0767 - accuracy: 0.9663 - val_loss: 2.6257 - val_accuracy: 0.7654\n",
      "Epoch 917/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9649 - val_loss: 2.4790 - val_accuracy: 0.7598\n",
      "Epoch 918/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9607 - val_loss: 2.5223 - val_accuracy: 0.7207\n",
      "Epoch 919/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9649 - val_loss: 2.5717 - val_accuracy: 0.7486\n",
      "Epoch 920/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9663 - val_loss: 2.5471 - val_accuracy: 0.7709\n",
      "Epoch 921/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0738 - accuracy: 0.9649 - val_loss: 2.4832 - val_accuracy: 0.7430\n",
      "Epoch 922/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9649 - val_loss: 2.5383 - val_accuracy: 0.7598\n",
      "Epoch 923/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0709 - accuracy: 0.9705 - val_loss: 2.6431 - val_accuracy: 0.7318\n",
      "Epoch 924/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0783 - accuracy: 0.9663 - val_loss: 2.6585 - val_accuracy: 0.7542\n",
      "Epoch 925/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9705 - val_loss: 2.8392 - val_accuracy: 0.7654\n",
      "Epoch 926/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9663 - val_loss: 2.6918 - val_accuracy: 0.7654\n",
      "Epoch 927/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9677 - val_loss: 2.7249 - val_accuracy: 0.7374\n",
      "Epoch 928/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9621 - val_loss: 2.7646 - val_accuracy: 0.7598\n",
      "Epoch 929/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0748 - accuracy: 0.9663 - val_loss: 2.7363 - val_accuracy: 0.7542\n",
      "Epoch 930/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9635 - val_loss: 2.4996 - val_accuracy: 0.7542\n",
      "Epoch 931/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9635 - val_loss: 2.6498 - val_accuracy: 0.7263\n",
      "Epoch 932/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9621 - val_loss: 2.5937 - val_accuracy: 0.7318\n",
      "Epoch 933/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 0.9635 - val_loss: 2.8310 - val_accuracy: 0.7318\n",
      "Epoch 934/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0794 - accuracy: 0.9663 - val_loss: 2.7152 - val_accuracy: 0.7654\n",
      "Epoch 935/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9677 - val_loss: 3.0006 - val_accuracy: 0.7542\n",
      "Epoch 936/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9691 - val_loss: 2.7271 - val_accuracy: 0.7374\n",
      "Epoch 937/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9677 - val_loss: 2.6112 - val_accuracy: 0.7654\n",
      "Epoch 938/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0736 - accuracy: 0.9691 - val_loss: 2.6598 - val_accuracy: 0.7654\n",
      "Epoch 939/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9663 - val_loss: 2.7028 - val_accuracy: 0.7542\n",
      "Epoch 940/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9677 - val_loss: 2.5566 - val_accuracy: 0.7654\n",
      "Epoch 941/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9677 - val_loss: 2.7273 - val_accuracy: 0.7654\n",
      "Epoch 942/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0781 - accuracy: 0.9649 - val_loss: 2.5200 - val_accuracy: 0.7542\n",
      "Epoch 943/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9677 - val_loss: 2.7236 - val_accuracy: 0.7654\n",
      "Epoch 944/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9649 - val_loss: 2.7606 - val_accuracy: 0.7654\n",
      "Epoch 945/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9649 - val_loss: 2.7498 - val_accuracy: 0.7263\n",
      "Epoch 946/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9691 - val_loss: 2.9119 - val_accuracy: 0.7654\n",
      "Epoch 947/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9663 - val_loss: 2.9327 - val_accuracy: 0.7430\n",
      "Epoch 948/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0743 - accuracy: 0.9663 - val_loss: 2.7548 - val_accuracy: 0.7709\n",
      "Epoch 949/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9649 - val_loss: 2.7656 - val_accuracy: 0.7598\n",
      "Epoch 950/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9663 - val_loss: 2.7633 - val_accuracy: 0.7654\n",
      "Epoch 951/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0746 - accuracy: 0.9663 - val_loss: 2.9626 - val_accuracy: 0.7374\n",
      "Epoch 952/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9579 - val_loss: 3.1068 - val_accuracy: 0.7654\n",
      "Epoch 953/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9621 - val_loss: 2.6594 - val_accuracy: 0.7654\n",
      "Epoch 954/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9677 - val_loss: 2.7196 - val_accuracy: 0.7598\n",
      "Epoch 955/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9649 - val_loss: 2.7282 - val_accuracy: 0.7765\n",
      "Epoch 956/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9649 - val_loss: 2.6326 - val_accuracy: 0.7542\n",
      "Epoch 957/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0761 - accuracy: 0.9663 - val_loss: 2.7576 - val_accuracy: 0.7709\n",
      "Epoch 958/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 0.9607 - val_loss: 2.8008 - val_accuracy: 0.7709\n",
      "Epoch 959/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9663 - val_loss: 2.7941 - val_accuracy: 0.7709\n",
      "Epoch 960/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0791 - accuracy: 0.9635 - val_loss: 2.6594 - val_accuracy: 0.7430\n",
      "Epoch 961/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9733 - val_loss: 2.6173 - val_accuracy: 0.7374\n",
      "Epoch 962/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9677 - val_loss: 2.8117 - val_accuracy: 0.7709\n",
      "Epoch 963/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0856 - accuracy: 0.9607 - val_loss: 2.8084 - val_accuracy: 0.7765\n",
      "Epoch 964/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.9649 - val_loss: 2.7592 - val_accuracy: 0.7654\n",
      "Epoch 965/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9691 - val_loss: 2.6081 - val_accuracy: 0.7542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 966/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0779 - accuracy: 0.9635 - val_loss: 2.6455 - val_accuracy: 0.7486\n",
      "Epoch 967/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9663 - val_loss: 2.6284 - val_accuracy: 0.7486\n",
      "Epoch 968/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0814 - accuracy: 0.9635 - val_loss: 2.6671 - val_accuracy: 0.7486\n",
      "Epoch 969/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1034 - accuracy: 0.9579 - val_loss: 3.0194 - val_accuracy: 0.7765\n",
      "Epoch 970/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9607 - val_loss: 2.7379 - val_accuracy: 0.7654\n",
      "Epoch 971/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9635 - val_loss: 2.7321 - val_accuracy: 0.7709\n",
      "Epoch 972/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9607 - val_loss: 2.9124 - val_accuracy: 0.7654\n",
      "Epoch 973/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9480 - val_loss: 2.6205 - val_accuracy: 0.7765\n",
      "Epoch 974/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9579 - val_loss: 2.6868 - val_accuracy: 0.7486\n",
      "Epoch 975/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0854 - accuracy: 0.9607 - val_loss: 2.7816 - val_accuracy: 0.7709\n",
      "Epoch 976/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9719 - val_loss: 2.8068 - val_accuracy: 0.7654\n",
      "Epoch 977/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9663 - val_loss: 2.6620 - val_accuracy: 0.7542\n",
      "Epoch 978/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9621 - val_loss: 2.7209 - val_accuracy: 0.7654\n",
      "Epoch 979/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9579 - val_loss: 2.6909 - val_accuracy: 0.7374\n",
      "Epoch 980/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0880 - accuracy: 0.9635 - val_loss: 2.8727 - val_accuracy: 0.7542\n",
      "Epoch 981/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9677 - val_loss: 2.9016 - val_accuracy: 0.7486\n",
      "Epoch 982/1000\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0892 - accuracy: 0.9677 - val_loss: 2.7954 - val_accuracy: 0.7486\n",
      "Epoch 983/1000\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.0783 - accuracy: 0.9635 - val_loss: 2.8228 - val_accuracy: 0.7654\n",
      "Epoch 984/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0797 - accuracy: 0.9607 - val_loss: 2.7141 - val_accuracy: 0.7598\n",
      "Epoch 985/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9593 - val_loss: 2.6564 - val_accuracy: 0.7598\n",
      "Epoch 986/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.9635 - val_loss: 2.8078 - val_accuracy: 0.7654\n",
      "Epoch 987/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9579 - val_loss: 2.6450 - val_accuracy: 0.7374\n",
      "Epoch 988/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9537 - val_loss: 2.8609 - val_accuracy: 0.7709\n",
      "Epoch 989/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9635 - val_loss: 2.6464 - val_accuracy: 0.7654\n",
      "Epoch 990/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9635 - val_loss: 2.8325 - val_accuracy: 0.7486\n",
      "Epoch 991/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9635 - val_loss: 2.9983 - val_accuracy: 0.7709\n",
      "Epoch 992/1000\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.1058 - accuracy: 0.9579 - val_loss: 2.7224 - val_accuracy: 0.7598\n",
      "Epoch 993/1000\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.7182 - accuracy: 0.9003 - val_loss: 2.8269 - val_accuracy: 0.7765\n",
      "Epoch 994/1000\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3026 - accuracy: 0.9003 - val_loss: 2.4509 - val_accuracy: 0.7318\n",
      "Epoch 995/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1938 - accuracy: 0.9284 - val_loss: 2.8008 - val_accuracy: 0.7654\n",
      "Epoch 996/1000\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.1291 - accuracy: 0.9452 - val_loss: 2.2841 - val_accuracy: 0.7765\n",
      "Epoch 997/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0999 - accuracy: 0.9551 - val_loss: 2.3205 - val_accuracy: 0.7765\n",
      "Epoch 998/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0904 - accuracy: 0.9635 - val_loss: 2.6878 - val_accuracy: 0.7709\n",
      "Epoch 999/1000\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1018 - accuracy: 0.9579 - val_loss: 2.3943 - val_accuracy: 0.7654\n",
      "Epoch 1000/1000\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.0942 - accuracy: 0.9677 - val_loss: 2.6665 - val_accuracy: 0.7486\n"
     ]
    }
   ],
   "source": [
    "printlog(\"step4: train model...\")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "          validation_data=ds_test,\n",
    "          epochs=1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T16:38:18.434000Z",
     "start_time": "2020-05-13T16:38:18.426685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T01:31:56.590642Z",
     "start_time": "2020-05-14T01:31:56.260857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2020-05-14 09:31:56\n",
      "step5: eval model......\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_features (DenseFeature multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  3008      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 7,297\n",
      "Trainable params: 7,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (http://matplotlib.org/) -->\n",
       "<svg height=\"277pt\" version=\"1.1\" viewBox=\"0 0 389 277\" width=\"389pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 389.28125 277.314375 \n",
       "L 389.28125 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 239.758125 \n",
       "L 378.58125 239.758125 \n",
       "L 378.58125 22.318125 \n",
       "L 43.78125 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"mb66bb34c43\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.694764\" xlink:href=\"#mb66bb34c43\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-30\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(55.513514 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"119.628424\" xlink:href=\"#mb66bb34c43\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-32\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(110.084674 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"180.562085\" xlink:href=\"#mb66bb34c43\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-34\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(171.018335 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.495746\" xlink:href=\"#mb66bb34c43\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-36\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(231.951996 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.429407\" xlink:href=\"#mb66bb34c43\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-38\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(292.885657 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.363068\" xlink:href=\"#mb66bb34c43\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-31\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(350.638068 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Epochs -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-45\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-70\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-6f\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-63\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-68\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-73\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(193.265625 268.034687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-70\"/>\n",
       "      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-6f\"/>\n",
       "      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-68\"/>\n",
       "      <use x=\"306.201172\" xlink:href=\"#DejaVuSans-73\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"md7508b58c3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#md7508b58c3\" y=\"236.544439\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.5 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-2e\"/>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-35\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 240.343658)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#md7508b58c3\" y=\"193.371741\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(20.878125 197.17096)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#md7508b58c3\" y=\"150.199042\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.7 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-37\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 153.998261)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-37\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#md7508b58c3\" y=\"107.026344\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(20.878125 110.825563)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#md7508b58c3\" y=\"63.853645\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.9 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.984375 1.515625 \n",
       "L 10.984375 10.5 \n",
       "Q 14.703125 8.734375 18.5 7.8125 \n",
       "Q 22.3125 6.890625 25.984375 6.890625 \n",
       "Q 35.75 6.890625 40.890625 13.453125 \n",
       "Q 46.046875 20.015625 46.78125 33.40625 \n",
       "Q 43.953125 29.203125 39.59375 26.953125 \n",
       "Q 35.25 24.703125 29.984375 24.703125 \n",
       "Q 19.046875 24.703125 12.671875 31.3125 \n",
       "Q 6.296875 37.9375 6.296875 49.421875 \n",
       "Q 6.296875 60.640625 12.9375 67.421875 \n",
       "Q 19.578125 74.21875 30.609375 74.21875 \n",
       "Q 43.265625 74.21875 49.921875 64.515625 \n",
       "Q 56.59375 54.828125 56.59375 36.375 \n",
       "Q 56.59375 19.140625 48.40625 8.859375 \n",
       "Q 40.234375 -1.421875 26.421875 -1.421875 \n",
       "Q 22.703125 -1.421875 18.890625 -0.6875 \n",
       "Q 15.09375 0.046875 10.984375 1.515625 \n",
       "z\n",
       "M 30.609375 32.421875 \n",
       "Q 37.25 32.421875 41.125 36.953125 \n",
       "Q 45.015625 41.5 45.015625 49.421875 \n",
       "Q 45.015625 57.28125 41.125 61.84375 \n",
       "Q 37.25 66.40625 30.609375 66.40625 \n",
       "Q 23.96875 66.40625 20.09375 61.84375 \n",
       "Q 16.21875 57.28125 16.21875 49.421875 \n",
       "Q 16.21875 41.5 20.09375 36.953125 \n",
       "Q 23.96875 32.421875 30.609375 32.421875 \n",
       "z\n",
       "\" id=\"DejaVuSans-39\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 67.652864)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-39\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- accuracy -->\n",
       "     <defs>\n",
       "      <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-61\"/>\n",
       "      <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-75\"/>\n",
       "      <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-72\"/>\n",
       "      <path d=\"M 32.171875 -5.078125 \n",
       "Q 28.375 -14.84375 24.75 -17.8125 \n",
       "Q 21.140625 -20.796875 15.09375 -20.796875 \n",
       "L 7.90625 -20.796875 \n",
       "L 7.90625 -13.28125 \n",
       "L 13.1875 -13.28125 \n",
       "Q 16.890625 -13.28125 18.9375 -11.515625 \n",
       "Q 21 -9.765625 23.484375 -3.21875 \n",
       "L 25.09375 0.875 \n",
       "L 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 11.921875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-79\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 153.5975)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-75\"/>\n",
       "      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path clip-path=\"url(#pf0d795a724)\" d=\"M 58.999432 229.874489 \n",
       "L 59.3041 155.292444 \n",
       "L 59.608768 149.835235 \n",
       "L 59.913437 146.803432 \n",
       "L 60.522773 137.101705 \n",
       "L 60.827442 135.888989 \n",
       "L 61.13211 129.825409 \n",
       "L 61.436778 129.219064 \n",
       "L 61.741447 123.761829 \n",
       "L 62.046115 111.028299 \n",
       "L 62.350783 112.241015 \n",
       "L 62.655451 118.910965 \n",
       "L 62.96012 105.57109 \n",
       "L 63.264788 103.752003 \n",
       "L 63.569456 104.964719 \n",
       "L 63.874125 104.358374 \n",
       "L 64.178793 97.688423 \n",
       "L 64.483461 106.783806 \n",
       "L 65.092798 99.50751 \n",
       "L 65.397466 102.539287 \n",
       "L 65.702135 98.294794 \n",
       "L 66.006803 101.326571 \n",
       "L 66.311471 102.539287 \n",
       "L 66.616139 101.932942 \n",
       "L 66.920808 95.262991 \n",
       "L 67.225476 97.688423 \n",
       "L 67.530144 94.656646 \n",
       "L 67.834813 94.656646 \n",
       "L 68.139481 92.837559 \n",
       "L 68.444149 96.475707 \n",
       "L 68.748818 97.082078 \n",
       "L 69.053486 94.656646 \n",
       "L 69.358154 96.475707 \n",
       "L 69.662822 94.050275 \n",
       "L 69.967491 94.656646 \n",
       "L 70.272159 94.656646 \n",
       "L 70.576827 92.837559 \n",
       "L 70.881496 94.656646 \n",
       "L 71.186164 91.624843 \n",
       "L 71.490832 92.837559 \n",
       "L 71.795501 98.294794 \n",
       "L 72.100169 89.805782 \n",
       "L 72.404837 90.412127 \n",
       "L 72.709506 94.656646 \n",
       "L 73.014174 91.018498 \n",
       "L 73.318842 91.018498 \n",
       "L 73.62351 97.688423 \n",
       "L 73.928179 88.593066 \n",
       "L 74.232847 97.688423 \n",
       "L 74.537515 92.231214 \n",
       "L 74.842184 89.805782 \n",
       "L 75.45152 87.38035 \n",
       "L 75.756189 89.199412 \n",
       "L 76.060857 88.593066 \n",
       "L 76.365525 86.77398 \n",
       "L 76.670193 81.923116 \n",
       "L 77.27953 84.954919 \n",
       "L 77.584198 81.923116 \n",
       "L 77.888867 86.167634 \n",
       "L 78.193535 82.529487 \n",
       "L 78.498203 86.167634 \n",
       "L 78.802872 81.316771 \n",
       "L 79.10754 84.954919 \n",
       "L 79.412208 84.348548 \n",
       "L 79.716877 81.316771 \n",
       "L 80.326213 78.891339 \n",
       "L 80.630881 88.593066 \n",
       "L 80.93555 80.7104 \n",
       "L 81.240218 83.135832 \n",
       "L 81.544886 78.284968 \n",
       "L 81.849555 78.891339 \n",
       "L 82.154223 80.104055 \n",
       "L 82.458891 79.497684 \n",
       "L 82.76356 78.284968 \n",
       "L 83.068228 79.497684 \n",
       "L 83.372896 77.072252 \n",
       "L 83.677564 81.923116 \n",
       "L 83.982233 81.316771 \n",
       "L 84.286901 80.104055 \n",
       "L 84.591569 94.656646 \n",
       "L 84.896238 80.104055 \n",
       "L 85.200906 87.986696 \n",
       "L 85.505574 78.284968 \n",
       "L 85.810243 78.891339 \n",
       "L 86.114911 80.104055 \n",
       "L 86.419579 77.072252 \n",
       "L 86.724248 78.284968 \n",
       "L 87.028916 81.316771 \n",
       "L 87.333584 77.678623 \n",
       "L 87.942921 78.891339 \n",
       "L 88.247589 77.678623 \n",
       "L 88.552257 71.008672 \n",
       "L 88.856926 75.859536 \n",
       "L 89.161594 74.040449 \n",
       "L 89.466262 76.465907 \n",
       "L 89.770931 74.64682 \n",
       "L 90.075599 74.040449 \n",
       "L 90.380267 75.859536 \n",
       "L 90.684936 76.465907 \n",
       "L 90.989604 74.040449 \n",
       "L 91.294272 74.64682 \n",
       "L 91.59894 72.221388 \n",
       "L 92.208277 80.7104 \n",
       "L 92.512945 76.465907 \n",
       "L 92.817614 74.64682 \n",
       "L 93.122282 77.678623 \n",
       "L 93.42695 74.64682 \n",
       "L 93.731619 73.434104 \n",
       "L 94.036287 75.859536 \n",
       "L 94.340955 75.253191 \n",
       "L 94.645623 72.221388 \n",
       "L 94.950292 74.040449 \n",
       "L 95.25496 67.370524 \n",
       "L 95.559628 72.221388 \n",
       "L 95.864297 70.402301 \n",
       "L 96.168965 65.551437 \n",
       "L 96.473633 71.008672 \n",
       "L 96.778302 71.615017 \n",
       "L 97.08297 71.008672 \n",
       "L 97.387638 98.294794 \n",
       "L 97.692307 71.615017 \n",
       "L 97.996975 68.58324 \n",
       "L 98.301643 73.434104 \n",
       "L 98.606311 67.976869 \n",
       "L 99.215648 67.976869 \n",
       "L 99.520316 72.221388 \n",
       "L 99.824985 67.370524 \n",
       "L 100.129653 66.764153 \n",
       "L 100.434321 67.976869 \n",
       "L 100.73899 64.338721 \n",
       "L 101.348326 72.827733 \n",
       "L 101.652994 73.434104 \n",
       "L 101.957663 65.551437 \n",
       "L 102.262331 66.764153 \n",
       "L 102.566999 66.764153 \n",
       "L 102.871668 67.370524 \n",
       "L 103.176336 64.338721 \n",
       "L 103.481004 67.976869 \n",
       "L 103.785673 66.157808 \n",
       "L 104.090341 66.157808 \n",
       "L 104.395009 60.094228 \n",
       "L 104.699678 60.094228 \n",
       "L 105.004346 64.945092 \n",
       "L 105.309014 65.551437 \n",
       "L 105.613682 68.58324 \n",
       "L 106.223019 63.126005 \n",
       "L 106.527687 60.700574 \n",
       "L 106.832356 62.51966 \n",
       "L 107.137024 63.126005 \n",
       "L 107.441692 62.51966 \n",
       "L 107.746361 66.764153 \n",
       "L 108.051029 66.157808 \n",
       "L 108.355697 72.221388 \n",
       "L 108.660365 60.700574 \n",
       "L 108.965034 61.306944 \n",
       "L 109.269702 60.094228 \n",
       "L 109.57437 63.732376 \n",
       "L 109.879039 65.551437 \n",
       "L 110.183707 60.094228 \n",
       "L 110.488375 60.700574 \n",
       "L 110.793044 67.370524 \n",
       "L 111.097712 60.094228 \n",
       "L 111.40238 61.306944 \n",
       "L 111.707049 71.008672 \n",
       "L 112.011717 59.487858 \n",
       "L 112.316385 63.732376 \n",
       "L 112.621053 60.700574 \n",
       "L 112.925722 59.487858 \n",
       "L 113.23039 59.487858 \n",
       "L 113.535058 62.51966 \n",
       "L 113.839727 60.700574 \n",
       "L 114.144395 67.370524 \n",
       "L 114.449063 71.008672 \n",
       "L 114.753732 80.104055 \n",
       "L 115.0584 75.859536 \n",
       "L 115.363068 64.945092 \n",
       "L 115.972405 55.84971 \n",
       "L 116.277073 58.275142 \n",
       "L 116.581741 58.881512 \n",
       "L 116.88641 57.062426 \n",
       "L 117.191078 57.668797 \n",
       "L 117.495746 57.062426 \n",
       "L 117.800415 57.062426 \n",
       "L 118.105083 55.243365 \n",
       "L 118.409751 57.062426 \n",
       "L 118.71442 56.456081 \n",
       "L 119.019088 55.243365 \n",
       "L 119.323756 58.275142 \n",
       "L 119.933093 54.030649 \n",
       "L 120.237761 58.881512 \n",
       "L 120.542429 54.030649 \n",
       "L 120.847098 53.424278 \n",
       "L 121.151766 56.456081 \n",
       "L 121.456434 57.668797 \n",
       "L 121.761103 50.998846 \n",
       "L 122.065771 58.275142 \n",
       "L 122.370439 52.817933 \n",
       "L 122.675107 51.605217 \n",
       "L 122.979776 54.030649 \n",
       "L 123.284444 52.817933 \n",
       "L 123.589112 54.030649 \n",
       "L 123.893781 53.424278 \n",
       "L 124.198449 49.179785 \n",
       "L 124.503117 54.030649 \n",
       "L 124.807786 52.211562 \n",
       "L 125.112454 51.605217 \n",
       "L 125.417122 54.636994 \n",
       "L 125.721791 52.211562 \n",
       "L 126.026459 56.456081 \n",
       "L 126.331127 49.78613 \n",
       "L 126.635795 51.605217 \n",
       "L 126.940464 55.84971 \n",
       "L 127.245132 53.424278 \n",
       "L 127.5498 62.51966 \n",
       "L 127.854469 54.636994 \n",
       "L 128.159137 57.062426 \n",
       "L 128.463805 54.030649 \n",
       "L 128.768474 48.573414 \n",
       "L 129.073142 53.424278 \n",
       "L 129.37781 52.817933 \n",
       "L 129.682479 57.668797 \n",
       "L 129.987147 53.424278 \n",
       "L 130.291815 55.84971 \n",
       "L 130.596483 50.998846 \n",
       "L 130.901152 52.817933 \n",
       "L 131.20582 52.211562 \n",
       "L 131.510488 49.179785 \n",
       "L 131.815157 49.78613 \n",
       "L 132.119825 49.78613 \n",
       "L 132.424493 52.211562 \n",
       "L 132.729162 51.605217 \n",
       "L 133.03383 52.817933 \n",
       "L 133.338498 50.392501 \n",
       "L 133.643166 53.424278 \n",
       "L 133.947835 52.817933 \n",
       "L 134.557171 48.573414 \n",
       "L 134.86184 51.605217 \n",
       "L 135.166508 47.967069 \n",
       "L 135.471176 47.967069 \n",
       "L 135.775845 48.573414 \n",
       "L 136.080513 49.78613 \n",
       "L 136.385181 49.78613 \n",
       "L 136.68985 52.211562 \n",
       "L 136.994518 51.605217 \n",
       "L 137.299186 50.392501 \n",
       "L 137.603854 51.605217 \n",
       "L 137.908523 53.424278 \n",
       "L 138.213191 50.392501 \n",
       "L 138.517859 49.179785 \n",
       "L 138.822528 46.147982 \n",
       "L 139.127196 46.147982 \n",
       "L 139.431864 49.179785 \n",
       "L 139.736533 47.360698 \n",
       "L 140.041201 49.179785 \n",
       "L 140.345869 49.179785 \n",
       "L 140.955206 46.147982 \n",
       "L 141.259874 48.573414 \n",
       "L 141.564542 46.147982 \n",
       "L 141.869211 47.360698 \n",
       "L 142.173879 46.754353 \n",
       "L 142.478547 46.754353 \n",
       "L 142.783216 47.967069 \n",
       "L 143.087884 46.754353 \n",
       "L 143.392552 46.147982 \n",
       "L 143.697221 46.147982 \n",
       "L 144.001889 46.754353 \n",
       "L 144.306557 44.935266 \n",
       "L 144.611225 48.573414 \n",
       "L 144.915894 49.78613 \n",
       "L 145.220562 46.754353 \n",
       "L 145.52523 44.935266 \n",
       "L 145.829899 44.935266 \n",
       "L 146.134567 46.754353 \n",
       "L 146.439235 43.72255 \n",
       "L 146.743904 44.935266 \n",
       "L 147.048572 49.179785 \n",
       "L 147.35324 43.72255 \n",
       "L 147.657908 44.328921 \n",
       "L 147.962577 43.72255 \n",
       "L 148.267245 46.754353 \n",
       "L 148.571913 44.328921 \n",
       "L 148.876582 44.328921 \n",
       "L 149.18125 45.541637 \n",
       "L 149.485918 44.935266 \n",
       "L 149.790587 47.967069 \n",
       "L 150.095255 47.967069 \n",
       "L 150.399923 48.573414 \n",
       "L 150.704592 47.360698 \n",
       "L 151.00926 43.72255 \n",
       "L 151.313928 43.116205 \n",
       "L 151.618596 43.116205 \n",
       "L 152.227933 54.030649 \n",
       "L 152.532601 47.360698 \n",
       "L 152.83727 49.179785 \n",
       "L 153.141938 46.147982 \n",
       "L 153.446606 45.541637 \n",
       "L 153.751275 47.360698 \n",
       "L 154.055943 41.297118 \n",
       "L 154.360611 43.116205 \n",
       "L 154.665279 46.147982 \n",
       "L 154.969948 44.935266 \n",
       "L 155.274616 47.360698 \n",
       "L 155.579284 42.509834 \n",
       "L 155.883953 44.935266 \n",
       "L 156.188621 42.509834 \n",
       "L 156.493289 44.935266 \n",
       "L 156.797958 43.116205 \n",
       "L 157.102626 44.328921 \n",
       "L 158.016631 44.328921 \n",
       "L 158.321299 41.903489 \n",
       "L 158.625967 43.116205 \n",
       "L 158.930636 41.297118 \n",
       "L 159.235304 41.903489 \n",
       "L 159.539972 41.903489 \n",
       "L 159.844641 47.360698 \n",
       "L 160.149309 46.147982 \n",
       "L 160.453977 42.509834 \n",
       "L 160.758646 43.116205 \n",
       "L 161.063314 44.935266 \n",
       "L 161.67265 41.903489 \n",
       "L 161.977319 43.72255 \n",
       "L 162.281987 43.72255 \n",
       "L 162.586655 41.903489 \n",
       "L 162.891324 43.72255 \n",
       "L 163.195992 42.509834 \n",
       "L 163.50066 42.509834 \n",
       "L 163.805329 41.903489 \n",
       "L 164.109997 40.084402 \n",
       "L 164.414665 41.903489 \n",
       "L 164.719334 41.297118 \n",
       "L 165.024002 41.297118 \n",
       "L 165.32867 42.509834 \n",
       "L 165.633338 43.116205 \n",
       "L 165.938007 39.478057 \n",
       "L 166.242675 43.72255 \n",
       "L 166.547343 44.328921 \n",
       "L 166.852012 41.297118 \n",
       "L 167.15668 41.297118 \n",
       "L 167.461348 44.328921 \n",
       "L 167.766017 43.72255 \n",
       "L 168.070685 41.297118 \n",
       "L 168.375353 41.297118 \n",
       "L 168.680021 40.690773 \n",
       "L 168.98469 41.903489 \n",
       "L 169.289358 41.903489 \n",
       "L 169.594026 43.116205 \n",
       "L 169.898695 40.690773 \n",
       "L 170.203363 45.541637 \n",
       "L 170.508031 38.871686 \n",
       "L 170.8127 41.903489 \n",
       "L 171.117368 46.754353 \n",
       "L 171.422036 41.903489 \n",
       "L 171.726705 43.72255 \n",
       "L 172.031373 41.903489 \n",
       "L 172.336041 43.116205 \n",
       "L 172.640709 47.967069 \n",
       "L 172.945378 58.881512 \n",
       "L 173.250046 62.51966 \n",
       "L 173.859383 46.754353 \n",
       "L 174.164051 43.116205 \n",
       "L 174.468719 41.297118 \n",
       "L 174.773388 41.903489 \n",
       "L 175.382724 39.478057 \n",
       "L 175.687393 41.903489 \n",
       "L 175.992061 41.297118 \n",
       "L 176.296729 43.72255 \n",
       "L 176.601397 41.903489 \n",
       "L 176.906066 43.116205 \n",
       "L 177.210734 43.72255 \n",
       "L 177.515402 38.871686 \n",
       "L 177.820071 43.72255 \n",
       "L 178.124739 40.690773 \n",
       "L 178.429407 43.72255 \n",
       "L 179.038744 40.690773 \n",
       "L 179.343412 41.297118 \n",
       "L 179.64808 38.871686 \n",
       "L 179.952749 40.690773 \n",
       "L 180.257417 41.297118 \n",
       "L 180.562085 40.084402 \n",
       "L 180.866754 41.297118 \n",
       "L 181.171422 43.72255 \n",
       "L 181.47609 41.297118 \n",
       "L 181.780759 41.903489 \n",
       "L 182.085427 40.690773 \n",
       "L 182.390095 41.297118 \n",
       "L 182.694764 43.116205 \n",
       "L 182.999432 41.903489 \n",
       "L 183.3041 41.903489 \n",
       "L 183.608768 38.871686 \n",
       "L 183.913437 41.903489 \n",
       "L 184.218105 39.478057 \n",
       "L 184.522773 39.478057 \n",
       "L 184.827442 41.297118 \n",
       "L 185.13211 41.297118 \n",
       "L 185.436778 43.72255 \n",
       "L 185.741447 40.690773 \n",
       "L 186.046115 40.084402 \n",
       "L 186.350783 42.509834 \n",
       "L 186.655451 41.297118 \n",
       "L 186.96012 40.690773 \n",
       "L 187.264788 39.478057 \n",
       "L 187.569456 39.478057 \n",
       "L 187.874125 40.690773 \n",
       "L 188.178793 38.871686 \n",
       "L 188.483461 40.084402 \n",
       "L 188.78813 38.265341 \n",
       "L 189.092798 41.903489 \n",
       "L 189.702135 38.871686 \n",
       "L 190.006803 41.297118 \n",
       "L 190.311471 39.478057 \n",
       "L 190.616139 39.478057 \n",
       "L 190.920808 41.297118 \n",
       "L 191.225476 39.478057 \n",
       "L 191.530144 41.903489 \n",
       "L 191.834813 40.690773 \n",
       "L 192.139481 40.084402 \n",
       "L 192.444149 42.509834 \n",
       "L 192.748818 39.478057 \n",
       "L 193.053486 37.65897 \n",
       "L 193.358154 43.116205 \n",
       "L 193.662822 37.052625 \n",
       "L 193.967491 38.871686 \n",
       "L 194.272159 36.446254 \n",
       "L 194.576827 40.084402 \n",
       "L 194.881496 40.084402 \n",
       "L 195.186164 41.903489 \n",
       "L 195.490832 40.690773 \n",
       "L 195.795501 40.690773 \n",
       "L 196.100169 37.65897 \n",
       "L 196.709506 44.328921 \n",
       "L 197.014174 40.084402 \n",
       "L 197.62351 40.084402 \n",
       "L 197.928179 38.265341 \n",
       "L 198.232847 41.297118 \n",
       "L 198.537515 38.871686 \n",
       "L 199.146852 43.116205 \n",
       "L 199.45152 38.871686 \n",
       "L 199.756189 38.871686 \n",
       "L 200.060857 40.084402 \n",
       "L 200.365525 45.541637 \n",
       "L 200.670193 43.72255 \n",
       "L 200.974862 38.871686 \n",
       "L 201.27953 40.084402 \n",
       "L 201.584198 39.478057 \n",
       "L 201.888867 40.690773 \n",
       "L 202.193535 38.265341 \n",
       "L 202.498203 41.903489 \n",
       "L 202.802872 40.084402 \n",
       "L 203.10754 39.478057 \n",
       "L 203.412208 37.65897 \n",
       "L 203.716877 39.478057 \n",
       "L 204.021545 39.478057 \n",
       "L 204.630881 37.052625 \n",
       "L 204.93555 39.478057 \n",
       "L 205.240218 40.690773 \n",
       "L 205.544886 38.265341 \n",
       "L 205.849555 40.690773 \n",
       "L 206.154223 41.903489 \n",
       "L 206.458891 38.871686 \n",
       "L 207.068228 64.338721 \n",
       "L 207.372896 49.78613 \n",
       "L 207.982233 39.478057 \n",
       "L 208.286901 38.871686 \n",
       "L 208.591569 37.65897 \n",
       "L 208.896238 39.478057 \n",
       "L 209.200906 37.052625 \n",
       "L 209.505574 37.65897 \n",
       "L 210.114911 43.116205 \n",
       "L 210.419579 43.116205 \n",
       "L 210.724248 40.084402 \n",
       "L 211.028916 38.871686 \n",
       "L 211.333584 40.690773 \n",
       "L 211.638252 38.265341 \n",
       "L 211.942921 42.509834 \n",
       "L 212.247589 42.509834 \n",
       "L 212.552257 41.903489 \n",
       "L 213.161594 37.65897 \n",
       "L 213.466262 39.478057 \n",
       "L 213.770931 38.871686 \n",
       "L 214.075599 40.690773 \n",
       "L 214.380267 35.233538 \n",
       "L 214.684936 35.839909 \n",
       "L 214.989604 38.871686 \n",
       "L 215.294272 35.839909 \n",
       "L 215.59894 37.052625 \n",
       "L 215.903609 37.052625 \n",
       "L 216.208277 40.690773 \n",
       "L 217.122282 37.052625 \n",
       "L 217.42695 38.265341 \n",
       "L 217.731619 37.052625 \n",
       "L 218.036287 38.265341 \n",
       "L 218.340955 37.65897 \n",
       "L 218.950292 40.690773 \n",
       "L 219.25496 40.084402 \n",
       "L 219.559628 36.446254 \n",
       "L 220.168965 38.871686 \n",
       "L 220.473633 36.446254 \n",
       "L 220.778302 37.052625 \n",
       "L 221.08297 36.446254 \n",
       "L 221.387638 39.478057 \n",
       "L 221.692307 35.233538 \n",
       "L 221.996975 36.446254 \n",
       "L 222.301643 38.265341 \n",
       "L 222.606311 36.446254 \n",
       "L 222.91098 36.446254 \n",
       "L 223.215648 40.084402 \n",
       "L 223.520316 39.478057 \n",
       "L 223.824985 35.839909 \n",
       "L 224.434321 39.478057 \n",
       "L 224.73899 37.052625 \n",
       "L 225.043658 41.297118 \n",
       "L 225.348326 35.839909 \n",
       "L 225.652994 37.65897 \n",
       "L 225.957663 38.265341 \n",
       "L 226.566999 42.509834 \n",
       "L 226.871668 38.871686 \n",
       "L 227.481004 38.871686 \n",
       "L 227.785673 37.65897 \n",
       "L 228.090341 40.690773 \n",
       "L 228.395009 36.446254 \n",
       "L 228.699678 35.233538 \n",
       "L 229.004346 39.478057 \n",
       "L 229.309014 40.084402 \n",
       "L 229.613682 35.839909 \n",
       "L 230.223019 37.052625 \n",
       "L 230.527687 35.839909 \n",
       "L 230.832356 40.690773 \n",
       "L 231.137024 40.690773 \n",
       "L 231.441692 38.871686 \n",
       "L 231.746361 38.871686 \n",
       "L 232.051029 38.265341 \n",
       "L 232.355697 39.478057 \n",
       "L 232.660365 39.478057 \n",
       "L 232.965034 38.871686 \n",
       "L 233.269702 38.871686 \n",
       "L 233.57437 37.052625 \n",
       "L 233.879039 37.052625 \n",
       "L 234.183707 38.265341 \n",
       "L 234.488375 40.690773 \n",
       "L 234.793044 37.052625 \n",
       "L 235.097712 37.65897 \n",
       "L 235.40238 37.052625 \n",
       "L 235.707049 40.690773 \n",
       "L 236.011717 37.65897 \n",
       "L 236.316385 40.084402 \n",
       "L 236.621053 40.084402 \n",
       "L 236.925722 35.233538 \n",
       "L 237.23039 37.052625 \n",
       "L 237.535058 35.839909 \n",
       "L 237.839727 34.020822 \n",
       "L 238.449063 41.297118 \n",
       "L 238.753732 38.265341 \n",
       "L 239.0584 38.871686 \n",
       "L 239.363068 36.446254 \n",
       "L 239.667736 37.052625 \n",
       "L 239.972405 34.627193 \n",
       "L 240.277073 36.446254 \n",
       "L 240.581741 35.839909 \n",
       "L 240.88641 37.65897 \n",
       "L 241.191078 38.265341 \n",
       "L 241.495746 37.052625 \n",
       "L 241.800415 40.690773 \n",
       "L 242.409751 35.233538 \n",
       "L 242.71442 38.871686 \n",
       "L 243.019088 35.839909 \n",
       "L 243.323756 36.446254 \n",
       "L 243.628424 36.446254 \n",
       "L 243.933093 38.265341 \n",
       "L 244.237761 38.871686 \n",
       "L 244.542429 38.265341 \n",
       "L 244.847098 35.839909 \n",
       "L 245.151766 36.446254 \n",
       "L 245.456434 36.446254 \n",
       "L 245.761103 38.265341 \n",
       "L 246.065771 37.65897 \n",
       "L 246.370439 36.446254 \n",
       "L 246.675107 36.446254 \n",
       "L 246.979776 38.265341 \n",
       "L 247.284444 38.265341 \n",
       "L 247.589112 34.627193 \n",
       "L 247.893781 35.839909 \n",
       "L 248.198449 43.116205 \n",
       "L 248.503117 46.754353 \n",
       "L 248.807786 46.754353 \n",
       "L 249.417122 36.446254 \n",
       "L 249.721791 38.871686 \n",
       "L 250.026459 34.627193 \n",
       "L 250.331127 37.052625 \n",
       "L 250.635795 37.052625 \n",
       "L 250.940464 35.839909 \n",
       "L 251.245132 38.871686 \n",
       "L 251.5498 36.446254 \n",
       "L 251.854469 36.446254 \n",
       "L 252.159137 37.65897 \n",
       "L 252.463805 37.052625 \n",
       "L 253.073142 37.052625 \n",
       "L 253.37781 34.020822 \n",
       "L 253.682479 40.690773 \n",
       "L 253.987147 34.627193 \n",
       "L 254.291815 40.084402 \n",
       "L 254.596483 39.478057 \n",
       "L 254.901152 34.627193 \n",
       "L 255.20582 37.65897 \n",
       "L 255.510488 35.839909 \n",
       "L 255.815157 42.509834 \n",
       "L 256.119825 38.265341 \n",
       "L 256.424493 39.478057 \n",
       "L 256.729162 36.446254 \n",
       "L 257.338498 37.65897 \n",
       "L 257.643166 33.414477 \n",
       "L 257.947835 38.871686 \n",
       "L 258.252503 35.233538 \n",
       "L 258.557171 38.265341 \n",
       "L 258.86184 38.871686 \n",
       "L 259.166508 35.839909 \n",
       "L 259.471176 36.446254 \n",
       "L 259.775845 37.65897 \n",
       "L 260.080513 38.265341 \n",
       "L 260.385181 37.65897 \n",
       "L 260.68985 36.446254 \n",
       "L 260.994518 38.871686 \n",
       "L 261.299186 35.233538 \n",
       "L 261.603854 38.265341 \n",
       "L 261.908523 37.052625 \n",
       "L 262.213191 36.446254 \n",
       "L 262.517859 39.478057 \n",
       "L 262.822528 35.839909 \n",
       "L 263.127196 40.084402 \n",
       "L 263.431864 36.446254 \n",
       "L 263.736533 36.446254 \n",
       "L 264.041201 38.871686 \n",
       "L 264.345869 37.052625 \n",
       "L 264.650537 37.052625 \n",
       "L 264.955206 35.839909 \n",
       "L 265.259874 34.020822 \n",
       "L 266.173879 38.871686 \n",
       "L 266.783216 36.446254 \n",
       "L 267.087884 39.478057 \n",
       "L 267.392552 35.839909 \n",
       "L 267.697221 40.084402 \n",
       "L 268.001889 39.478057 \n",
       "L 268.306557 39.478057 \n",
       "L 268.611225 37.65897 \n",
       "L 268.915894 38.871686 \n",
       "L 269.220562 40.690773 \n",
       "L 269.52523 38.265341 \n",
       "L 269.829899 39.478057 \n",
       "L 270.134567 37.65897 \n",
       "L 270.439235 37.65897 \n",
       "L 270.743904 34.627193 \n",
       "L 271.048572 36.446254 \n",
       "L 271.35324 36.446254 \n",
       "L 271.657908 42.509834 \n",
       "L 271.962577 35.839909 \n",
       "L 272.267245 35.839909 \n",
       "L 272.571913 35.233538 \n",
       "L 272.876582 36.446254 \n",
       "L 273.18125 38.265341 \n",
       "L 273.790587 34.627193 \n",
       "L 274.095255 35.839909 \n",
       "L 274.399923 34.020822 \n",
       "L 274.704592 37.052625 \n",
       "L 275.00926 37.65897 \n",
       "L 275.313928 36.446254 \n",
       "L 275.618596 38.265341 \n",
       "L 276.227933 34.627193 \n",
       "L 276.532601 35.839909 \n",
       "L 276.83727 37.65897 \n",
       "L 277.141938 38.265341 \n",
       "L 277.446606 37.052625 \n",
       "L 277.751275 38.265341 \n",
       "L 278.360611 34.627193 \n",
       "L 278.665279 34.020822 \n",
       "L 278.969948 35.233538 \n",
       "L 279.274616 34.020822 \n",
       "L 279.579284 35.839909 \n",
       "L 279.883953 34.627193 \n",
       "L 280.188621 39.478057 \n",
       "L 280.493289 37.65897 \n",
       "L 280.797958 37.052625 \n",
       "L 281.102626 40.690773 \n",
       "L 281.407294 41.297118 \n",
       "L 281.711963 36.446254 \n",
       "L 282.016631 36.446254 \n",
       "L 282.321299 37.052625 \n",
       "L 282.625967 36.446254 \n",
       "L 282.930636 42.509834 \n",
       "L 283.235304 40.084402 \n",
       "L 283.539972 35.839909 \n",
       "L 283.844641 34.627193 \n",
       "L 284.149309 35.839909 \n",
       "L 284.453977 35.233538 \n",
       "L 284.758646 40.084402 \n",
       "L 285.063314 40.690773 \n",
       "L 285.367982 33.414477 \n",
       "L 285.67265 37.65897 \n",
       "L 285.977319 37.65897 \n",
       "L 286.281987 35.233538 \n",
       "L 286.586655 37.052625 \n",
       "L 286.891324 47.967069 \n",
       "L 287.195992 52.817933 \n",
       "L 287.50066 47.360698 \n",
       "L 287.805329 35.839909 \n",
       "L 288.414665 38.871686 \n",
       "L 288.719334 36.446254 \n",
       "L 289.024002 35.233538 \n",
       "L 289.633338 40.690773 \n",
       "L 289.938007 34.020822 \n",
       "L 290.242675 37.052625 \n",
       "L 290.547343 44.328921 \n",
       "L 290.852012 37.052625 \n",
       "L 291.15668 37.052625 \n",
       "L 291.461348 34.627193 \n",
       "L 291.766017 37.65897 \n",
       "L 292.070685 35.839909 \n",
       "L 292.375353 35.839909 \n",
       "L 292.680021 36.446254 \n",
       "L 292.98469 36.446254 \n",
       "L 293.289358 35.233538 \n",
       "L 293.898695 36.446254 \n",
       "L 294.203363 38.265341 \n",
       "L 294.508031 37.65897 \n",
       "L 294.8127 35.233538 \n",
       "L 295.117368 36.446254 \n",
       "L 295.422036 36.446254 \n",
       "L 295.726705 35.839909 \n",
       "L 296.031373 37.052625 \n",
       "L 296.336041 35.839909 \n",
       "L 296.640709 33.414477 \n",
       "L 296.945378 35.233538 \n",
       "L 297.250046 35.839909 \n",
       "L 297.554714 34.627193 \n",
       "L 297.859383 38.265341 \n",
       "L 298.164051 38.871686 \n",
       "L 298.468719 34.627193 \n",
       "L 298.773388 36.446254 \n",
       "L 299.078056 39.478057 \n",
       "L 299.382724 38.265341 \n",
       "L 299.687393 36.446254 \n",
       "L 299.992061 35.839909 \n",
       "L 300.296729 37.052625 \n",
       "L 300.601397 35.839909 \n",
       "L 301.210734 37.052625 \n",
       "L 301.515402 35.233538 \n",
       "L 301.820071 36.446254 \n",
       "L 302.124739 36.446254 \n",
       "L 302.429407 35.233538 \n",
       "L 302.734076 34.627193 \n",
       "L 303.038744 36.446254 \n",
       "L 303.343412 39.478057 \n",
       "L 303.64808 34.020822 \n",
       "L 303.952749 37.65897 \n",
       "L 304.257417 34.020822 \n",
       "L 304.562085 37.65897 \n",
       "L 304.866754 35.233538 \n",
       "L 305.171422 36.446254 \n",
       "L 305.47609 35.839909 \n",
       "L 305.780759 36.446254 \n",
       "L 306.085427 35.839909 \n",
       "L 306.390095 34.020822 \n",
       "L 306.694764 36.446254 \n",
       "L 306.999432 37.052625 \n",
       "L 307.3041 38.871686 \n",
       "L 307.608768 36.446254 \n",
       "L 307.913437 37.65897 \n",
       "L 308.218105 35.839909 \n",
       "L 308.522773 35.839909 \n",
       "L 308.827442 35.233538 \n",
       "L 309.13211 34.020822 \n",
       "L 309.436778 35.839909 \n",
       "L 309.741447 35.839909 \n",
       "L 310.046115 37.65897 \n",
       "L 310.350783 37.65897 \n",
       "L 310.655451 35.839909 \n",
       "L 311.264788 37.052625 \n",
       "L 311.569456 37.052625 \n",
       "L 311.874125 39.478057 \n",
       "L 312.178793 38.871686 \n",
       "L 312.78813 32.808106 \n",
       "L 313.397466 36.446254 \n",
       "L 313.702135 36.446254 \n",
       "L 314.006803 37.65897 \n",
       "L 314.311471 36.446254 \n",
       "L 314.616139 35.839909 \n",
       "L 315.530144 35.839909 \n",
       "L 315.834813 34.020822 \n",
       "L 316.139481 34.020822 \n",
       "L 316.444149 37.65897 \n",
       "L 316.748818 35.839909 \n",
       "L 317.053486 38.871686 \n",
       "L 317.358154 35.233538 \n",
       "L 317.967491 36.446254 \n",
       "L 318.272159 40.690773 \n",
       "L 318.576827 36.446254 \n",
       "L 318.881496 40.690773 \n",
       "L 319.186164 36.446254 \n",
       "L 319.490832 36.446254 \n",
       "L 320.100169 35.233538 \n",
       "L 320.709506 37.65897 \n",
       "L 321.014174 35.839909 \n",
       "L 321.318842 37.052625 \n",
       "L 321.62351 36.446254 \n",
       "L 321.928179 37.052625 \n",
       "L 322.232847 35.233538 \n",
       "L 322.537515 37.052625 \n",
       "L 322.842184 42.509834 \n",
       "L 323.146852 35.839909 \n",
       "L 323.45152 35.839909 \n",
       "L 323.756189 36.446254 \n",
       "L 324.060857 34.627193 \n",
       "L 324.365525 34.020822 \n",
       "L 324.974862 37.65897 \n",
       "L 325.27953 38.265341 \n",
       "L 325.584198 41.903489 \n",
       "L 325.888867 35.233538 \n",
       "L 326.193535 34.627193 \n",
       "L 326.498203 33.414477 \n",
       "L 326.802872 34.020822 \n",
       "L 327.10754 37.65897 \n",
       "L 327.716877 38.871686 \n",
       "L 328.021545 35.233538 \n",
       "L 328.326213 37.052625 \n",
       "L 328.630881 35.839909 \n",
       "L 328.93555 37.052625 \n",
       "L 329.544886 40.084402 \n",
       "L 329.849555 37.65897 \n",
       "L 330.154223 37.052625 \n",
       "L 330.458891 37.052625 \n",
       "L 330.76356 38.265341 \n",
       "L 331.068228 37.65897 \n",
       "L 331.372896 36.446254 \n",
       "L 331.677564 33.414477 \n",
       "L 331.982233 34.627193 \n",
       "L 332.286901 35.233538 \n",
       "L 332.591569 36.446254 \n",
       "L 332.896238 36.446254 \n",
       "L 333.200906 35.233538 \n",
       "L 333.505574 35.839909 \n",
       "L 333.810243 35.839909 \n",
       "L 334.114911 35.233538 \n",
       "L 334.419579 38.871686 \n",
       "L 334.724248 36.446254 \n",
       "L 335.028916 37.052625 \n",
       "L 335.333584 45.541637 \n",
       "L 335.638252 42.509834 \n",
       "L 335.942921 37.65897 \n",
       "L 336.247589 46.754353 \n",
       "L 336.552257 40.084402 \n",
       "L 336.856926 40.084402 \n",
       "L 337.161594 37.052625 \n",
       "L 337.466262 38.265341 \n",
       "L 337.770931 35.233538 \n",
       "L 338.075599 35.839909 \n",
       "L 338.380267 37.65897 \n",
       "L 338.684936 35.839909 \n",
       "L 338.989604 35.233538 \n",
       "L 339.294272 35.839909 \n",
       "L 339.59894 35.839909 \n",
       "L 339.903609 33.414477 \n",
       "L 340.208277 35.233538 \n",
       "L 340.512945 33.414477 \n",
       "L 340.817614 35.233538 \n",
       "L 341.122282 34.627193 \n",
       "L 341.42695 37.052625 \n",
       "L 341.731619 35.233538 \n",
       "L 342.036287 36.446254 \n",
       "L 342.340955 36.446254 \n",
       "L 342.645623 37.052625 \n",
       "L 342.950292 36.446254 \n",
       "L 343.25496 35.233538 \n",
       "L 343.864297 34.020822 \n",
       "L 344.168965 34.627193 \n",
       "L 344.473633 34.020822 \n",
       "L 344.778302 35.233538 \n",
       "L 345.08297 34.627193 \n",
       "L 345.387638 34.627193 \n",
       "L 345.692307 35.839909 \n",
       "L 345.996975 34.627193 \n",
       "L 346.301643 35.839909 \n",
       "L 346.606311 35.839909 \n",
       "L 346.91098 34.020822 \n",
       "L 347.215648 35.233538 \n",
       "L 347.520316 35.233538 \n",
       "L 347.824985 35.839909 \n",
       "L 348.129653 35.233538 \n",
       "L 348.434321 35.233538 \n",
       "L 348.73899 38.871686 \n",
       "L 349.348326 34.627193 \n",
       "L 349.652994 35.839909 \n",
       "L 349.957663 35.839909 \n",
       "L 350.262331 35.233538 \n",
       "L 350.566999 37.65897 \n",
       "L 350.871668 35.233538 \n",
       "L 351.176336 36.446254 \n",
       "L 351.481004 32.201761 \n",
       "L 352.090341 37.65897 \n",
       "L 352.699678 34.020822 \n",
       "L 353.004346 36.446254 \n",
       "L 353.309014 35.233538 \n",
       "L 353.613682 36.446254 \n",
       "L 353.918351 38.871686 \n",
       "L 354.527687 36.446254 \n",
       "L 354.832356 37.65897 \n",
       "L 355.137024 43.116205 \n",
       "L 355.441692 38.871686 \n",
       "L 355.746361 37.65897 \n",
       "L 356.051029 32.808106 \n",
       "L 356.660365 37.052625 \n",
       "L 356.965034 38.871686 \n",
       "L 357.57437 34.627193 \n",
       "L 357.879039 34.627193 \n",
       "L 358.488375 37.65897 \n",
       "L 358.793044 38.265341 \n",
       "L 359.097712 36.446254 \n",
       "L 359.707049 40.690773 \n",
       "L 360.011717 36.446254 \n",
       "L 360.621053 36.446254 \n",
       "L 360.925722 38.871686 \n",
       "L 361.23039 63.732376 \n",
       "L 361.535058 63.732376 \n",
       "L 361.839727 51.605217 \n",
       "L 362.144395 44.328921 \n",
       "L 362.753732 36.446254 \n",
       "L 363.0584 38.871686 \n",
       "L 363.363068 34.627193 \n",
       "L 363.363068 34.627193 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#pf0d795a724)\" d=\"M 58.999432 167.805778 \n",
       "L 59.3041 167.805778 \n",
       "L 59.608768 162.982011 \n",
       "L 59.913437 160.57014 \n",
       "L 60.218105 146.098839 \n",
       "L 60.522773 141.275072 \n",
       "L 60.827442 131.627538 \n",
       "L 61.13211 126.803771 \n",
       "L 61.436778 136.451305 \n",
       "L 61.741447 136.451305 \n",
       "L 62.046115 109.920599 \n",
       "L 62.350783 109.920599 \n",
       "L 62.655451 112.332495 \n",
       "L 62.96012 124.3919 \n",
       "L 63.569456 107.508728 \n",
       "L 64.178793 107.508728 \n",
       "L 64.483461 117.156262 \n",
       "L 64.78813 102.684961 \n",
       "L 65.092798 114.744366 \n",
       "L 65.397466 102.684961 \n",
       "L 65.702135 121.980004 \n",
       "L 66.006803 105.096832 \n",
       "L 66.311471 102.684961 \n",
       "L 66.920808 114.744366 \n",
       "L 67.225476 107.508728 \n",
       "L 67.530144 107.508728 \n",
       "L 67.834813 105.096832 \n",
       "L 68.139481 105.096832 \n",
       "L 68.748818 114.744366 \n",
       "L 69.053486 114.744366 \n",
       "L 69.358154 119.568133 \n",
       "L 69.662822 107.508728 \n",
       "L 69.967491 105.096832 \n",
       "L 70.881496 105.096832 \n",
       "L 71.186164 112.332495 \n",
       "L 71.490832 107.508728 \n",
       "L 71.795501 112.332495 \n",
       "L 72.100169 109.920599 \n",
       "L 72.404837 105.096832 \n",
       "L 72.709506 109.920599 \n",
       "L 73.014174 105.096832 \n",
       "L 73.318842 112.332495 \n",
       "L 73.62351 107.508728 \n",
       "L 73.928179 112.332495 \n",
       "L 74.537515 97.861194 \n",
       "L 74.842184 105.096832 \n",
       "L 75.146852 107.508728 \n",
       "L 75.45152 112.332495 \n",
       "L 75.756189 109.920599 \n",
       "L 76.060857 105.096832 \n",
       "L 76.365525 107.508728 \n",
       "L 76.670193 107.508728 \n",
       "L 76.974862 109.920599 \n",
       "L 77.27953 107.508728 \n",
       "L 77.584198 107.508728 \n",
       "L 77.888867 105.096832 \n",
       "L 78.193535 107.508728 \n",
       "L 78.498203 112.332495 \n",
       "L 79.10754 112.332495 \n",
       "L 79.412208 107.508728 \n",
       "L 79.716877 109.920599 \n",
       "L 80.021545 105.096832 \n",
       "L 80.326213 112.332495 \n",
       "L 80.630881 105.096832 \n",
       "L 80.93555 109.920599 \n",
       "L 81.240218 105.096832 \n",
       "L 81.849555 105.096832 \n",
       "L 82.154223 102.684961 \n",
       "L 82.458891 107.508728 \n",
       "L 82.76356 105.096832 \n",
       "L 83.068228 107.508728 \n",
       "L 83.372896 107.508728 \n",
       "L 83.982233 112.332495 \n",
       "L 84.286901 112.332495 \n",
       "L 84.591569 102.684961 \n",
       "L 84.896238 107.508728 \n",
       "L 85.505574 107.508728 \n",
       "L 85.810243 105.096832 \n",
       "L 86.114911 112.332495 \n",
       "L 86.419579 109.920599 \n",
       "L 86.724248 114.744366 \n",
       "L 87.028916 109.920599 \n",
       "L 87.333584 112.332495 \n",
       "L 87.638252 107.508728 \n",
       "L 87.942921 112.332495 \n",
       "L 88.247589 112.332495 \n",
       "L 88.552257 107.508728 \n",
       "L 88.856926 114.744366 \n",
       "L 89.161594 109.920599 \n",
       "L 89.466262 102.684961 \n",
       "L 90.075599 114.744366 \n",
       "L 90.684936 109.920599 \n",
       "L 90.989604 109.920599 \n",
       "L 91.294272 114.744366 \n",
       "L 91.59894 112.332495 \n",
       "L 91.903609 114.744366 \n",
       "L 92.208277 114.744366 \n",
       "L 92.512945 107.508728 \n",
       "L 92.817614 114.744366 \n",
       "L 93.122282 114.744366 \n",
       "L 93.42695 112.332495 \n",
       "L 93.731619 117.156262 \n",
       "L 94.036287 109.920599 \n",
       "L 94.340955 109.920599 \n",
       "L 94.645623 107.508728 \n",
       "L 94.950292 112.332495 \n",
       "L 95.25496 109.920599 \n",
       "L 95.559628 109.920599 \n",
       "L 95.864297 114.744366 \n",
       "L 96.168965 112.332495 \n",
       "L 96.473633 112.332495 \n",
       "L 96.778302 109.920599 \n",
       "L 97.08297 117.156262 \n",
       "L 97.387638 105.096832 \n",
       "L 97.692307 117.156262 \n",
       "L 97.996975 112.332495 \n",
       "L 98.301643 112.332495 \n",
       "L 98.91098 117.156262 \n",
       "L 99.215648 112.332495 \n",
       "L 99.824985 112.332495 \n",
       "L 100.129653 107.508728 \n",
       "L 100.434321 114.744366 \n",
       "L 100.73899 109.920599 \n",
       "L 101.043658 109.920599 \n",
       "L 101.348326 112.332495 \n",
       "L 101.652994 117.156262 \n",
       "L 101.957663 112.332495 \n",
       "L 102.262331 114.744366 \n",
       "L 102.566999 112.332495 \n",
       "L 102.871668 114.744366 \n",
       "L 103.176336 107.508728 \n",
       "L 103.785673 117.156262 \n",
       "L 104.090341 112.332495 \n",
       "L 104.395009 109.920599 \n",
       "L 104.699678 112.332495 \n",
       "L 105.004346 109.920599 \n",
       "L 105.309014 112.332495 \n",
       "L 105.613682 112.332495 \n",
       "L 106.223019 117.156262 \n",
       "L 106.527687 109.920599 \n",
       "L 106.832356 107.508728 \n",
       "L 107.137024 109.920599 \n",
       "L 107.441692 109.920599 \n",
       "L 107.746361 114.744366 \n",
       "L 108.051029 112.332495 \n",
       "L 108.355697 107.508728 \n",
       "L 108.660365 114.744366 \n",
       "L 109.879039 114.744366 \n",
       "L 110.183707 109.920599 \n",
       "L 110.488375 109.920599 \n",
       "L 110.793044 114.744366 \n",
       "L 111.097712 109.920599 \n",
       "L 111.40238 119.568133 \n",
       "L 111.707049 109.920599 \n",
       "L 112.011717 112.332495 \n",
       "L 112.316385 112.332495 \n",
       "L 112.621053 109.920599 \n",
       "L 112.925722 112.332495 \n",
       "L 113.23039 117.156262 \n",
       "L 113.839727 112.332495 \n",
       "L 114.144395 107.508728 \n",
       "L 114.449063 107.508728 \n",
       "L 114.753732 117.156262 \n",
       "L 115.0584 112.332495 \n",
       "L 115.363068 114.744366 \n",
       "L 115.667736 109.920599 \n",
       "L 115.972405 112.332495 \n",
       "L 116.277073 109.920599 \n",
       "L 116.581741 114.744366 \n",
       "L 116.88641 105.096832 \n",
       "L 117.191078 114.744366 \n",
       "L 117.495746 117.156262 \n",
       "L 117.800415 105.096832 \n",
       "L 118.105083 109.920599 \n",
       "L 118.409751 107.508728 \n",
       "L 118.71442 109.920599 \n",
       "L 119.323756 109.920599 \n",
       "L 119.933093 114.744366 \n",
       "L 120.237761 112.332495 \n",
       "L 120.542429 112.332495 \n",
       "L 120.847098 107.508728 \n",
       "L 121.151766 109.920599 \n",
       "L 121.456434 114.744366 \n",
       "L 121.761103 109.920599 \n",
       "L 122.065771 112.332495 \n",
       "L 122.370439 112.332495 \n",
       "L 122.675107 114.744366 \n",
       "L 122.979776 112.332495 \n",
       "L 123.284444 114.744366 \n",
       "L 123.589112 107.508728 \n",
       "L 123.893781 109.920599 \n",
       "L 124.198449 121.980004 \n",
       "L 124.503117 114.744366 \n",
       "L 124.807786 112.332495 \n",
       "L 125.112454 112.332495 \n",
       "L 125.417122 126.803771 \n",
       "L 125.721791 114.744366 \n",
       "L 126.026459 114.744366 \n",
       "L 126.331127 112.332495 \n",
       "L 126.940464 112.332495 \n",
       "L 127.245132 114.744366 \n",
       "L 127.5498 112.332495 \n",
       "L 127.854469 117.156262 \n",
       "L 128.159137 107.508728 \n",
       "L 128.463805 126.803771 \n",
       "L 128.768474 109.920599 \n",
       "L 129.073142 117.156262 \n",
       "L 129.37781 114.744366 \n",
       "L 129.682479 121.980004 \n",
       "L 130.291815 112.332495 \n",
       "L 130.596483 109.920599 \n",
       "L 130.901152 112.332495 \n",
       "L 131.20582 117.156262 \n",
       "L 131.510488 112.332495 \n",
       "L 131.815157 112.332495 \n",
       "L 132.119825 114.744366 \n",
       "L 132.424493 114.744366 \n",
       "L 132.729162 112.332495 \n",
       "L 133.338498 117.156262 \n",
       "L 133.643166 121.980004 \n",
       "L 133.947835 114.744366 \n",
       "L 134.252503 114.744366 \n",
       "L 134.557171 112.332495 \n",
       "L 134.86184 119.568133 \n",
       "L 135.166508 112.332495 \n",
       "L 135.471176 109.920599 \n",
       "L 135.775845 121.980004 \n",
       "L 136.080513 117.156262 \n",
       "L 136.385181 126.803771 \n",
       "L 136.68985 124.3919 \n",
       "L 136.994518 119.568133 \n",
       "L 137.299186 131.627538 \n",
       "L 137.603854 119.568133 \n",
       "L 137.908523 117.156262 \n",
       "L 138.213191 117.156262 \n",
       "L 138.517859 112.332495 \n",
       "L 138.822528 114.744366 \n",
       "L 139.127196 114.744366 \n",
       "L 139.431864 119.568133 \n",
       "L 139.736533 119.568133 \n",
       "L 140.345869 109.920599 \n",
       "L 140.650537 121.980004 \n",
       "L 140.955206 114.744366 \n",
       "L 141.259874 119.568133 \n",
       "L 141.564542 114.744366 \n",
       "L 141.869211 126.803771 \n",
       "L 142.173879 121.980004 \n",
       "L 142.478547 112.332495 \n",
       "L 143.087884 112.332495 \n",
       "L 143.697221 117.156262 \n",
       "L 144.001889 112.332495 \n",
       "L 144.306557 117.156262 \n",
       "L 144.611225 129.215667 \n",
       "L 144.915894 114.744366 \n",
       "L 145.220562 112.332495 \n",
       "L 145.52523 117.156262 \n",
       "L 145.829899 112.332495 \n",
       "L 146.134567 117.156262 \n",
       "L 146.439235 117.156262 \n",
       "L 146.743904 129.215667 \n",
       "L 147.048572 117.156262 \n",
       "L 147.35324 112.332495 \n",
       "L 147.657908 117.156262 \n",
       "L 147.962577 117.156262 \n",
       "L 148.267245 114.744366 \n",
       "L 148.876582 119.568133 \n",
       "L 149.18125 119.568133 \n",
       "L 149.485918 129.215667 \n",
       "L 149.790587 126.803771 \n",
       "L 150.095255 114.744366 \n",
       "L 150.399923 126.803771 \n",
       "L 150.704592 121.980004 \n",
       "L 151.00926 121.980004 \n",
       "L 151.313928 126.803771 \n",
       "L 151.618596 121.980004 \n",
       "L 151.923265 124.3919 \n",
       "L 152.227933 121.980004 \n",
       "L 152.532601 126.803771 \n",
       "L 152.83727 124.3919 \n",
       "L 153.141938 124.3919 \n",
       "L 153.446606 126.803771 \n",
       "L 153.751275 119.568133 \n",
       "L 154.055943 119.568133 \n",
       "L 154.360611 121.980004 \n",
       "L 154.665279 117.156262 \n",
       "L 154.969948 119.568133 \n",
       "L 155.274616 114.744366 \n",
       "L 155.579284 114.744366 \n",
       "L 155.883953 119.568133 \n",
       "L 156.188621 119.568133 \n",
       "L 156.493289 114.744366 \n",
       "L 156.797958 117.156262 \n",
       "L 157.102626 121.980004 \n",
       "L 157.407294 117.156262 \n",
       "L 157.711963 121.980004 \n",
       "L 158.016631 117.156262 \n",
       "L 158.321299 124.3919 \n",
       "L 158.625967 119.568133 \n",
       "L 158.930636 124.3919 \n",
       "L 159.235304 124.3919 \n",
       "L 159.539972 121.980004 \n",
       "L 159.844641 114.744366 \n",
       "L 160.149309 117.156262 \n",
       "L 160.453977 126.803771 \n",
       "L 161.367982 119.568133 \n",
       "L 161.67265 126.803771 \n",
       "L 161.977319 129.215667 \n",
       "L 162.281987 117.156262 \n",
       "L 162.586655 117.156262 \n",
       "L 162.891324 121.980004 \n",
       "L 163.50066 117.156262 \n",
       "L 163.805329 124.3919 \n",
       "L 164.109997 117.156262 \n",
       "L 164.414665 119.568133 \n",
       "L 164.719334 124.3919 \n",
       "L 165.024002 117.156262 \n",
       "L 165.32867 121.980004 \n",
       "L 165.633338 114.744366 \n",
       "L 165.938007 121.980004 \n",
       "L 166.242675 114.744366 \n",
       "L 166.547343 119.568133 \n",
       "L 166.852012 131.627538 \n",
       "L 167.15668 117.156262 \n",
       "L 167.461348 119.568133 \n",
       "L 167.766017 117.156262 \n",
       "L 168.070685 121.980004 \n",
       "L 168.375353 119.568133 \n",
       "L 168.680021 121.980004 \n",
       "L 168.98469 117.156262 \n",
       "L 169.289358 117.156262 \n",
       "L 169.594026 121.980004 \n",
       "L 169.898695 117.156262 \n",
       "L 170.203363 138.863201 \n",
       "L 170.508031 114.744366 \n",
       "L 170.8127 119.568133 \n",
       "L 171.117368 119.568133 \n",
       "L 171.726705 114.744366 \n",
       "L 172.336041 124.3919 \n",
       "L 172.640709 119.568133 \n",
       "L 172.945378 119.568133 \n",
       "L 173.250046 131.627538 \n",
       "L 173.554714 136.451305 \n",
       "L 173.859383 117.156262 \n",
       "L 174.164051 119.568133 \n",
       "L 174.468719 114.744366 \n",
       "L 175.078056 114.744366 \n",
       "L 175.382724 119.568133 \n",
       "L 175.687393 119.568133 \n",
       "L 175.992061 117.156262 \n",
       "L 176.601397 121.980004 \n",
       "L 176.906066 119.568133 \n",
       "L 177.210734 119.568133 \n",
       "L 177.515402 117.156262 \n",
       "L 177.820071 121.980004 \n",
       "L 178.124739 119.568133 \n",
       "L 178.429407 119.568133 \n",
       "L 178.734076 117.156262 \n",
       "L 179.343412 121.980004 \n",
       "L 179.64808 117.156262 \n",
       "L 179.952749 119.568133 \n",
       "L 180.562085 114.744366 \n",
       "L 180.866754 121.980004 \n",
       "L 181.171422 119.568133 \n",
       "L 181.47609 119.568133 \n",
       "L 181.780759 124.3919 \n",
       "L 182.085427 117.156262 \n",
       "L 182.390095 114.744366 \n",
       "L 182.694764 124.3919 \n",
       "L 182.999432 114.744366 \n",
       "L 183.3041 121.980004 \n",
       "L 183.608768 117.156262 \n",
       "L 183.913437 119.568133 \n",
       "L 184.827442 119.568133 \n",
       "L 185.13211 131.627538 \n",
       "L 185.436778 117.156262 \n",
       "L 185.741447 119.568133 \n",
       "L 186.046115 119.568133 \n",
       "L 186.350783 121.980004 \n",
       "L 186.655451 119.568133 \n",
       "L 186.96012 126.803771 \n",
       "L 187.264788 119.568133 \n",
       "L 187.569456 124.3919 \n",
       "L 187.874125 119.568133 \n",
       "L 188.178793 119.568133 \n",
       "L 188.483461 117.156262 \n",
       "L 188.78813 121.980004 \n",
       "L 189.092798 121.980004 \n",
       "L 189.397466 119.568133 \n",
       "L 189.702135 121.980004 \n",
       "L 190.006803 117.156262 \n",
       "L 190.311471 124.3919 \n",
       "L 190.616139 124.3919 \n",
       "L 190.920808 119.568133 \n",
       "L 191.225476 124.3919 \n",
       "L 191.530144 121.980004 \n",
       "L 191.834813 126.803771 \n",
       "L 192.139481 119.568133 \n",
       "L 192.444149 124.3919 \n",
       "L 192.748818 117.156262 \n",
       "L 193.053486 119.568133 \n",
       "L 193.358154 124.3919 \n",
       "L 193.662822 119.568133 \n",
       "L 193.967491 119.568133 \n",
       "L 194.272159 117.156262 \n",
       "L 194.576827 121.980004 \n",
       "L 194.881496 121.980004 \n",
       "L 195.186164 119.568133 \n",
       "L 195.490832 126.803771 \n",
       "L 195.795501 121.980004 \n",
       "L 196.100169 119.568133 \n",
       "L 196.404837 124.3919 \n",
       "L 196.709506 124.3919 \n",
       "L 197.014174 129.215667 \n",
       "L 197.318842 121.980004 \n",
       "L 197.928179 117.156262 \n",
       "L 198.232847 119.568133 \n",
       "L 198.537515 124.3919 \n",
       "L 198.842184 117.156262 \n",
       "L 199.146852 124.3919 \n",
       "L 199.45152 114.744366 \n",
       "L 199.756189 117.156262 \n",
       "L 200.060857 141.275072 \n",
       "L 200.365525 124.3919 \n",
       "L 200.670193 117.156262 \n",
       "L 200.974862 134.039434 \n",
       "L 201.27953 124.3919 \n",
       "L 201.584198 121.980004 \n",
       "L 201.888867 121.980004 \n",
       "L 202.193535 112.332495 \n",
       "L 202.498203 124.3919 \n",
       "L 202.802872 121.980004 \n",
       "L 203.10754 131.627538 \n",
       "L 203.412208 121.980004 \n",
       "L 203.716877 124.3919 \n",
       "L 204.021545 121.980004 \n",
       "L 204.326213 131.627538 \n",
       "L 204.630881 126.803771 \n",
       "L 204.93555 126.803771 \n",
       "L 205.240218 129.215667 \n",
       "L 205.544886 121.980004 \n",
       "L 206.154223 126.803771 \n",
       "L 206.458891 124.3919 \n",
       "L 206.76356 124.3919 \n",
       "L 207.068228 153.334502 \n",
       "L 207.677564 124.3919 \n",
       "L 207.982233 129.215667 \n",
       "L 208.286901 121.980004 \n",
       "L 208.591569 126.803771 \n",
       "L 208.896238 134.039434 \n",
       "L 209.200906 124.3919 \n",
       "L 209.505574 121.980004 \n",
       "L 209.810243 124.3919 \n",
       "L 210.114911 121.980004 \n",
       "L 210.419579 121.980004 \n",
       "L 210.724248 129.215667 \n",
       "L 211.333584 119.568133 \n",
       "L 211.638252 119.568133 \n",
       "L 211.942921 134.039434 \n",
       "L 212.552257 124.3919 \n",
       "L 212.856926 117.156262 \n",
       "L 213.161594 121.980004 \n",
       "L 213.466262 129.215667 \n",
       "L 213.770931 124.3919 \n",
       "L 214.075599 124.3919 \n",
       "L 214.380267 119.568133 \n",
       "L 214.684936 124.3919 \n",
       "L 214.989604 131.627538 \n",
       "L 215.294272 124.3919 \n",
       "L 215.59894 124.3919 \n",
       "L 215.903609 114.744366 \n",
       "L 216.208277 124.3919 \n",
       "L 216.512945 126.803771 \n",
       "L 216.817614 119.568133 \n",
       "L 217.122282 126.803771 \n",
       "L 217.42695 121.980004 \n",
       "L 218.645623 131.627538 \n",
       "L 219.25496 126.803771 \n",
       "L 219.559628 126.803771 \n",
       "L 220.168965 131.627538 \n",
       "L 220.473633 124.3919 \n",
       "L 220.778302 121.980004 \n",
       "L 221.08297 146.098839 \n",
       "L 221.387638 129.215667 \n",
       "L 221.996975 124.3919 \n",
       "L 222.301643 129.215667 \n",
       "L 222.606311 124.3919 \n",
       "L 222.91098 124.3919 \n",
       "L 223.215648 148.510735 \n",
       "L 223.520316 126.803771 \n",
       "L 223.824985 119.568133 \n",
       "L 224.129653 134.039434 \n",
       "L 224.434321 129.215667 \n",
       "L 224.73899 136.451305 \n",
       "L 225.043658 121.980004 \n",
       "L 225.348326 119.568133 \n",
       "L 225.652994 121.980004 \n",
       "L 225.957663 129.215667 \n",
       "L 226.262331 124.3919 \n",
       "L 226.566999 138.863201 \n",
       "L 226.871668 141.275072 \n",
       "L 227.176336 121.980004 \n",
       "L 227.481004 134.039434 \n",
       "L 227.785673 134.039434 \n",
       "L 228.395009 117.156262 \n",
       "L 228.699678 138.863201 \n",
       "L 229.004346 124.3919 \n",
       "L 229.309014 131.627538 \n",
       "L 229.613682 126.803771 \n",
       "L 229.918351 124.3919 \n",
       "L 230.223019 126.803771 \n",
       "L 230.527687 119.568133 \n",
       "L 230.832356 124.3919 \n",
       "L 231.137024 126.803771 \n",
       "L 231.441692 117.156262 \n",
       "L 231.746361 126.803771 \n",
       "L 232.051029 121.980004 \n",
       "L 232.355697 126.803771 \n",
       "L 232.660365 117.156262 \n",
       "L 232.965034 146.098839 \n",
       "L 233.269702 121.980004 \n",
       "L 233.57437 119.568133 \n",
       "L 233.879039 131.627538 \n",
       "L 234.183707 117.156262 \n",
       "L 234.488375 126.803771 \n",
       "L 234.793044 121.980004 \n",
       "L 235.097712 141.275072 \n",
       "L 235.40238 117.156262 \n",
       "L 236.011717 134.039434 \n",
       "L 236.316385 117.156262 \n",
       "L 236.621053 134.039434 \n",
       "L 236.925722 119.568133 \n",
       "L 237.23039 124.3919 \n",
       "L 237.535058 121.980004 \n",
       "L 237.839727 121.980004 \n",
       "L 238.144395 119.568133 \n",
       "L 238.449063 119.568133 \n",
       "L 238.753732 121.980004 \n",
       "L 239.0584 117.156262 \n",
       "L 239.363068 119.568133 \n",
       "L 239.667736 126.803771 \n",
       "L 239.972405 121.980004 \n",
       "L 240.277073 124.3919 \n",
       "L 240.581741 124.3919 \n",
       "L 240.88641 134.039434 \n",
       "L 241.191078 124.3919 \n",
       "L 241.495746 119.568133 \n",
       "L 241.800415 124.3919 \n",
       "L 242.105083 124.3919 \n",
       "L 242.409751 131.627538 \n",
       "L 242.71442 126.803771 \n",
       "L 243.019088 119.568133 \n",
       "L 243.323756 129.215667 \n",
       "L 243.933093 119.568133 \n",
       "L 244.237761 117.156262 \n",
       "L 244.542429 126.803771 \n",
       "L 244.847098 131.627538 \n",
       "L 245.151766 134.039434 \n",
       "L 245.456434 131.627538 \n",
       "L 245.761103 121.980004 \n",
       "L 246.065771 121.980004 \n",
       "L 246.370439 126.803771 \n",
       "L 246.675107 134.039434 \n",
       "L 246.979776 146.098839 \n",
       "L 247.284444 148.510735 \n",
       "L 247.589112 129.215667 \n",
       "L 247.893781 141.275072 \n",
       "L 248.198449 121.980004 \n",
       "L 248.503117 129.215667 \n",
       "L 248.807786 114.744366 \n",
       "L 249.112454 124.3919 \n",
       "L 249.417122 121.980004 \n",
       "L 249.721791 121.980004 \n",
       "L 250.026459 124.3919 \n",
       "L 250.331127 131.627538 \n",
       "L 250.635795 124.3919 \n",
       "L 250.940464 143.686968 \n",
       "L 251.5498 121.980004 \n",
       "L 251.854469 126.803771 \n",
       "L 252.159137 121.980004 \n",
       "L 252.463805 136.451305 \n",
       "L 252.768474 124.3919 \n",
       "L 253.37781 124.3919 \n",
       "L 253.682479 119.568133 \n",
       "L 253.987147 121.980004 \n",
       "L 254.291815 129.215667 \n",
       "L 254.596483 119.568133 \n",
       "L 254.901152 141.275072 \n",
       "L 255.20582 121.980004 \n",
       "L 255.510488 117.156262 \n",
       "L 255.815157 121.980004 \n",
       "L 256.119825 121.980004 \n",
       "L 256.424493 124.3919 \n",
       "L 256.729162 136.451305 \n",
       "L 257.03383 121.980004 \n",
       "L 257.338498 121.980004 \n",
       "L 257.643166 119.568133 \n",
       "L 257.947835 126.803771 \n",
       "L 258.252503 117.156262 \n",
       "L 258.557171 134.039434 \n",
       "L 258.86184 124.3919 \n",
       "L 259.166508 121.980004 \n",
       "L 259.471176 129.215667 \n",
       "L 259.775845 117.156262 \n",
       "L 260.080513 131.627538 \n",
       "L 260.385181 121.980004 \n",
       "L 260.68985 131.627538 \n",
       "L 260.994518 124.3919 \n",
       "L 261.299186 121.980004 \n",
       "L 261.908523 126.803771 \n",
       "L 262.213191 143.686968 \n",
       "L 262.517859 138.863201 \n",
       "L 262.822528 124.3919 \n",
       "L 263.127196 126.803771 \n",
       "L 263.431864 119.568133 \n",
       "L 263.736533 121.980004 \n",
       "L 264.041201 117.156262 \n",
       "L 264.345869 141.275072 \n",
       "L 264.650537 131.627538 \n",
       "L 264.955206 134.039434 \n",
       "L 265.259874 117.156262 \n",
       "L 265.564542 121.980004 \n",
       "L 265.869211 117.156262 \n",
       "L 266.173879 114.744366 \n",
       "L 266.478547 138.863201 \n",
       "L 266.783216 141.275072 \n",
       "L 267.087884 124.3919 \n",
       "L 267.392552 129.215667 \n",
       "L 267.697221 131.627538 \n",
       "L 268.001889 119.568133 \n",
       "L 268.306557 124.3919 \n",
       "L 268.611225 121.980004 \n",
       "L 269.220562 121.980004 \n",
       "L 269.52523 119.568133 \n",
       "L 269.829899 121.980004 \n",
       "L 270.134567 126.803771 \n",
       "L 270.439235 124.3919 \n",
       "L 270.743904 124.3919 \n",
       "L 271.048572 117.156262 \n",
       "L 271.35324 126.803771 \n",
       "L 271.657908 124.3919 \n",
       "L 271.962577 131.627538 \n",
       "L 272.267245 126.803771 \n",
       "L 272.571913 119.568133 \n",
       "L 272.876582 121.980004 \n",
       "L 273.18125 131.627538 \n",
       "L 273.790587 119.568133 \n",
       "L 274.095255 141.275072 \n",
       "L 274.399923 126.803771 \n",
       "L 274.704592 134.039434 \n",
       "L 275.00926 131.627538 \n",
       "L 275.313928 134.039434 \n",
       "L 275.618596 124.3919 \n",
       "L 275.923265 131.627538 \n",
       "L 276.227933 121.980004 \n",
       "L 276.532601 129.215667 \n",
       "L 276.83727 129.215667 \n",
       "L 277.141938 134.039434 \n",
       "L 277.446606 119.568133 \n",
       "L 277.751275 117.156262 \n",
       "L 278.055943 121.980004 \n",
       "L 278.360611 121.980004 \n",
       "L 278.665279 131.627538 \n",
       "L 278.969948 119.568133 \n",
       "L 279.274616 136.451305 \n",
       "L 279.579284 129.215667 \n",
       "L 279.883953 126.803771 \n",
       "L 280.188621 121.980004 \n",
       "L 280.493289 119.568133 \n",
       "L 280.797958 136.451305 \n",
       "L 281.102626 124.3919 \n",
       "L 281.407294 126.803771 \n",
       "L 282.321299 119.568133 \n",
       "L 282.625967 119.568133 \n",
       "L 282.930636 117.156262 \n",
       "L 283.235304 129.215667 \n",
       "L 283.539972 119.568133 \n",
       "L 283.844641 121.980004 \n",
       "L 284.149309 121.980004 \n",
       "L 284.453977 124.3919 \n",
       "L 284.758646 131.627538 \n",
       "L 285.063314 126.803771 \n",
       "L 285.367982 131.627538 \n",
       "L 285.67265 124.3919 \n",
       "L 285.977319 126.803771 \n",
       "L 286.281987 126.803771 \n",
       "L 286.586655 119.568133 \n",
       "L 286.891324 141.275072 \n",
       "L 287.195992 124.3919 \n",
       "L 287.50066 126.803771 \n",
       "L 287.805329 121.980004 \n",
       "L 288.109997 124.3919 \n",
       "L 288.414665 121.980004 \n",
       "L 288.719334 124.3919 \n",
       "L 289.024002 114.744366 \n",
       "L 289.633338 126.803771 \n",
       "L 290.242675 121.980004 \n",
       "L 290.547343 124.3919 \n",
       "L 290.852012 129.215667 \n",
       "L 291.15668 121.980004 \n",
       "L 291.766017 117.156262 \n",
       "L 292.070685 126.803771 \n",
       "L 292.98469 119.568133 \n",
       "L 293.289358 119.568133 \n",
       "L 293.594026 121.980004 \n",
       "L 293.898695 119.568133 \n",
       "L 294.203363 119.568133 \n",
       "L 294.508031 126.803771 \n",
       "L 294.8127 129.215667 \n",
       "L 295.117368 124.3919 \n",
       "L 295.422036 126.803771 \n",
       "L 295.726705 124.3919 \n",
       "L 296.031373 119.568133 \n",
       "L 296.336041 124.3919 \n",
       "L 296.640709 141.275072 \n",
       "L 296.945378 119.568133 \n",
       "L 297.250046 131.627538 \n",
       "L 297.554714 124.3919 \n",
       "L 297.859383 134.039434 \n",
       "L 298.164051 131.627538 \n",
       "L 298.468719 131.627538 \n",
       "L 298.773388 141.275072 \n",
       "L 299.078056 131.627538 \n",
       "L 299.382724 131.627538 \n",
       "L 299.687393 124.3919 \n",
       "L 300.296729 129.215667 \n",
       "L 300.906066 119.568133 \n",
       "L 301.210734 121.980004 \n",
       "L 301.820071 143.686968 \n",
       "L 302.429407 121.980004 \n",
       "L 302.734076 126.803771 \n",
       "L 303.038744 124.3919 \n",
       "L 303.343412 119.568133 \n",
       "L 303.64808 119.568133 \n",
       "L 303.952749 126.803771 \n",
       "L 304.257417 117.156262 \n",
       "L 304.562085 117.156262 \n",
       "L 304.866754 129.215667 \n",
       "L 305.171422 117.156262 \n",
       "L 305.47609 129.215667 \n",
       "L 306.085427 129.215667 \n",
       "L 306.999432 121.980004 \n",
       "L 307.3041 126.803771 \n",
       "L 307.608768 126.803771 \n",
       "L 307.913437 136.451305 \n",
       "L 308.522773 117.156262 \n",
       "L 308.827442 129.215667 \n",
       "L 309.13211 124.3919 \n",
       "L 309.436778 117.156262 \n",
       "L 309.741447 124.3919 \n",
       "L 310.046115 121.980004 \n",
       "L 310.350783 121.980004 \n",
       "L 310.655451 119.568133 \n",
       "L 310.96012 119.568133 \n",
       "L 311.264788 121.980004 \n",
       "L 311.569456 136.451305 \n",
       "L 311.874125 119.568133 \n",
       "L 312.178793 117.156262 \n",
       "L 312.483461 129.215667 \n",
       "L 312.78813 119.568133 \n",
       "L 313.092798 124.3919 \n",
       "L 313.397466 119.568133 \n",
       "L 314.006803 129.215667 \n",
       "L 314.311471 141.275072 \n",
       "L 314.616139 124.3919 \n",
       "L 314.920808 117.156262 \n",
       "L 315.530144 126.803771 \n",
       "L 315.834813 124.3919 \n",
       "L 316.139481 119.568133 \n",
       "L 316.748818 138.863201 \n",
       "L 317.053486 126.803771 \n",
       "L 317.358154 138.863201 \n",
       "L 317.662822 126.803771 \n",
       "L 317.967491 121.980004 \n",
       "L 318.272159 121.980004 \n",
       "L 318.576827 119.568133 \n",
       "L 318.881496 141.275072 \n",
       "L 319.186164 117.156262 \n",
       "L 319.490832 119.568133 \n",
       "L 319.795501 117.156262 \n",
       "L 321.014174 117.156262 \n",
       "L 321.318842 124.3919 \n",
       "L 321.928179 112.332495 \n",
       "L 322.232847 126.803771 \n",
       "L 322.537515 121.980004 \n",
       "L 322.842184 121.980004 \n",
       "L 323.146852 119.568133 \n",
       "L 323.45152 121.980004 \n",
       "L 323.756189 121.980004 \n",
       "L 324.060857 119.568133 \n",
       "L 324.670193 134.039434 \n",
       "L 325.27953 121.980004 \n",
       "L 325.584198 119.568133 \n",
       "L 325.888867 121.980004 \n",
       "L 326.193535 121.980004 \n",
       "L 326.498203 124.3919 \n",
       "L 326.802872 119.568133 \n",
       "L 327.716877 119.568133 \n",
       "L 328.021545 121.980004 \n",
       "L 328.326213 126.803771 \n",
       "L 328.93555 117.156262 \n",
       "L 329.240218 121.980004 \n",
       "L 329.544886 124.3919 \n",
       "L 330.154223 124.3919 \n",
       "L 330.458891 114.744366 \n",
       "L 330.76356 117.156262 \n",
       "L 331.372896 126.803771 \n",
       "L 331.677564 124.3919 \n",
       "L 331.982233 119.568133 \n",
       "L 332.286901 117.156262 \n",
       "L 332.591569 124.3919 \n",
       "L 332.896238 121.980004 \n",
       "L 333.200906 129.215667 \n",
       "L 333.505574 131.627538 \n",
       "L 333.810243 124.3919 \n",
       "L 334.114911 121.980004 \n",
       "L 334.419579 117.156262 \n",
       "L 335.028916 126.803771 \n",
       "L 335.333584 119.568133 \n",
       "L 335.638252 121.980004 \n",
       "L 335.942921 117.156262 \n",
       "L 336.247589 117.156262 \n",
       "L 336.552257 126.803771 \n",
       "L 336.856926 124.3919 \n",
       "L 337.161594 141.275072 \n",
       "L 337.770931 121.980004 \n",
       "L 338.075599 124.3919 \n",
       "L 338.380267 141.275072 \n",
       "L 338.989604 119.568133 \n",
       "L 339.294272 131.627538 \n",
       "L 339.59894 124.3919 \n",
       "L 339.903609 136.451305 \n",
       "L 340.208277 126.803771 \n",
       "L 340.512945 121.980004 \n",
       "L 340.817614 121.980004 \n",
       "L 341.122282 134.039434 \n",
       "L 341.42695 124.3919 \n",
       "L 341.731619 126.803771 \n",
       "L 342.036287 126.803771 \n",
       "L 342.340955 138.863201 \n",
       "L 342.645623 136.451305 \n",
       "L 342.950292 136.451305 \n",
       "L 343.25496 121.980004 \n",
       "L 343.559628 126.803771 \n",
       "L 343.864297 134.039434 \n",
       "L 344.168965 121.980004 \n",
       "L 344.473633 121.980004 \n",
       "L 344.778302 126.803771 \n",
       "L 345.08297 121.980004 \n",
       "L 345.387638 121.980004 \n",
       "L 345.692307 126.803771 \n",
       "L 345.996975 121.980004 \n",
       "L 346.301643 121.980004 \n",
       "L 346.606311 138.863201 \n",
       "L 346.91098 121.980004 \n",
       "L 347.215648 131.627538 \n",
       "L 347.520316 119.568133 \n",
       "L 347.824985 124.3919 \n",
       "L 348.129653 121.980004 \n",
       "L 348.434321 134.039434 \n",
       "L 348.73899 121.980004 \n",
       "L 349.043658 121.980004 \n",
       "L 349.348326 124.3919 \n",
       "L 349.652994 117.156262 \n",
       "L 349.957663 126.803771 \n",
       "L 350.262331 119.568133 \n",
       "L 350.871668 119.568133 \n",
       "L 351.176336 131.627538 \n",
       "L 351.481004 134.039434 \n",
       "L 351.785673 119.568133 \n",
       "L 352.090341 117.156262 \n",
       "L 352.699678 126.803771 \n",
       "L 353.004346 129.215667 \n",
       "L 353.613682 129.215667 \n",
       "L 353.918351 117.156262 \n",
       "L 354.223019 121.980004 \n",
       "L 354.527687 119.568133 \n",
       "L 354.832356 121.980004 \n",
       "L 355.137024 117.156262 \n",
       "L 355.441692 129.215667 \n",
       "L 355.746361 119.568133 \n",
       "L 356.051029 121.980004 \n",
       "L 356.355697 126.803771 \n",
       "L 356.660365 121.980004 \n",
       "L 356.965034 134.039434 \n",
       "L 357.269702 126.803771 \n",
       "L 357.57437 129.215667 \n",
       "L 357.879039 129.215667 \n",
       "L 358.183707 121.980004 \n",
       "L 358.488375 124.3919 \n",
       "L 358.793044 124.3919 \n",
       "L 359.097712 121.980004 \n",
       "L 359.40238 134.039434 \n",
       "L 359.707049 119.568133 \n",
       "L 360.011717 121.980004 \n",
       "L 360.316385 129.215667 \n",
       "L 360.621053 119.568133 \n",
       "L 360.925722 124.3919 \n",
       "L 361.23039 117.156262 \n",
       "L 361.535058 136.451305 \n",
       "L 361.839727 121.980004 \n",
       "L 362.144395 117.156262 \n",
       "L 362.449063 117.156262 \n",
       "L 363.0584 121.980004 \n",
       "L 363.363068 129.215667 \n",
       "L 363.363068 129.215667 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 239.758125 \n",
       "L 43.78125 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 378.58125 239.758125 \n",
       "L 378.58125 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 239.758125 \n",
       "L 378.58125 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 22.318125 \n",
       "L 378.58125 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- Training Test accuracy -->\n",
       "    <defs>\n",
       "     <path d=\"M -0.296875 72.90625 \n",
       "L 61.375 72.90625 \n",
       "L 61.375 64.59375 \n",
       "L 35.5 64.59375 \n",
       "L 35.5 0 \n",
       "L 25.59375 0 \n",
       "L 25.59375 64.59375 \n",
       "L -0.296875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "     <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "     <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-6e\"/>\n",
       "     <path d=\"M 45.40625 27.984375 \n",
       "Q 45.40625 37.75 41.375 43.109375 \n",
       "Q 37.359375 48.484375 30.078125 48.484375 \n",
       "Q 22.859375 48.484375 18.828125 43.109375 \n",
       "Q 14.796875 37.75 14.796875 27.984375 \n",
       "Q 14.796875 18.265625 18.828125 12.890625 \n",
       "Q 22.859375 7.515625 30.078125 7.515625 \n",
       "Q 37.359375 7.515625 41.375 12.890625 \n",
       "Q 45.40625 18.265625 45.40625 27.984375 \n",
       "z\n",
       "M 54.390625 6.78125 \n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \n",
       "Q 42 -20.796875 29.203125 -20.796875 \n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \n",
       "L 12.109375 -9.1875 \n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \n",
       "Q 23.78125 -13.375 27.78125 -13.375 \n",
       "Q 36.625 -13.375 41.015625 -8.765625 \n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \n",
       "L 45.40625 9.625 \n",
       "Q 42.625 4.78125 38.28125 2.390625 \n",
       "Q 33.9375 0 27.875 0 \n",
       "Q 17.828125 0 11.671875 7.65625 \n",
       "Q 5.515625 15.328125 5.515625 27.984375 \n",
       "Q 5.515625 40.671875 11.671875 48.328125 \n",
       "Q 17.828125 56 27.875 56 \n",
       "Q 33.9375 56 38.28125 53.609375 \n",
       "Q 42.625 51.21875 45.40625 46.390625 \n",
       "L 45.40625 54.6875 \n",
       "L 54.390625 54.6875 \n",
       "z\n",
       "\" id=\"DejaVuSans-67\"/>\n",
       "     <path id=\"DejaVuSans-20\"/>\n",
       "     <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-65\"/>\n",
       "     <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-74\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(142.935 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "     <use x=\"60.865234\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "     <use x=\"101.978516\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use x=\"163.257812\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "     <use x=\"191.041016\" xlink:href=\"#DejaVuSans-6e\"/>\n",
       "     <use x=\"254.419922\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "     <use x=\"282.203125\" xlink:href=\"#DejaVuSans-6e\"/>\n",
       "     <use x=\"345.582031\" xlink:href=\"#DejaVuSans-67\"/>\n",
       "     <use x=\"409.058594\" xlink:href=\"#DejaVuSans-20\"/>\n",
       "     <use x=\"440.845703\" xlink:href=\"#DejaVuSans-54\"/>\n",
       "     <use x=\"501.664062\" xlink:href=\"#DejaVuSans-65\"/>\n",
       "     <use x=\"563.1875\" xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use x=\"615.287109\" xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use x=\"654.496094\" xlink:href=\"#DejaVuSans-20\"/>\n",
       "     <use x=\"686.283203\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use x=\"747.5625\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "     <use x=\"802.542969\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "     <use x=\"857.523438\" xlink:href=\"#DejaVuSans-75\"/>\n",
       "     <use x=\"920.902344\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "     <use x=\"962.015625\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use x=\"1023.294922\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "     <use x=\"1078.275391\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 266.1875 234.758125 \n",
       "L 371.58125 234.758125 \n",
       "Q 373.58125 234.758125 373.58125 232.758125 \n",
       "L 373.58125 203.845625 \n",
       "Q 373.58125 201.845625 371.58125 201.845625 \n",
       "L 266.1875 201.845625 \n",
       "Q 264.1875 201.845625 264.1875 203.845625 \n",
       "L 264.1875 232.758125 \n",
       "Q 264.1875 234.758125 266.1875 234.758125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_14\">\n",
       "     <path d=\"M 268.1875 209.944062 \n",
       "L 288.1875 209.944062 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_15\"/>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- train_accuracy -->\n",
       "     <defs>\n",
       "      <path d=\"M 50.984375 -16.609375 \n",
       "L 50.984375 -23.578125 \n",
       "L -0.984375 -23.578125 \n",
       "L -0.984375 -16.609375 \n",
       "z\n",
       "\" id=\"DejaVuSans-5f\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(296.1875 213.444062)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-6e\"/>\n",
       "      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-5f\"/>\n",
       "      <use x=\"282.763672\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"344.042969\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"399.023438\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"454.003906\" xlink:href=\"#DejaVuSans-75\"/>\n",
       "      <use x=\"517.382812\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"558.496094\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"619.775391\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"674.755859\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_16\">\n",
       "     <path d=\"M 268.1875 224.900312 \n",
       "L 288.1875 224.900312 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\"/>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- test_accuracy -->\n",
       "     <g transform=\"translate(296.1875 228.400312)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-73\"/>\n",
       "      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-5f\"/>\n",
       "      <use x=\"242.041016\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"303.320312\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"358.300781\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"413.28125\" xlink:href=\"#DejaVuSans-75\"/>\n",
       "      <use x=\"476.660156\" xlink:href=\"#DejaVuSans-72\"/>\n",
       "      <use x=\"517.773438\" xlink:href=\"#DejaVuSans-61\"/>\n",
       "      <use x=\"579.052734\" xlink:href=\"#DejaVuSans-63\"/>\n",
       "      <use x=\"634.033203\" xlink:href=\"#DejaVuSans-79\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pf0d795a724\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18398714e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printlog(\"step5: eval model...\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics)\n",
    "#              'bo-')\n",
    "    plt.plot(epochs, val_metrics)\n",
    "#              'ro-')\n",
    "    \n",
    "    plt.title('Training '+ 'Test '+metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'test_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "plot_metric(history,\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
